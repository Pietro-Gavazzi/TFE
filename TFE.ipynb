{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ffce1229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62944809",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Activation function (ReLU) and its derivative\n",
    "\n",
    "# def relu(x):\n",
    "#     return np.maximum(0, x)\n",
    "\n",
    "def activation_fn(x):\n",
    "    return x\n",
    "\n",
    "# def relu_derivative(x):\n",
    "#     return np.where(x > 0, 1, 0)\n",
    "\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return 1\n",
    "\n",
    "# Mean Squared Error and its derivative\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def mse_derivative(y_true, y_pred):\n",
    "    return -2 * (y_true - y_pred) / len(y_true)\n",
    "\n",
    "# Neural Network with multiple optimizers and early stopping\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, dim_list,  lr=0.01, epsilon=1e-8):\n",
    "        self.dim_list = dim_list\n",
    "        self.lr = lr\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        # Initialize weights and biases        \n",
    "        for i in range(len(dim_list)-1):\n",
    "            self.weights.append(np.random.randn(dim_list[i], dim_list[i+1]) )\n",
    "            self.biases.append(np.zeros((1, dim_list[i+1])))\n",
    "        \n",
    "\n",
    "    def forward(self, X):\n",
    "        self.activations = [X]\n",
    "        self.z_values = []\n",
    "        \n",
    "        for i in range(len(self.weights)):\n",
    "            Z = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]\n",
    "            self.z_values.append(Z)\n",
    "            if i == len(self.weights) - 1:  # No activation for the output layer\n",
    "                self.activations.append(Z) \n",
    "            else:\n",
    "                self.activations.append(activation_fn(Z))\n",
    "        \n",
    "        return self.activations[-1]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward(X)\n",
    "\n",
    "    def __call__(self, X):\n",
    "        return self.predict(X)\n",
    "    \n",
    "    def backward(self, X, y, y_pred):\n",
    "        dL_dZ = mse_derivative(y, y_pred)\n",
    "\n",
    "        # print(\"dldz = \"+str(dL_dZ))\n",
    "        # print (\"activations = \"+str(self.activations))\n",
    "        gradients_weights = []\n",
    "        gradients_biases = []\n",
    "\n",
    "        self.z_der = dL_dZ\n",
    "\n",
    "        last_layer = True\n",
    "\n",
    "        for i in reversed(range(len(self.weights))):\n",
    "            dL_dW = np.dot(self.activations[i].T, dL_dZ)\n",
    "            dL_db = np.sum(dL_dZ, axis=0, keepdims=True)\n",
    "            gradients_weights.insert(0, dL_dW)\n",
    "            gradients_biases.insert(0, dL_db)\n",
    "            \n",
    "            if i > 0:\n",
    "                if last_layer:\n",
    "                    dL_dA_prev = np.dot(dL_dZ, self.weights[i].T)\n",
    "                    dL_dZ = dL_dA_prev * self.z_values[i - 1]\n",
    "                    last_layer = False\n",
    "                else : \n",
    "                    dL_dA_prev = np.dot(dL_dZ, self.weights[i].T)\n",
    "                    dL_dZ = dL_dA_prev * relu_derivative(self.z_values[i - 1])\n",
    "        \n",
    "        return gradients_weights, gradients_biases\n",
    "    \n",
    "    def update_parameters(self, gradients_weights, gradients_biases, X, y):\n",
    "        \"\"\"\n",
    "        Gradient descent with bold-driver adaptive learning rate:\n",
    "        - If loss decreases:    lr ← 2 * lr\n",
    "        - If loss increases:    restore old weights, lr ← lr / 2\n",
    "        \"\"\"\n",
    "        print(self.lr)\n",
    "\n",
    "        # Compute current loss\n",
    "        old_loss = mse(y, self.forward(X))\n",
    "\n",
    "        # Save old weights and biases\n",
    "        old_weights = [w.copy() for w in self.weights]\n",
    "        old_biases  = [b.copy() for b in self.biases]\n",
    "\n",
    "        # --- Try update with current LR ---\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= self.lr * gradients_weights[i]\n",
    "            self.biases[i]  -= self.lr * gradients_biases[i]\n",
    "\n",
    "        # Compute new loss\n",
    "        new_loss = mse(y, self.forward(X))\n",
    "\n",
    "        # ----------------------------------------------\n",
    "        # Case 1: Improvement → double learning rate\n",
    "        # ----------------------------------------------\n",
    "        if new_loss <= old_loss:\n",
    "            self.lr *= 2\n",
    "            return\n",
    "\n",
    "        # ----------------------------------------------\n",
    "        # Case 2: Loss increased → rollback & shrink LR\n",
    "        # ----------------------------------------------\n",
    "        # Restore parameters\n",
    "        self.weights = [w.copy() for w in old_weights]\n",
    "        self.biases  = [b.copy() for b in old_biases]\n",
    "\n",
    "        # Reduce learning rate until we get improvement\n",
    "        while True:\n",
    "            self.lr /= 2\n",
    "            if self.lr < 1e-8:\n",
    "                # Stop trying if LR becomes too small\n",
    "                break\n",
    "\n",
    "            # Try update again\n",
    "            for i in range(len(self.weights)):\n",
    "                self.weights[i] = old_weights[i] - self.lr * gradients_weights[i]\n",
    "                self.biases[i]  = old_biases[i]  - self.lr * gradients_biases[i]\n",
    "\n",
    "            new_loss = mse(y, self.forward(X))\n",
    "\n",
    "            if new_loss <= old_loss:\n",
    "                break  # success\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def step(self, X, y, X_val, y_val):\n",
    "        y_pred = self.forward(X)\n",
    "        loss = mse(y, y_pred) \n",
    "        val_loss = mse(y_val, self.forward(X_val))\n",
    "        gradients_weights, gradients_biases = self.backward(X, y, y_pred)\n",
    "\n",
    "        self.update_parameters(gradients_weights, gradients_biases, X, y)\n",
    "        return loss, val_loss, gradients_weights, gradients_biases \n",
    "\n",
    "\n",
    "\n",
    "    def train(self, X, y, X_val, y_val, epochs, patience=10):\n",
    "        best_loss = float(\"inf\")\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            loss, val_loss = self.step(X, y, X_val, y_val)\n",
    "            print(f\"Epoch {epoch}, Loss: {loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "            \n",
    "            # # Early stopping check\n",
    "            # if val_loss < best_loss:\n",
    "            #     best_loss = val_loss\n",
    "            #     patience_counter = 0\n",
    "            # else:\n",
    "            #     patience_counter += 1\n",
    "            #     if patience_counter >= patience:\n",
    "            #         print(\"Early stopping triggered\")\n",
    "            #         break\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa7ccaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_data(n, d, noise_variance):\n",
    "    \"\"\"Generates random Gaussian data with noise.\"\"\"\n",
    "    X = np.random.normal(0, 1, (n, d))\n",
    "    Xtest = np.random.normal(0, 1, (n, d))\n",
    "    w_true = np.random.normal(0, 1, (d,1))\n",
    "    noise = np.random.normal(0, 1, (n, 1))\n",
    "    y = X @ w_true + noise_variance * noise\n",
    "    noise2 = np.random.normal(0, 1, (n,1))\n",
    "    ytest = Xtest @ w_true + noise_variance * noise2\n",
    "    w_star = np.linalg.pinv(X.T @ X) @ X.T @ y\n",
    "    norm_factor = np.linalg.norm(w_star)\n",
    "    w_star = w_star / norm_factor\n",
    "    y = y / norm_factor\n",
    "    ytest = ytest / norm_factor\n",
    "    return (X, y, Xtest, ytest, w_star)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76ede3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, y, Xtest, ytest, w_star) = generate_data(10, 1, .1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f2806ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "Epoch 0, Loss: 0.0753, Validation Loss: 0.1282, Gradient norm: 0.06333340436427637\n",
      "0.2\n",
      "Epoch 1, Loss: 0.0771, Validation Loss: 0.1318, Gradient norm: 0.030366563230881022\n",
      "0.2\n",
      "Epoch 2, Loss: 0.0848, Validation Loss: 0.1400, Gradient norm: 0.019307732156421266\n",
      "0.2\n",
      "Epoch 3, Loss: 0.0958, Validation Loss: 0.1503, Gradient norm: 0.016563693721319172\n",
      "0.2\n",
      "Epoch 4, Loss: 0.1095, Validation Loss: 0.1622, Gradient norm: 0.01728825202268365\n",
      "0.2\n",
      "Epoch 5, Loss: 0.1261, Validation Loss: 0.1758, Gradient norm: 0.019788515399089848\n",
      "0.2\n",
      "Epoch 6, Loss: 0.1465, Validation Loss: 0.1916, Gradient norm: 0.023528905078352313\n",
      "0.2\n",
      "Epoch 7, Loss: 0.1713, Validation Loss: 0.2102, Gradient norm: 0.02841918821879382\n",
      "0.2\n",
      "Epoch 8, Loss: 0.2018, Validation Loss: 0.2321, Gradient norm: 0.03456232444742476\n",
      "0.2\n",
      "Epoch 9, Loss: 0.2391, Validation Loss: 0.2582, Gradient norm: 0.042168356727440556\n",
      "0.2\n",
      "Epoch 10, Loss: 0.2850, Validation Loss: 0.2895, Gradient norm: 0.05152961646366706\n",
      "0.2\n",
      "Epoch 11, Loss: 0.3414, Validation Loss: 0.3270, Gradient norm: 0.0630199911044772\n",
      "0.2\n",
      "Epoch 12, Loss: 0.4106, Validation Loss: 0.3721, Gradient norm: 0.07710518322863534\n",
      "0.2\n",
      "Epoch 13, Loss: 0.4956, Validation Loss: 0.4265, Gradient norm: 0.09435964460440312\n",
      "0.2\n",
      "Epoch 14, Loss: 0.6000, Validation Loss: 0.4920, Gradient norm: 0.11548913034518042\n",
      "0.2\n",
      "Epoch 15, Loss: 0.7281, Validation Loss: 0.5713, Gradient norm: 0.14135913377381687\n",
      "0.2\n",
      "Epoch 16, Loss: 0.8853, Validation Loss: 0.6671, Gradient norm: 0.17303010425127682\n",
      "0.2\n",
      "Epoch 17, Loss: 1.0781, Validation Loss: 0.7831, Gradient norm: 0.21180078041896835\n",
      "0.2\n",
      "Epoch 18, Loss: 1.3146, Validation Loss: 0.9237, Gradient norm: 0.25926136453276083\n",
      "0.2\n",
      "Epoch 19, Loss: 1.6047, Validation Loss: 1.0942, Gradient norm: 0.3173586928665798\n",
      "0.2\n",
      "Epoch 20, Loss: 1.9603, Validation Loss: 1.3013, Gradient norm: 0.38847606111670896\n",
      "0.2\n",
      "Epoch 21, Loss: 2.3963, Validation Loss: 1.5528, Gradient norm: 0.47553097095711955\n",
      "0.2\n",
      "Epoch 22, Loss: 2.9306, Validation Loss: 1.8587, Gradient norm: 0.5820948024310084\n",
      "0.2\n",
      "Epoch 23, Loss: 3.5856, Validation Loss: 2.2307, Gradient norm: 0.7125393183366485\n",
      "0.2\n",
      "Epoch 24, Loss: 4.3881, Validation Loss: 2.6835, Gradient norm: 0.872216008767574\n",
      "0.2\n",
      "Epoch 25, Loss: 5.3715, Validation Loss: 3.2349, Gradient norm: 1.0676756320143634\n",
      "0.2\n",
      "Epoch 26, Loss: 6.5763, Validation Loss: 3.9068, Gradient norm: 1.306936957600366\n",
      "0.2\n",
      "Epoch 27, Loss: 8.0522, Validation Loss: 4.7258, Gradient norm: 1.599815736079869\n",
      "0.2\n",
      "Epoch 28, Loss: 9.8602, Validation Loss: 5.7244, Gradient norm: 1.9583273912595933\n",
      "0.2\n",
      "Epoch 29, Loss: 12.0749, Validation Loss: 6.9425, Gradient norm: 2.397179955126929\n",
      "0.2\n",
      "Epoch 30, Loss: 14.7874, Validation Loss: 8.4289, Gradient norm: 2.934377468091776\n",
      "0.2\n",
      "Epoch 31, Loss: 18.1096, Validation Loss: 10.2432, Gradient norm: 3.59195859907886\n",
      "0.2\n",
      "Epoch 32, Loss: 22.1782, Validation Loss: 12.4583, Gradient norm: 4.396900787477686\n",
      "0.2\n",
      "Epoch 33, Loss: 27.1607, Validation Loss: 15.1633, Gradient norm: 5.382226999562276\n",
      "0.2\n",
      "Epoch 34, Loss: 33.2622, Validation Loss: 18.4675, Gradient norm: 6.588360504322525\n",
      "0.2\n",
      "Epoch 35, Loss: 40.7337, Validation Loss: 22.5043, Gradient norm: 8.06478324872305\n",
      "0.2\n",
      "Epoch 36, Loss: 49.8824, Validation Loss: 27.4370, Gradient norm: 9.87206586765988\n",
      "0.2\n",
      "Epoch 37, Loss: 61.0846, Validation Loss: 33.4656, Gradient norm: 12.084352610302911\n",
      "0.2\n",
      "Epoch 38, Loss: 74.8007, Validation Loss: 40.8345, Gradient norm: 14.792403127580366\n",
      "0.2\n",
      "Epoch 39, Loss: 91.5944, Validation Loss: 49.8431, Gradient norm: 18.107315910940418\n",
      "0.2\n",
      "Epoch 40, Loss: 112.1560, Validation Loss: 60.8575, Gradient norm: 22.16508613745109\n",
      "0.2\n",
      "Epoch 41, Loss: 137.3303, Validation Loss: 74.3258, Gradient norm: 27.132184908041467\n",
      "0.2\n",
      "Epoch 42, Loss: 168.1513, Validation Loss: 90.7964, Gradient norm: 33.21238876861409\n",
      "0.2\n",
      "Epoch 43, Loss: 205.8852, Validation Loss: 110.9404, Gradient norm: 40.655139696943905\n",
      "0.2\n",
      "Epoch 44, Loss: 252.0816, Validation Loss: 135.5792, Gradient norm: 49.76577852604574\n",
      "0.2\n",
      "Epoch 45, Loss: 308.6377, Validation Loss: 165.7179, Gradient norm: 60.918071632921425\n",
      "0.2\n",
      "Epoch 46, Loss: 377.8759, Validation Loss: 202.5867, Gradient norm: 74.569544803417\n",
      "0.2\n",
      "Epoch 47, Loss: 462.6390, Validation Loss: 247.6914, Gradient norm: 91.28025334906792\n",
      "0.2\n",
      "Epoch 48, Loss: 566.4069, Validation Loss: 302.8747, Gradient norm: 111.73575852495996\n",
      "0.2\n",
      "Epoch 49, Loss: 693.4398, Validation Loss: 370.3920, Gradient norm: 136.7752528622472\n",
      "0.2\n",
      "Epoch 50, Loss: 848.9522, Validation Loss: 453.0041, Gradient norm: 167.42598826456447\n",
      "0.2\n",
      "Epoch 51, Loss: 1039.3277, Validation Loss: 554.0897, Gradient norm: 204.94541929012775\n",
      "0.2\n",
      "Epoch 52, Loss: 1272.3802, Validation Loss: 677.7845, Gradient norm: 250.87279055886205\n",
      "0.2\n",
      "Epoch 53, Loss: 1557.6752, Validation Loss: 829.1504, Gradient norm: 307.0922846716318\n",
      "0.2\n",
      "Epoch 54, Loss: 1906.9216, Validation Loss: 1014.3834, Gradient norm: 375.91032130172744\n",
      "0.2\n",
      "Epoch 55, Loss: 2334.4526, Validation Loss: 1241.0671, Gradient norm: 460.150178674358\n",
      "0.2\n",
      "Epoch 56, Loss: 2857.8136, Validation Loss: 1518.4842, Gradient norm: 563.2678193054729\n",
      "0.2\n",
      "Epoch 57, Loss: 3498.4820, Validation Loss: 1857.9970, Gradient norm: 689.4936717816007\n",
      "0.2\n",
      "Epoch 58, Loss: 4282.7486, Validation Loss: 2273.5130, Gradient norm: 844.0061852158716\n",
      "0.2\n",
      "Epoch 59, Loss: 5242.7958, Validation Loss: 2782.0557, Gradient norm: 1033.1442764978476\n",
      "0.2\n",
      "Epoch 60, Loss: 6418.0187, Validation Loss: 3404.4626, Gradient norm: 1264.667386042031\n",
      "0.2\n",
      "Epoch 61, Loss: 7856.6406, Validation Loss: 4166.2397, Gradient norm: 1548.0738108911298\n",
      "0.2\n",
      "Epoch 62, Loss: 9617.6920, Validation Loss: 5098.6077, Gradient norm: 1894.9903748742204\n",
      "0.2\n",
      "Epoch 63, Loss: 11773.4323, Validation Loss: 6239.7826, Gradient norm: 2319.6494221414578\n",
      "0.2\n",
      "Epoch 64, Loss: 14412.3143, Validation Loss: 7636.5429, Gradient norm: 2839.4727028618017\n",
      "0.2\n",
      "Epoch 65, Loss: 17642.6132, Validation Loss: 9346.1486, Gradient norm: 3475.7861051494865\n",
      "0.2\n",
      "Epoch 66, Loss: 21596.8689, Validation Loss: 11438.6896, Gradient norm: 4254.694555286311\n",
      "0.2\n",
      "Epoch 67, Loss: 26437.3233, Validation Loss: 13999.9611, Gradient norm: 5208.152979253723\n",
      "0.2\n",
      "Epoch 68, Loss: 32362.5769, Validation Loss: 17134.9822, Gradient norm: 6375.277262055797\n",
      "0.2\n",
      "Epoch 69, Loss: 39615.7365, Validation Loss: 20972.3043, Gradient norm: 7803.948987287555\n",
      "0.2\n",
      "Epoch 70, Loss: 48494.3885, Validation Loss: 25669.2841, Gradient norm: 9552.779791815321\n",
      "0.2\n",
      "Epoch 71, Loss: 59362.8086, Validation Loss: 31418.5385, Gradient norm: 11693.515923741725\n",
      "0.2\n",
      "Epoch 72, Loss: 72666.9057, Validation Loss: 38455.8459, Gradient norm: 14313.981651284044\n",
      "0.2\n",
      "Epoch 73, Loss: 88952.5164, Validation Loss: 47069.8182, Gradient norm: 17521.682276696698\n",
      "0.2\n",
      "Epoch 74, Loss: 108887.7979, Validation Loss: 57613.7403, Gradient norm: 21448.214569841006\n",
      "0.2\n",
      "Epoch 75, Loss: 133290.6399, Validation Loss: 70520.0627, Gradient norm: 26254.665560610047\n",
      "0.2\n",
      "Epoch 76, Loss: 163162.2194, Validation Loss: 86318.1412, Gradient norm: 32138.22117710159\n",
      "0.2\n",
      "Epoch 77, Loss: 199728.0742, Validation Loss: 105655.9534, Gradient norm: 39340.255850674876\n",
      "0.2\n",
      "Epoch 78, Loss: 244488.3819, Validation Loss: 129326.6798, Gradient norm: 48156.2349660864\n",
      "0.2\n",
      "Epoch 79, Loss: 299279.5053, Validation Loss: 158301.2431, Gradient norm: 58947.83640735114\n",
      "0.2\n",
      "Epoch 80, Loss: 366349.3305, Validation Loss: 193768.1389, Gradient norm: 72157.78848896647\n",
      "0.2\n",
      "Epoch 81, Loss: 448449.4872, Validation Loss: 237182.1916, Gradient norm: 88328.03300256687\n",
      "0.2\n",
      "Epoch 82, Loss: 548948.2367, Validation Loss: 290324.2373, Gradient norm: 108121.95852282131\n",
      "0.2\n",
      "Epoch 83, Loss: 671968.6557, Validation Loss: 355374.1799, Gradient norm: 132351.61609985103\n",
      "0.2\n",
      "Epoch 84, Loss: 822557.7878, Validation Loss: 435000.4206, Gradient norm: 162011.03386917466\n",
      "0.2\n",
      "Epoch 85, Loss: 1006893.7010, Validation Loss: 532469.3258, Gradient norm: 198316.99731990212\n",
      "0.2\n",
      "Epoch 86, Loss: 1232538.9453, Validation Loss: 651779.2281, Gradient norm: 242758.96824250335\n",
      "0.2\n",
      "Epoch 87, Loss: 1508750.8100, Validation Loss: 797824.4546, Gradient norm: 297160.1902942419\n",
      "0.2\n",
      "Epoch 88, Loss: 1846861.1075, Validation Loss: 976596.1147, Gradient norm: 363752.4880543187\n",
      "0.2\n",
      "Epoch 89, Loss: 2260741.0655, Validation Loss: 1195427.8821, Gradient norm: 445267.82821982604\n",
      "0.2\n",
      "Epoch 90, Loss: 2767370.3996, Validation Loss: 1463296.8558, Gradient norm: 545050.3992648819\n",
      "0.2\n",
      "Epoch 91, Loss: 3387533.9121, Validation Loss: 1791191.8425, Gradient norm: 667193.8076607245\n",
      "0.2\n",
      "Epoch 92, Loss: 4146674.1966, Validation Loss: 2192564.1695, Gradient norm: 816709.0191681231\n",
      "0.2\n",
      "Epoch 93, Loss: 5075935.4292, Validation Loss: 2683879.5220, Gradient norm: 999729.9350382187\n",
      "0.2\n",
      "Epoch 94, Loss: 6213441.0687, Validation Loss: 3285293.4452, Gradient norm: 1223765.036940014\n",
      "0.2\n",
      "Epoch 95, Loss: 7605857.8850, Validation Loss: 4021478.2224, Gradient norm: 1498005.4244144878\n",
      "0.2\n",
      "Epoch 96, Loss: 9310310.4785, Validation Loss: 4922635.0531, Gradient norm: 1833701.882173665\n",
      "0.2\n",
      "Epoch 97, Loss: 11396724.8354, Validation Loss: 6025733.0552, Gradient norm: 2244626.446530724\n",
      "0.2\n",
      "Epoch 98, Loss: 13950697.0636, Validation Loss: 7376025.9219, Gradient norm: 2747637.4068464753\n",
      "0.2\n",
      "Epoch 99, Loss: 17077004.9998, Validation Loss: 9028908.4540, Gradient norm: 3363370.9213265665\n",
      "0.2\n",
      "Epoch 100, Loss: 20903906.7527, Validation Loss: 11052189.1333, Gradient norm: 4117087.62089116\n",
      "0.2\n",
      "Epoch 101, Loss: 25588402.5313, Validation Loss: 13528871.9680, Gradient norm: 5039708.9332655985\n",
      "0.2\n",
      "Epoch 102, Loss: 31322675.6254, Validation Loss: 16560561.7381, Gradient norm: 6169085.642763036\n",
      "0.2\n",
      "Epoch 103, Loss: 38341976.7825, Validation Loss: 20271632.3396, Gradient norm: 7551550.728760973\n",
      "0.2\n",
      "Epoch 104, Loss: 46934275.4389, Validation Loss: 24814329.2371, Gradient norm: 9243820.188482478\n",
      "0.2\n",
      "Epoch 105, Loss: 57452073.7502, Validation Loss: 30375015.3514, Gradient norm: 11315319.825841429\n",
      "0.2\n",
      "Epoch 106, Loss: 70326868.0937, Validation Loss: 37181816.6231, Gradient norm: 13851033.463481849\n",
      "0.2\n",
      "Epoch 107, Loss: 86086851.3317, Validation Loss: 45513980.9124, Gradient norm: 16954989.426666778\n",
      "0.2\n",
      "Epoch 108, Loss: 105378582.0739, Validation Loss: 55713334.1867, Gradient norm: 20754528.332943447\n",
      "0.2\n",
      "Epoch 109, Loss: 128993509.9275, Validation Loss: 68198303.9876, Gradient norm: 25405527.274789583\n",
      "0.2\n",
      "Epoch 110, Loss: 157900444.9400, Validation Loss: 83481085.4949, Gradient norm: 31098794.71872059\n",
      "0.2\n",
      "Epoch 111, Loss: 193285303.3027, Validation Loss: 102188654.4287, Gradient norm: 38067898.47329129\n",
      "0.2\n",
      "Epoch 112, Loss: 236599759.8928, Validation Loss: 125088488.8495, Gradient norm: 46598747.87045872\n",
      "0.2\n",
      "Epoch 113, Loss: 289620803.6374, Validation Loss: 153120055.0985, Gradient norm: 57041323.27183973\n",
      "0.2\n",
      "Epoch 114, Loss: 354523638.9753, Validation Loss: 187433349.5987, Gradient norm: 69824034.10597248\n",
      "0.2\n",
      "Epoch 115, Loss: 433970924.2173, Validation Loss: 229436077.7011, Gradient norm: 85471294.47887309\n",
      "0.2\n",
      "Epoch 116, Loss: 531222007.8338, Validation Loss: 280851405.1029, Gradient norm: 104625037.40197632\n",
      "0.2\n",
      "Epoch 117, Loss: 650266644.1163, Validation Loss: 343788651.1022, Gradient norm: 128071050.26437496\n",
      "0.2\n",
      "Epoch 118, Loss: 795988673.9352, Validation Loss: 420829823.8983, Gradient norm: 156771211.96909806\n",
      "0.2\n",
      "Epoch 119, Loss: 974366385.6395, Validation Loss: 515135548.0720, Gradient norm: 191902954.27050474\n",
      "0.2\n",
      "Epoch 120, Loss: 1192717775.9583, Validation Loss: 630574729.9455, Gradient norm: 234907566.2246368\n",
      "0.2\n",
      "Epoch 121, Loss: 1460000772.7976, Validation Loss: 771883280.3787, Gradient norm: 287549323.4554311\n",
      "0.2\n",
      "Epoch 122, Loss: 1787180736.6541, Validation Loss: 944858406.6447, Gradient norm: 351987868.030639\n",
      "0.2\n",
      "Epoch 123, Loss: 2187680317.4876, Validation Loss: 1156596444.2587, Gradient norm: 430866808.35108167\n",
      "0.2\n",
      "Epoch 124, Loss: 2677930122.5515, Validation Loss: 1415783985.8740, Gradient norm: 527422173.8872212\n",
      "0.2\n",
      "Epoch 125, Loss: 3278042786.4753, Validation Loss: 1733054250.8823, Gradient norm: 645615174.1474099\n",
      "0.2\n",
      "Epoch 126, Loss: 4012638097.5043, Validation Loss: 2121423315.8754, Gradient norm: 790294708.3497447\n",
      "0.2\n",
      "Epoch 127, Loss: 4911853030.9194, Validation Loss: 2596824102.4358, Gradient norm: 967396292.7999657\n",
      "0.2\n",
      "Epoch 128, Loss: 6012578126.5277, Validation Loss: 3178760029.2458, Gradient norm: 1184185567.0238822\n",
      "0.2\n",
      "Epoch 129, Loss: 7359970932.9392, Validation Loss: 3891105144.7635, Gradient norm: 1449556368.5580883\n",
      "0.2\n",
      "Epoch 130, Loss: 9009308608.0838, Validation Loss: 4763083566.1191, Gradient norm: 1774395604.996372\n",
      "0.2\n",
      "Epoch 131, Loss: 11028255679.3978, Validation Loss: 5830468405.9688, Gradient norm: 2172029892.2644258\n",
      "0.2\n",
      "Epoch 132, Loss: 13499639999.1447, Validation Loss: 7137049373.5961, Gradient norm: 2658772282.576673\n",
      "0.2\n",
      "Epoch 133, Loss: 16524850779.1751, Validation Loss: 8736429258.9821, Gradient norm: 3254591511.734757\n",
      "0.2\n",
      "Epoch 134, Loss: 20227998110.4067, Validation Loss: 10694223001.0757, Gradient norm: 3983931221.815899\n",
      "0.2\n",
      "Epoch 135, Loss: 24761004612.4149, Validation Loss: 13090749557.6207, Gradient norm: 4876712768.079342\n",
      "0.2\n",
      "Epoch 136, Loss: 30309838099.4140, Validation Loss: 16024327011.2081, Gradient norm: 5969562750.510523\n",
      "0.2\n",
      "Epoch 137, Loss: 37102140959.4062, Validation Loss: 19615306094.1497, Gradient norm: 7307315629.810536\n",
      "0.2\n",
      "Epoch 138, Loss: 45416569243.8063, Validation Loss: 24011007608.5961, Gradient norm: 8944853073.050749\n",
      "0.2\n",
      "Epoch 139, Loss: 55594224606.1754, Validation Loss: 29391766300.8634, Gradient norm: 10949355488.636507\n",
      "0.2\n",
      "Epoch 140, Loss: 68052648088.3889, Validation Loss: 35978329141.5112, Gradient norm: 13403058120.399647\n",
      "0.2\n",
      "Epoch 141, Loss: 83302949853.0333, Validation Loss: 44040911527.5683, Gradient norm: 16406624770.311592\n",
      "0.2\n",
      "Epoch 142, Loss: 101970777613.8558, Validation Loss: 53910282939.9980, Gradient norm: 20083277557.687397\n",
      "0.2\n",
      "Epoch 143, Loss: 124821983999.6955, Validation Loss: 65991336848.4347, Gradient norm: 24583852139.348343\n",
      "0.2\n",
      "Epoch 144, Loss: 152794045862.3220, Validation Loss: 80779701572.1254, Gradient norm: 30092985782.49269\n",
      "0.2\n",
      "Epoch 145, Loss: 187034524513.6294, Validation Loss: 98882073562.0461, Gradient norm: 36836692157.607216\n",
      "0.2\n",
      "Epoch 146, Loss: 228948144733.6358, Validation Loss: 121041107282.4760, Gradient norm: 45091633609.30944\n",
      "0.2\n",
      "Epoch 147, Loss: 280254423978.0939, Validation Loss: 148165882806.0165, Gradient norm: 55196471302.494965\n",
      "0.2\n",
      "Epoch 148, Loss: 343058216039.2645, Validation Loss: 181369201063.2145, Gradient norm: 67565758886.54764\n",
      "0.2\n",
      "Epoch 149, Loss: 419936063232.2706, Validation Loss: 222013236794.2897, Gradient norm: 82706949668.87744\n",
      "0.2\n",
      "Epoch 150, Loss: 514041899728.4139, Validation Loss: 271765422127.4127, Gradient norm: 101241215021.5952\n",
      "0.2\n",
      "Epoch 151, Loss: 629236442542.7754, Validation Loss: 332666853422.1505, Gradient norm: 123928928101.98587\n",
      "0.2\n",
      "Epoch 152, Loss: 770245578475.7292, Validation Loss: 407216027786.9697, Gradient norm: 151700858363.17908\n",
      "0.2\n",
      "Epoch 153, Loss: 942854244874.7136, Validation Loss: 498471344583.6346, Gradient norm: 185696356618.10068\n",
      "0.2\n",
      "Epoch 154, Loss: 1154143758225.9919, Validation Loss: 610176577069.9072, Gradient norm: 227310097209.09152\n",
      "0.2\n",
      "Epoch 155, Loss: 1412782327044.9148, Validation Loss: 746914461687.9700, Gradient norm: 278249294893.1132\n",
      "0.2\n",
      "Epoch 156, Loss: 1729380667433.1497, Validation Loss: 914294706039.8763, Gradient norm: 340603743780.4502\n",
      "0.2\n",
      "Epoch 157, Loss: 2116927310525.5500, Validation Loss: 1119184128627.1011, Gradient norm: 416931551692.9629\n",
      "0.2\n",
      "Epoch 158, Loss: 2591321460430.2705, Validation Loss: 1369988371898.0671, Gradient norm: 510364087216.70496\n",
      "0.2\n",
      "Epoch 159, Loss: 3172025263300.6270, Validation Loss: 1676996745956.1753, Gradient norm: 624734444929.6018\n",
      "0.2\n",
      "Epoch 160, Loss: 3882862247050.5615, Validation Loss: 2052804350232.9668, Gradient norm: 764734699124.2646\n",
      "0.2\n",
      "Epoch 161, Loss: 4752994687915.0898, Validation Loss: 2512828790780.0845, Gradient norm: 936108397401.6836\n",
      "0.2\n",
      "Epoch 162, Loss: 5818120000578.3887, Validation Loss: 3075942691644.0610, Gradient norm: 1145886191236.5706\n",
      "0.2\n",
      "Epoch 163, Loss: 7121935234092.1904, Validation Loss: 3765247949270.9624, Gradient norm: 1402674270320.8826\n",
      "0.2\n",
      "Epoch 164, Loss: 8717929754918.4922, Validation Loss: 4609023493933.3340, Gradient norm: 1717007433781.023\n",
      "0.2\n",
      "Epoch 165, Loss: 10671579662394.3262, Validation Loss: 5641885440343.5371, Gradient norm: 2101781283109.2107\n",
      "0.2\n",
      "Epoch 166, Loss: 13063033963095.8086, Validation Loss: 6906207222940.3525, Gradient norm: 2572781267638.69\n",
      "0.2\n",
      "Epoch 167, Loss: 15990402705117.9629, Validation Loss: 8453857977275.9277, Gradient norm: 3149330286793.979\n",
      "0.2\n",
      "Epoch 168, Loss: 19573781968852.3047, Validation Loss: 10348330485060.9180, Gradient norm: 3855081417170.33\n",
      "0.2\n",
      "Epoch 169, Loss: 23960180840577.5078, Validation Loss: 12667345982378.2070, Gradient norm: 4718988286281.392\n",
      "0.2\n",
      "Epoch 170, Loss: 29329552499263.0547, Validation Loss: 15506042694013.5820, Gradient norm: 5776492902815.672\n",
      "0.2\n",
      "Epoch 171, Loss: 35902176843523.3828, Validation Loss: 18980878904370.8086, Gradient norm: 7070979674453.49\n",
      "0.2\n",
      "Epoch 172, Loss: 43947697532953.5156, Validation Loss: 23234410689491.5117, Gradient norm: 8655555264711.43\n",
      "0.2\n",
      "Epoch 173, Loss: 53796184190866.7031, Validation Loss: 28441140317904.3242, Gradient norm: 10595227307913.895\n",
      "0.2\n",
      "Epoch 174, Loss: 65851673598238.5781, Validation Loss: 34814675252500.8750, Gradient norm: 12969571364652.014\n",
      "0.2\n",
      "Epoch 175, Loss: 80608745409934.8125, Validation Loss: 42616491453391.0469, Gradient norm: 15875995530285.645\n",
      "0.2\n",
      "Epoch 176, Loss: 98672812416382.1562, Validation Loss: 52166660498563.7812, Gradient norm: 19433736627919.2\n",
      "0.2\n",
      "Epoch 177, Loss: 120784957764054.7188, Validation Loss: 63856980605326.5000, Gradient norm: 23788751930729.04\n",
      "0.2\n",
      "Epoch 178, Loss: 147852338088341.8438, Validation Loss: 78167050256163.8125, Gradient norm: 29119707097849.94\n",
      "0.2\n",
      "Epoch 179, Loss: 180985399855394.9375, Validation Loss: 95683943853783.9219, Gradient norm: 35645305980480.04\n",
      "0.2\n",
      "Epoch 180, Loss: 221543435723260.5625, Validation Loss: 117126296604324.6562, Gradient norm: 43633263005446.22\n",
      "0.2\n",
      "Epoch 181, Loss: 271190349884110.5625, Validation Loss: 143373786717447.5625, Gradient norm: 53411286230647.84\n",
      "0.2\n",
      "Epoch 182, Loss: 331962920175541.0625, Validation Loss: 175503224438406.3125, Gradient norm: 65380521655144.48\n",
      "0.2\n",
      "Epoch 183, Loss: 406354357432182.8750, Validation Loss: 214832728474211.2812, Gradient norm: 80032010340279.1\n",
      "0.2\n",
      "Epoch 184, Loss: 497416590122207.5000, Validation Loss: 262975802163503.5625, Gradient norm: 97966833499600.23\n",
      "0.2\n",
      "Epoch 185, Loss: 608885470523102.2500, Validation Loss: 321907527879365.0000, Gradient norm: 119920772015245.58\n",
      "0.2\n",
      "Epoch 186, Loss: 745334039053319.2500, Validation Loss: 394045595308013.5000, Gradient norm: 146794492043995.56\n",
      "0.2\n",
      "Epoch 187, Loss: 912360134469700.0000, Validation Loss: 482349487810032.1875, Gradient norm: 179690495085498.75\n",
      "0.2\n",
      "Epoch 188, Loss: 1116816046688835.2500, Validation Loss: 590441896010935.8750, Gradient norm: 219958348399028.7\n",
      "0.2\n",
      "Epoch 189, Loss: 1367089633800344.0000, Validation Loss: 722757339645864.3750, Gradient norm: 269250051358631.56\n",
      "0.2\n",
      "Epoch 190, Loss: 1673448436172168.5000, Validation Loss: 884724094909043.5000, Gradient norm: 329587809166082.75\n",
      "0.2\n",
      "Epoch 191, Loss: 2048460905020437.2500, Validation Loss: 1082986890925825.2500, Gradient norm: 403446994356221.1\n",
      "0.2\n",
      "Epoch 192, Loss: 2507512026457815.0000, Validation Loss: 1325679511529207.0000, Gradient norm: 493857699612449.8\n",
      "0.2\n",
      "Epoch 193, Loss: 3069434494633824.0000, Validation Loss: 1622758485901084.0000, Gradient norm: 604529048123617.6\n",
      "0.2\n",
      "Epoch 194, Loss: 3757281328012819.0000, Validation Loss: 1986411557825401.2500, Gradient norm: 740001361347680.8\n",
      "0.2\n",
      "Epoch 195, Loss: 4599271625577563.0000, Validation Loss: 2431557691112754.5000, Gradient norm: 905832426905058.2\n",
      "0.2\n",
      "Epoch 196, Loss: 5629948262857749.0000, Validation Loss: 2976459124051765.5000, Gradient norm: 1108825508291450.1\n",
      "0.2\n",
      "Epoch 197, Loss: 6891595022570479.0000, Validation Loss: 3643470582583581.5000, Gradient norm: 1357308450569144.5\n",
      "0.2\n",
      "Epoch 198, Loss: 8435971298033434.0000, Validation Loss: 4459956388868937.0000, Gradient norm: 1661475332421894.2\n",
      "0.2\n",
      "Epoch 199, Loss: 10326435536018914.0000, Validation Loss: 5459413089870226.0000, Gradient norm: 2033804680939632.2\n",
      "0.2\n",
      "Epoch 200, Loss: 12640544533855614.0000, Validation Loss: 6682843662084258.0000, Gradient norm: 2489571406505611.5\n",
      "0.2\n",
      "Epoch 201, Loss: 15473235227631946.0000, Validation Loss: 8180439669539710.0000, Gradient norm: 3047473460050664.0\n",
      "0.2\n",
      "Epoch 202, Loss: 18940719505206692.0000, Validation Loss: 10013640386037796.0000, Gradient norm: 3730398921454767.5\n",
      "0.2\n",
      "Epoch 203, Loss: 23185251829764940.0000, Validation Loss: 12257653357672756.0000, Gradient norm: 4566364989101342.0\n",
      "0.2\n",
      "Epoch 204, Loss: 28380965266941676.0000, Validation Loss: 15004539812378880.0000, Gradient norm: 5589667392880018.0\n",
      "0.2\n",
      "Epoch 205, Loss: 34741015340075128.0000, Validation Loss: 18366991496249928.0000, Gradient norm: 6842287385611501.0\n",
      "0.2\n",
      "Epoch 206, Loss: 42526324792148688.0000, Validation Loss: 22482953882343704.0000, Gradient norm: 8375614035091343.0\n",
      "0.2\n",
      "Epoch 207, Loss: 52056288010601792.0000, Validation Loss: 27521285420340712.0000, Gradient norm: 1.0252552474240956e+16\n",
      "0.2\n",
      "Epoch 208, Loss: 63721874266880048.0000, Validation Loss: 33688684999276556.0000, Gradient norm: 1.2550104600888332e+16\n",
      "0.2\n",
      "Epoch 209, Loss: 78001667334606160.0000, Validation Loss: 41238171824346160.0000, Gradient norm: 1.5362528101071628e+16\n",
      "0.2\n",
      "Epoch 210, Loss: 95481499515965712.0000, Validation Loss: 50479465596977288.0000, Gradient norm: 1.8805203395636252e+16\n",
      "0.2\n",
      "Epoch 211, Loss: 116878485567454304.0000, Validation Loss: 61791692847816832.0000, Gradient norm: 2.3019367152635596e+16\n",
      "0.2\n",
      "Epoch 212, Loss: 143070442523170128.0000, Validation Loss: 75638940703314688.0000, Gradient norm: 2.817790655913883e+16\n",
      "0.2\n",
      "Epoch 213, Loss: 175131902371715008.0000, Validation Loss: 92589296183308656.0000, Gradient norm: 3.44924520639852e+16\n",
      "0.2\n",
      "Epoch 214, Loss: 214378195016335168.0000, Validation Loss: 113338152121849760.0000, Gradient norm: 4.222205957313951e+16\n",
      "0.2\n",
      "Epoch 215, Loss: 262419410033447168.0000, Validation Loss: 138736735842857008.0000, Gradient norm: 5.1683838287018184e+16\n",
      "0.2\n",
      "Epoch 216, Loss: 321226451025019008.0000, Validation Loss: 169827030987096256.0000, Gradient norm: 6.32659601896353e+16\n",
      "0.2\n",
      "Epoch 217, Loss: 393211892462153088.0000, Validation Loss: 207884525167706880.0000, Gradient norm: 7.744358490731267e+16\n",
      "0.2\n",
      "Epoch 218, Loss: 481328956193346944.0000, Validation Loss: 254470537188193632.0000, Gradient norm: 9.479835325851437e+16\n",
      "0.2\n",
      "Epoch 219, Loss: 589192668154963712.0000, Validation Loss: 311496270560897664.0000, Gradient norm: 1.1604224922285987e+17\n",
      "0.2\n",
      "Epoch 220, Loss: 721228165770127360.0000, Validation Loss: 381301221138547904.0000, Gradient norm: 1.4204680927293269e+17\n",
      "0.2\n",
      "Epoch 221, Loss: 882852240386465024.0000, Validation Loss: 466749155552794432.0000, Gradient norm: 1.738788773894785e+17\n",
      "0.2\n",
      "Epoch 222, Loss: 1080695562579400064.0000, Validation Loss: 571345598000653696.0000, Gradient norm: 2.1284437261897984e+17\n",
      "0.2\n",
      "Epoch 223, Loss: 1322874707173078272.0000, Validation Loss: 699381645305468032.0000, Gradient norm: 2.605418647492863e+17\n",
      "0.2\n",
      "Epoch 224, Loss: 1619325137877626368.0000, Validation Loss: 856110010303444736.0000, Gradient norm: 3.189281560596079e+17\n",
      "0.2\n",
      "Epoch 225, Loss: 1982208812325915392.0000, Validation Loss: 1047960515782449920.0000, Gradient norm: 3.9039855965358874e+17\n",
      "0.2\n",
      "Epoch 226, Loss: 2426413129614670848.0000, Validation Loss: 1282803879669112832.0000, Gradient norm: 4.778851678153844e+17\n",
      "0.2\n",
      "Epoch 227, Loss: 2970161689805300736.0000, Validation Loss: 1570274613321582336.0000, Gradient norm: 5.84977141874143e+17\n",
      "0.2\n",
      "Epoch 228, Loss: 3635761921955113984.0000, Validation Loss: 1922166279916128256.0000, Gradient norm: 7.160679585005194e+17\n",
      "0.2\n",
      "Epoch 229, Loss: 4450520252317432832.0000, Validation Loss: 2352915328507850752.0000, Gradient norm: 8.765356532536445e+17\n",
      "0.2\n",
      "Epoch 230, Loss: 5447862357729011712.0000, Validation Loss: 2880193353186304000.0000, Gradient norm: 1.0729634559179014e+18\n",
      "0.2\n",
      "Epoch 231, Loss: 6668704462877381632.0000, Validation Loss: 3525632074915149312.0000, Gradient norm: 1.313409869252799e+18\n",
      "0.2\n",
      "Epoch 232, Loss: 8163131939282681856.0000, Validation Loss: 4315710788628292608.0000, Gradient norm: 1.6077392712083633e+18\n",
      "0.2\n",
      "Epoch 233, Loss: 9992454070962876416.0000, Validation Loss: 5282842683335293952.0000, Gradient norm: 1.9680266036497155e+18\n",
      "0.2\n",
      "Epoch 234, Loss: 12231719284089323520.0000, Validation Loss: 6466704601806764032.0000, Gradient norm: 2.409052750053197e+18\n",
      "0.2\n",
      "Epoch 235, Loss: 14972794028597219328.0000, Validation Loss: 7915864793583951872.0000, Gradient norm: 2.948910925175599e+18\n",
      "0.2\n",
      "Epoch 236, Loss: 18328131623686422528.0000, Validation Loss: 9689775440311941120.0000, Gradient norm: 3.6097489539936287e+18\n",
      "0.2\n",
      "Epoch 237, Loss: 22435385685100060672.0000, Validation Loss: 11861211697277257728.0000, Gradient norm: 4.4186778921042463e+18\n",
      "0.2\n",
      "Epoch 238, Loss: 27463057401259991040.0000, Validation Loss: 14519257313476644864.0000, Gradient norm: 5.40888426397901e+18\n",
      "0.2\n",
      "Epoch 239, Loss: 33617408339261968384.0000, Validation Loss: 17772959316073017344.0000, Gradient norm: 6.620991548942155e+18\n",
      "0.2\n",
      "Epoch 240, Loss: 41150922380432048128.0000, Validation Loss: 21755801693638815744.0000, Gradient norm: 8.104726770196155e+18\n",
      "0.2\n",
      "Epoch 241, Loss: 50372663938597060608.0000, Validation Loss: 26631181612229570560.0000, Gradient norm: 9.920960559152067e+18\n",
      "0.2\n",
      "Epoch 242, Loss: 61660957409724268544.0000, Validation Loss: 32599112827506360320.0000, Gradient norm: 1.21442043892454e+19\n",
      "0.2\n",
      "Epoch 243, Loss: 75478908030717902848.0000, Validation Loss: 39904431302169067520.0000, Gradient norm: 1.4865667428918022e+19\n",
      "0.2\n",
      "Epoch 244, Loss: 92393400894726340608.0000, Validation Loss: 48846839666334580736.0000, Gradient norm: 1.8196998421971214e+19\n",
      "0.2\n",
      "Epoch 245, Loss: 113098357562606845952.0000, Validation Loss: 59793202597513945088.0000, Gradient norm: 2.2274866106924835e+19\n",
      "0.2\n",
      "Epoch 246, Loss: 138443204379208744960.0000, Validation Loss: 73192597541416468480.0000, Gradient norm: 2.7266566088303284e+19\n",
      "0.2\n",
      "Epoch 247, Loss: 169467720414709350400.0000, Validation Loss: 89594738233398394880.0000, Gradient norm: 3.337688418323113e+19\n",
      "0.2\n",
      "Epoch 248, Loss: 207444694677048590336.0000, Validation Loss: 109672526850414870528.0000, Gradient norm: 4.085649781395507e+19\n",
      "0.2\n",
      "Epoch 249, Loss: 253932142618928414720.0000, Validation Loss: 134249660001497464832.0000, Gradient norm: 5.00122601156511e+19\n",
      "0.2\n",
      "Epoch 250, Loss: 310837224135442235392.0000, Validation Loss: 164334421099846434816.0000, Gradient norm: 6.1219788667770225e+19\n",
      "0.2\n",
      "Epoch 251, Loss: 380494485305156960256.0000, Validation Loss: 201161045457574789120.0000, Gradient norm: 7.493887530496881e+19\n",
      "0.2\n",
      "Epoch 252, Loss: 465761633762851618816.0000, Validation Loss: 246240355117100171264.0000, Gradient norm: 9.173234919920894e+19\n",
      "0.2\n",
      "Epoch 253, Loss: 570136776914007752704.0000, Validation Loss: 301421740726586114048.0000, Gradient norm: 1.1228916707597897e+20\n",
      "0.2\n",
      "Epoch 254, Loss: 697901932719932440576.0000, Validation Loss: 368969033282330099712.0000, Gradient norm: 1.3745267784688842e+20\n",
      "0.2\n",
      "Epoch 255, Loss: 854298700621574701056.0000, Validation Loss: 451653378396475490304.0000, Gradient norm: 1.6825522122269023e+20\n",
      "0.2\n",
      "Epoch 256, Loss: 1045743299548332556288.0000, Validation Loss: 552866923281540055040.0000, Gradient norm: 2.0596047972402102e+20\n",
      "0.2\n",
      "Epoch 257, Loss: 1280089795003256143872.0000, Validation Loss: 676761980490487300096.0000, Gradient norm: 2.5211532159233986e+20\n",
      "0.2\n",
      "Epoch 258, Loss: 1566952314185710043136.0000, Validation Loss: 828421377641726738432.0000, Gradient norm: 3.0861326147025764e+20\n",
      "0.2\n",
      "Epoch 259, Loss: 1918099468112453173248.0000, Validation Loss: 1014066981771744116736.0000, Gradient norm: 3.77772142342512e+20\n",
      "0.2\n",
      "Epoch 260, Loss: 2347937162009389563904.0000, Validation Loss: 1241314953082293714944.0000, Gradient norm: 4.624292256598468e+20\n",
      "0.2\n",
      "Epoch 261, Loss: 2874099601398492037120.0000, Validation Loss: 1519488199934906204160.0000, Gradient norm: 5.66057590743375e+20\n",
      "0.2\n",
      "Epoch 262, Loss: 3518172740061546676224.0000, Validation Loss: 1859998853641824370688.0000, Gradient norm: 6.929086187858921e+20\n",
      "0.2\n",
      "Epoch 263, Loss: 4306579849525522857984.0000, Validation Loss: 2276816454183218315264.0000, Gradient norm: 8.481864068941329e+20\n",
      "0.2\n",
      "Epoch 264, Loss: 5271665540792834850816.0000, Validation Loss: 2787041054294046932992.0000, Gradient norm: 1.0382612675543583e+21\n",
      "0.2\n",
      "Epoch 265, Loss: 6453022710595802103808.0000, Validation Loss: 3411604753667882745856.0000, Gradient norm: 1.2709310723935384e+21\n",
      "0.2\n",
      "Epoch 266, Loss: 7899116850497743486976.0000, Validation Loss: 4176130443904702480384.0000, Gradient norm: 1.5557411619333294e+21\n",
      "0.2\n",
      "Epoch 267, Loss: 9669274356552841560064.0000, Validation Loss: 5111982994442127671296.0000, Gradient norm: 1.9043759457194384e+21\n",
      "0.2\n",
      "Epoch 268, Loss: 11836116410456514494464.0000, Validation Loss: 6257556004652052381696.0000, Gradient norm: 2.3311382583256657e+21\n",
      "0.2\n",
      "Epoch 269, Loss: 14488538282806762012672.0000, Validation Loss: 7659846911449089703936.0000, Gradient norm: 2.853536136939955e+21\n",
      "0.2\n",
      "Epoch 270, Loss: 17735356285183739297792.0000, Validation Loss: 9376385071618668363776.0000, Gradient norm: 3.4930010932387324e+21\n",
      "0.2\n",
      "Epoch 271, Loss: 21709771988225109262336.0000, Validation Loss: 11477591918954279862272.0000, Gradient norm: 4.2757673468439235e+21\n",
      "0.2\n",
      "Epoch 272, Loss: 26574836851428919607296.0000, Validation Loss: 14049670022277028118528.0000, Gradient norm: 5.233948091148563e+21\n",
      "0.2\n",
      "Epoch 273, Loss: 32530141452572685238272.0000, Validation Loss: 17198139568709905154048.0000, Gradient norm: 6.406852945602429e+21\n",
      "0.2\n",
      "Epoch 274, Loss: 39820003744161653063680.0000, Validation Loss: 21052167357372041265152.0000, Gradient norm: 7.842600643287394e+21\n",
      "0.2\n",
      "Epoch 275, Loss: 48743492262301374873600.0000, Validation Loss: 25769865901608779382784.0000, Gradient norm: 9.600093114718512e+21\n",
      "0.2\n",
      "Epoch 276, Loss: 59666695492799473647616.0000, Validation Loss: 31544780036833426800640.0000, Gradient norm: 1.175143195518292e+22\n",
      "0.2\n",
      "Epoch 277, Loss: 73037740748499354386432.0000, Validation Loss: 38613827148789823045632.0000, Gradient norm: 1.4384876411830894e+22\n",
      "0.2\n",
      "Epoch 278, Loss: 89405178711275477139456.0000, Validation Loss: 47267016772208417570816.0000, Gradient norm: 1.7608464242724508e+22\n",
      "0.2\n",
      "Epoch 279, Loss: 109440487869407838601216.0000, Validation Loss: 57859348308971457871872.0000, Gradient norm: 2.1554443994548293e+22\n",
      "0.2\n",
      "Epoch 280, Loss: 133965622100853392408576.0000, Validation Loss: 70825374972834159263744.0000, Gradient norm: 2.6384700534351276e+22\n",
      "0.2\n",
      "Epoch 281, Loss: 163986731549333131362304.0000, Validation Loss: 86697031450400821084160.0000, Gradient norm: 3.229739641920122e+22\n",
      "0.2\n",
      "Epoch 282, Loss: 200735440201129924755456.0000, Validation Loss: 106125456662881365917696.0000, Gradient norm: 3.953510156770399e+22\n",
      "0.2\n",
      "Epoch 283, Loss: 245719373586144383991808.0000, Validation Loss: 129907706913223220396032.0000, Gradient norm: 4.839474475532122e+22\n",
      "0.2\n",
      "Epoch 284, Loss: 300784009515561855746048.0000, Validation Loss: 159019455332573132095488.0000, Gradient norm: 5.9239795196223816e+22\n",
      "0.2\n",
      "Epoch 285, Loss: 368188389299064124997632.0000, Validation Loss: 194655019129541333352448.0000, Gradient norm: 7.251517396431098e+22\n",
      "0.2\n",
      "Epoch 286, Loss: 450697795514377078571008.0000, Validation Loss: 238276356770798577385472.0000, Gradient norm: 8.876550699840172e+22\n",
      "0.2\n",
      "Epoch 287, Loss: 551697198459254827122688.0000, Validation Loss: 291673045215347635912704.0000, Gradient norm: 1.0865746852598278e+23\n",
      "0.2\n",
      "Epoch 288, Loss: 675330125456717096419328.0000, Validation Loss: 357035697784432621518848.0000, Gradient norm: 1.3300713155040673e+23\n",
      "0.2\n",
      "Epoch 289, Loss: 826668650163660379914240.0000, Validation Loss: 437045834654691153149952.0000, Gradient norm: 1.628134474625353e+23\n",
      "0.2\n",
      "Epoch 290, Loss: 1011921475739359075368960.0000, Validation Loss: 534985892935394129870848.0000, Gradient norm: 1.9929922828679092e+23\n",
      "0.2\n",
      "Epoch 291, Loss: 1238688648541102848081920.0000, Validation Loss: 654873889522400528171008.0000, Gradient norm: 2.4396131286913703e+23\n",
      "0.2\n",
      "Epoch 292, Loss: 1516273352043954190680064.0000, Validation Loss: 801628261308168696496128.0000, Gradient norm: 2.986319750881727e+23\n",
      "0.2\n",
      "Epoch 293, Loss: 1856063572412982762668032.0000, Validation Loss: 981269645361204747567104.0000, Gradient norm: 3.6555409337750426e+23\n",
      "0.2\n",
      "Epoch 294, Loss: 2271999293659404520390656.0000, Validation Loss: 1201167877160388660297728.0000, Gradient norm: 4.4747316540900945e+23\n",
      "0.2\n",
      "Epoch 295, Loss: 2781144389185968963321856.0000, Validation Loss: 1470344340052322352627712.0000, Gradient norm: 5.477499428638065e+23\n",
      "0.2\n",
      "Epoch 296, Loss: 3404386671724076715737088.0000, Validation Loss: 1799842069898466913419264.0000, Gradient norm: 6.704983071623158e+23\n",
      "0.2\n",
      "Epoch 297, Loss: 4167294821397187103031296.0000, Validation Loss: 2203178798553491878969344.0000, Gradient norm: 8.207540425418392e+23\n",
      "0.2\n",
      "Epoch 298, Loss: 5101167347611841622704128.0000, Validation Loss: 2696901522403818651779072.0000, Gradient norm: 1.0046814304419945e+24\n",
      "0.2\n",
      "Epoch 299, Loss: 6244316618716396835045376.0000, Validation Loss: 3301265347287903927009280.0000, Gradient norm: 1.2298261407875027e+24\n",
      "0.2\n",
      "Epoch 300, Loss: 7643640637085153920811008.0000, Validation Loss: 4041064459591370481336320.0000, Gradient norm: 1.5054247951003675e+24\n",
      "0.2\n",
      "Epoch 301, Loss: 9356547042118054914818048.0000, Validation Loss: 4946649314326794813308928.0000, Gradient norm: 1.8427839013503034e+24\n",
      "0.2\n",
      "Epoch 302, Loss: 11453308273889859373891584.0000, Validation Loss: 6055171770609191597637632.0000, Gradient norm: 2.25574370644629e+24\n",
      "0.2\n",
      "Epoch 303, Loss: 14019944518662818709372928.0000, Validation Loss: 7412109256540728923783168.0000, Gradient norm: 2.7612459960408373e+24\n",
      "0.2\n",
      "Epoch 304, Loss: 17161752709868065451409408.0000, Validation Loss: 9073130492773702607831040.0000, Gradient norm: 3.3800291357847584e+24\n",
      "0.2\n",
      "Epoch 305, Loss: 21007626362757882973257728.0000, Validation Loss: 11106379316556377322684416.0000, Gradient norm: 4.137478868284391e+24\n",
      "0.2\n",
      "Epoch 306, Loss: 25715343465092530416123904.0000, Validation Loss: 13595270300749539456319488.0000, Gradient norm: 5.064669769932431e+24\n",
      "0.2\n",
      "Epoch 307, Loss: 31478039360981106272763904.0000, Validation Loss: 16641910858826219547262976.0000, Gradient norm: 6.199640093655286e+24\n",
      "0.2\n",
      "Epoch 308, Loss: 38532130179654618479329280.0000, Validation Loss: 20371290228620852186841088.0000, Gradient norm: 7.588952298339268e+24\n",
      "0.2\n",
      "Epoch 309, Loss: 47167011869940501998206976.0000, Validation Loss: 24936407188998321346707456.0000, Gradient norm: 9.289603286069572e+24\n",
      "0.2\n",
      "Epoch 310, Loss: 57736932745903283921485824.0000, Validation Loss: 30524546875380960323436544.0000, Gradient norm: 1.1371362715172082e+25\n",
      "0.2\n",
      "Epoch 311, Loss: 70675526617988439079911424.0000, Validation Loss: 37364964202156894455857152.0000, Gradient norm: 1.3919635318971282e+25\n",
      "0.2\n",
      "Epoch 312, Loss: 86513602735233895669694464.0000, Validation Loss: 45738289106414209727463424.0000, Gradient norm: 1.7038964657651502e+25\n",
      "0.2\n",
      "Epoch 313, Loss: 105900922375651263332220928.0000, Validation Loss: 55988039465622389796110336.0000, Gradient norm: 2.0857322045571586e+25\n",
      "0.2\n",
      "Epoch 314, Loss: 129632855475180064234012672.0000, Validation Loss: 68534714009765982492426240.0000, Gradient norm: 2.5531356608415364e+25\n",
      "0.2\n",
      "Epoch 315, Loss: 158683010890494815819005952.0000, Validation Loss: 83893043393392161222295552.0000, Gradient norm: 3.125282185516597e+25\n",
      "0.2\n",
      "Epoch 316, Loss: 194243178960861490449481728.0000, Validation Loss: 102693107157384280091394048.0000, Gradient norm: 3.8256442416726046e+25\n",
      "0.2\n",
      "Epoch 317, Loss: 237772225023248075897962496.0000, Validation Loss: 125706182909424172443631616.0000, Gradient norm: 4.682954368622417e+25\n",
      "0.2\n",
      "Epoch 318, Loss: 291055939750129508015931392.0000, Validation Loss: 153876388192635739768356864.0000, Gradient norm: 5.7323839419558105e+25\n",
      "0.2\n",
      "Epoch 319, Loss: 356280301685986149812666368.0000, Validation Loss: 188359413158472428464111616.0000, Gradient norm: 7.016986088561728e+25\n",
      "0.2\n",
      "Epoch 320, Loss: 436121157597509072392814592.0000, Validation Loss: 230569933062037523264438272.0000, Gradient norm: 8.589461952590258e+25\n",
      "0.2\n",
      "Epoch 321, Loss: 533853999797689839572221952.0000, Validation Loss: 282239645690047128418648064.0000, Gradient norm: 1.0514322773884555e+26\n",
      "0.2\n",
      "Epoch 322, Loss: 653488344087664899662020608.0000, Validation Loss: 345488314722328108079251456.0000, Gradient norm: 1.2870536478724299e+26\n",
      "0.2\n",
      "Epoch 323, Loss: 799932221207058520081432576.0000, Validation Loss: 422910733599619374674608128.0000, Gradient norm: 1.5754767359968783e+26\n",
      "0.2\n",
      "Epoch 324, Loss: 979193530098245916227010560.0000, Validation Loss: 517683177613443350594060288.0000, Gradient norm: 1.928534175533763e+26\n",
      "0.2\n",
      "Epoch 325, Loss: 1198626513555676803178168320.0000, Validation Loss: 633693711443301043747684352.0000, Gradient norm: 2.3607102416833512e+26\n",
      "0.2\n",
      "Epoch 326, Loss: 1467233467989200325178294272.0000, Validation Loss: 775701698042501298074419200.0000, Gradient norm: 2.8897350723101588e+26\n",
      "0.2\n",
      "Epoch 327, Loss: 1796034065024558130861703168.0000, Validation Loss: 949533052767018502598950912.0000, Gradient norm: 3.537312051556508e+26\n",
      "0.2\n",
      "Epoch 328, Loss: 2198517436457755724530843648.0000, Validation Loss: 1162319253099860971929731072.0000, Gradient norm: 4.330008196939628e+26\n",
      "0.2\n",
      "Epoch 329, Loss: 2691195569468605348813209600.0000, Validation Loss: 1422789909408347396625137664.0000, Gradient norm: 5.300344078299322e+26\n",
      "0.2\n",
      "Epoch 330, Loss: 3294280715279019983583051776.0000, Validation Loss: 1741630899527303345695883264.0000, Gradient norm: 6.488127982810466e+26\n",
      "0.2\n",
      "Epoch 331, Loss: 4032514602126112435933806592.0000, Validation Loss: 2131922759734528896334299136.0000, Gradient norm: 7.94208906053419e+26\n",
      "0.2\n",
      "Epoch 332, Loss: 4936183471232516183241523200.0000, Validation Loss: 2609677317224720377640386560.0000, Gradient norm: 9.721876450737623e+26\n",
      "0.2\n",
      "Epoch 333, Loss: 6042360577894087021933101056.0000, Validation Loss: 3194494579571568535815585792.0000, Gradient norm: 1.190050640367027e+27\n",
      "0.2\n",
      "Epoch 334, Loss: 7396427131622066053453971456.0000, Validation Loss: 3910366830242637726263279616.0000, Gradient norm: 1.4567357791617672e+27\n",
      "0.2\n",
      "Epoch 335, Loss: 9053934072312815697524686848.0000, Validation Loss: 4786662918399005125142118400.0000, Gradient norm: 1.783183890086866e+27\n",
      "0.2\n",
      "Epoch 336, Loss: 11082881062306862488788926464.0000, Validation Loss: 5859333123730076546447179776.0000, Gradient norm: 2.1827875935710263e+27\n",
      "0.2\n",
      "Epoch 337, Loss: 13566506190591608818447155200.0000, Validation Loss: 7172384026223308202607378432.0000, Gradient norm: 2.6719407376518476e+27\n",
      "0.2\n",
      "Epoch 338, Loss: 16606700837503269833879322624.0000, Validation Loss: 8779683887792741964702547968.0000, Gradient norm: 3.27071095994444e+27\n",
      "0.2\n",
      "Epoch 339, Loss: 20328189795659196568797446144.0000, Validation Loss: 10747172612027056560516628480.0000, Gradient norm: 4.0036629678028974e+27\n",
      "0.2\n",
      "Epoch 340, Loss: 24883648137691790347260133376.0000, Validation Loss: 13155566946242545311396397056.0000, Gradient norm: 4.900866311961919e+27\n",
      "0.2\n",
      "Epoch 341, Loss: 30459964751641231516707586048.0000, Validation Loss: 16103671907473571139140190208.0000, Gradient norm: 5.999128997839674e+27\n",
      "0.2\n",
      "Epoch 342, Loss: 37285909507209818988854902784.0000, Validation Loss: 19712434284530934175768772608.0000, Gradient norm: 7.343507543733318e+27\n",
      "0.2\n",
      "Epoch 343, Loss: 45641518600409127015264813056.0000, Validation Loss: 24129904512126457594813349888.0000, Gradient norm: 8.989155436445469e+27\n",
      "0.2\n",
      "Epoch 344, Loss: 55869583112856136994175057920.0000, Validation Loss: 29537310479267153705506439168.0000, Gradient norm: 1.1003585817724545e+28\n",
      "0.2\n",
      "Epoch 345, Loss: 68389712106913999853734330368.0000, Validation Loss: 36156492451521106773614264320.0000, Gradient norm: 1.346944122883097e+28\n",
      "0.2\n",
      "Epoch 346, Loss: 83715547198889324389223890944.0000, Validation Loss: 44259004126815069732205494272.0000, Gradient norm: 1.648788404273553e+28\n",
      "0.2\n",
      "Epoch 347, Loss: 102475834842722653252865753088.0000, Validation Loss: 54177253197994413769099313152.0000, Gradient norm: 2.0182746677331004e+28\n",
      "0.2\n",
      "Epoch 348, Loss: 125440220820204909756550217728.0000, Validation Loss: 66318138466682569592169037824.0000, Gradient norm: 2.4705611853255848e+28\n",
      "0.2\n",
      "Epoch 349, Loss: 153550825163530965174861168640.0000, Validation Loss: 81179742974656671812981620736.0000, Gradient norm: 3.024203131525664e+28\n",
      "0.2\n",
      "Epoch 350, Loss: 187960892879770089248163627008.0000, Validation Loss: 99371767992886716628331397120.0000, Gradient norm: 3.7019138141783573e+28\n",
      "0.2\n",
      "Epoch 351, Loss: 230082106133489456284870639616.0000, Validation Loss: 121640546178064185316859707392.0000, Gradient norm: 4.531496493984186e+28\n",
      "0.2\n",
      "Epoch 352, Loss: 281642498882382576538894729216.0000, Validation Loss: 148899660068007754250221256704.0000, Gradient norm: 5.5469850206517065e+28\n",
      "0.2\n",
      "Epoch 353, Loss: 344757349929209499606482681856.0000, Validation Loss: 182267422047850434531820568576.0000, Gradient norm: 6.790040080618411e+28\n",
      "0.2\n",
      "Epoch 354, Loss: 422015962796324331200054296576.0000, Validation Loss: 223112753412572228552707014656.0000, Gradient norm: 8.311658337773499e+28\n",
      "0.2\n",
      "Epoch 355, Loss: 516587892590188677143289921536.0000, Validation Loss: 273111344726600386829369737216.0000, Gradient norm: 1.0174264585134504e+29\n",
      "0.2\n",
      "Epoch 356, Loss: 632352977841189360702918230016.0000, Validation Loss: 334314401474142172884380942336.0000, Gradient norm: 1.245427273855575e+29\n",
      "0.2\n",
      "Epoch 357, Loss: 774060511909515985723334852608.0000, Validation Loss: 409232795308807113791988826112.0000, Gradient norm: 1.5245220737915616e+29\n",
      "0.2\n",
      "Epoch 358, Loss: 947524084006289315771348680704.0000, Validation Loss: 500940073229879068748305924096.0000, Gradient norm: 1.86616079659361e+29\n",
      "0.2\n",
      "Epoch 359, Loss: 1159860083234560599861615394816.0000, Validation Loss: 613198550664046079739812642816.0000, Gradient norm: 2.2843592615760583e+29\n",
      "0.2\n",
      "Epoch 360, Loss: 1419779650341797983310827225088.0000, Validation Loss: 750613661454743065398937124864.0000, Gradient norm: 2.796274171804222e+29\n",
      "0.2\n",
      "Epoch 361, Loss: 1737946054582019870878307713024.0000, Validation Loss: 918822897008407306002875023360.0000, Gradient norm: 3.4229069723930866e+29\n",
      "0.2\n",
      "Epoch 362, Loss: 2127412157168236227074975596544.0000, Validation Loss: 1124727085876286009695317000192.0000, Gradient norm: 4.1899654403693734e+29\n",
      "0.2\n",
      "Epoch 363, Loss: 2604155908369488022435365126144.0000, Validation Loss: 1376773502078048275545364365312.0000, Gradient norm: 5.128918353050009e+29\n",
      "0.2\n",
      "Epoch 364, Loss: 3187735847163076813477375901696.0000, Validation Loss: 1685302416761347534952482209792.0000, Gradient norm: 6.2782865029870445e+29\n",
      "0.2\n",
      "Epoch 365, Loss: 3902093495489257530431453003776.0000, Validation Loss: 2062971310571191926109891461120.0000, Gradient norm: 7.685223023710116e+29\n",
      "0.2\n",
      "Epoch 366, Loss: 4776535565545757678894055424000.0000, Validation Loss: 2525274150154193117029410537472.0000, Gradient norm: 9.40744785954951e+29\n",
      "0.2\n",
      "Epoch 367, Loss: 5846936275437161214889621979136.0000, Validation Loss: 3091177032254185475871543918592.0000, Gradient norm: 1.1515615741678032e+30\n",
      "0.2\n",
      "Epoch 368, Loss: 7157209098497914884617366667264.0000, Validation Loss: 3783896272866984333710414839808.0000, Gradient norm: 1.4096214817217493e+30\n",
      "0.2\n",
      "Epoch 369, Loss: 8761108325195714981987230941184.0000, Validation Loss: 4631850862768477533279336005632.0000, Gradient norm: 1.7255114848438615e+30\n",
      "0.2\n",
      "Epoch 370, Loss: 10724434347170694890509133938688.0000, Validation Loss: 5669828364156976999486046863360.0000, Gradient norm: 2.1121910547868541e+30\n",
      "0.2\n",
      "Epoch 371, Loss: 13127733135773697275832249090048.0000, Validation Loss: 6940412079629136294316903235584.0000, Gradient norm: 2.5855238235782044e+30\n",
      "0.2\n",
      "Epoch 372, Loss: 16069600661927354376502458187776.0000, Validation Loss: 8495728043475639132449427947520.0000, Gradient norm: 3.164928393736164e+30\n",
      "0.2\n",
      "Epoch 373, Loss: 19670727822012265210576224911360.0000, Validation Loss: 10399583506078389843853005815808.0000, Gradient norm: 3.874174991594068e+30\n",
      "0.2\n",
      "Epoch 374, Loss: 24078851813936677377559104585728.0000, Validation Loss: 12730084643299452349580270632960.0000, Gradient norm: 4.742360647147125e+30\n",
      "0.2\n",
      "Epoch 375, Loss: 29474817094907604181813693513728.0000, Validation Loss: 15582840883084399629203715129344.0000, Gradient norm: 5.805102907433701e+30\n",
      "0.2\n",
      "Epoch 376, Loss: 36079994573305287005153175535616.0000, Validation Loss: 19074887307629867205664679395328.0000, Gradient norm: 7.106001055859761e+30\n",
      "0.2\n",
      "Epoch 377, Loss: 44165363408977576927544538562560.0000, Validation Loss: 23349486048705634734811023147008.0000, Gradient norm: 8.698424784376953e+30\n",
      "0.2\n",
      "Epoch 378, Loss: 54062628005222637600465825562624.0000, Validation Loss: 28582003654649224313766252904448.0000, Gradient norm: 1.0647703699265616e+31\n",
      "0.2\n",
      "Epoch 379, Loss: 66177826270007925070995210108928.0000, Validation Loss: 34987105549574525969470026940416.0000, Gradient norm: 1.3033807485578555e+31\n",
      "0.2\n",
      "Epoch 380, Loss: 81007987428955064466608834478080.0000, Validation Loss: 42827562739393656317349646565376.0000, Gradient norm: 1.5954626684703918e+31\n",
      "0.2\n",
      "Epoch 381, Loss: 99161522781291559194784480362496.0000, Validation Loss: 52425032062105107563015556825088.0000, Gradient norm: 1.9529988679817236e+31\n",
      "0.2\n",
      "Epoch 382, Loss: 121383185934945740609420917735424.0000, Validation Loss: 64173252244978421235476229783552.0000, Gradient norm: 2.390657364609266e+31\n",
      "0.2\n",
      "Epoch 383, Loss: 148584626521058194991962145161216.0000, Validation Loss: 78554197140385362680030987026432.0000, Gradient norm: 2.9263932143835743e+31\n",
      "0.2\n",
      "Epoch 384, Loss: 181881790862158997036399218130944.0000, Validation Loss: 96157848831066407329516857851904.0000, Gradient norm: 3.5821851227894023e+31\n",
      "0.2\n",
      "Epoch 385, Loss: 222640703966353581720453011996672.0000, Validation Loss: 117706401801726274651568455286784.0000, Gradient norm: 4.3849371269939605e+31\n",
      "0.2\n",
      "Epoch 386, Loss: 272533511065985687099642468106240.0000, Validation Loss: 144083891159525019066742261940224.0000, Gradient norm: 5.367582341115208e+31\n",
      "0.2\n",
      "Epoch 387, Loss: 333607077819779238670652487499776.0000, Validation Loss: 176372460409076872850600833843200.0000, Gradient norm: 6.570434045972944e+31\n",
      "0.2\n",
      "Epoch 388, Loss: 408366963519968148185830916096000.0000, Validation Loss: 215896756677055879996854708994048.0000, Gradient norm: 8.042839552138267e+31\n",
      "0.2\n",
      "Epoch 389, Loss: 499880212327532828967064496504832.0000, Validation Loss: 264278274712286337949104657661952.0000, Gradient norm: 9.845204686452476e+31\n",
      "0.2\n",
      "Epoch 390, Loss: 611901179573260710450588656074752.0000, Validation Loss: 323501879138350029766024086159360.0000, Gradient norm: 1.2051471957112013e+32\n",
      "0.2\n",
      "Epoch 391, Loss: 749025555182043076809316768940032.0000, Validation Loss: 395997234051786750859940592615424.0000, Gradient norm: 1.4752154064700406e+32\n",
      "0.2\n",
      "Epoch 392, Loss: 916878903072284147628987140538368.0000, Validation Loss: 484738480636775416427416760877056.0000, Gradient norm: 1.8058047209762443e+32\n",
      "0.2\n",
      "Epoch 393, Loss: 1122347451409344101409713148657664.0000, Validation Loss: 593366252096904888755903210192896.0000, Gradient norm: 2.2104776536349935e+32\n",
      "0.2\n",
      "Epoch 394, Loss: 1373860601944444325507055107440640.0000, Validation Loss: 726337031599005763497835297243136.0000, Gradient norm: 2.7058360189567502e+32\n",
      "0.2\n",
      "Epoch 395, Loss: 1681736748459671714058836125941760.0000, Validation Loss: 889105980678349164779312785653760.0000, Gradient norm: 3.312202025405632e+32\n",
      "0.2\n",
      "Epoch 396, Loss: 2058606591612616804363960401788928.0000, Validation Loss: 1088350738689076238643771023032320.0000, Gradient norm: 4.054451999397574e+32\n",
      "0.2\n",
      "Epoch 397, Loss: 2519931316784529137898528333365248.0000, Validation Loss: 1332245374731739458627297393770496.0000, Gradient norm: 4.9630369431966666e+32\n",
      "0.2\n",
      "Epoch 398, Loss: 3084636893315821300524192836354048.0000, Validation Loss: 1630795731008518323310404755783680.0000, Gradient norm: 6.075231795368359e+32\n",
      "0.2\n",
      "Epoch 399, Loss: 3775890517423446612929513162539008.0000, Validation Loss: 1996249915156300297749832168112128.0000, Gradient norm: 7.436664645031245e+32\n",
      "0.2\n",
      "Epoch 400, Loss: 4622051052577020519716356171497472.0000, Validation Loss: 2443600782114580492501809528569856.0000, Gradient norm: 9.103188636328315e+32\n",
      "0.2\n",
      "Epoch 401, Loss: 5657832459402461890741179093352448.0000, Validation Loss: 2991201019980238996230288449732608.0000, Gradient norm: 1.1143173358495441e+33\n",
      "0.2\n",
      "Epoch 402, Loss: 6925727945133876630813628457549824.0000, Validation Loss: 3661516073909688760453143457693696.0000, Gradient norm: 1.36403097264131e+33\n",
      "0.2\n",
      "Epoch 403, Loss: 8477753258723056406558115555704832.0000, Validation Loss: 4482045796971408292055989081866240.0000, Gradient norm: 1.6697043422610952e+33\n",
      "0.2\n",
      "Epoch 404, Loss: 10377580650751376727356583016660992.0000, Validation Loss: 5486452638919795640136892114010112.0000, Gradient norm: 2.0438777758594745e+33\n",
      "0.2\n",
      "Epoch 405, Loss: 12703151044416044429460528173154304.0000, Validation Loss: 6715942657134345614852246290300928.0000, Gradient norm: 2.501901837899776e+33\n",
      "0.2\n",
      "Epoch 406, Loss: 15549871582599048601058949514395648.0000, Validation Loss: 8220956006064617215390920931803136.0000, Gradient norm: 3.0625670871410527e+33\n",
      "0.2\n",
      "Epoch 407, Loss: 19034529731236199659852863866142720.0000, Validation Loss: 10063236257959302378427804521857024.0000, Gradient norm: 3.7488749643003986e+33\n",
      "0.2\n",
      "Epoch 408, Loss: 23300084516116423768497192154693632.0000, Validation Loss: 12318363449311804114005942559834112.0000, Gradient norm: 4.5889814322656955e+33\n",
      "0.2\n",
      "Epoch 409, Loss: 28521531454872961658276534898655232.0000, Validation Loss: 15078854771925269347713355542953984.0000, Gradient norm: 5.617352081948988e+33\n",
      "0.2\n",
      "Epoch 410, Loss: 34913081794558920127192631152214016.0000, Validation Loss: 18457960115271329691915664987521024.0000, Gradient norm: 6.876176092304947e+33\n",
      "0.2\n",
      "Epoch 411, Loss: 42736950584934495957693855856328704.0000, Validation Loss: 22594308173275623357212619268161536.0000, Gradient norm: 8.417097052599418e+33\n",
      "0.2\n",
      "Epoch 412, Loss: 52314114120506517149203966843682816.0000, Validation Loss: 27657593723294556924539897515081728.0000, Gradient norm: 1.0303331654371468e+34\n",
      "0.2\n",
      "Epoch 413, Loss: 64037478078235551118561661083975680.0000, Validation Loss: 33855539399413466131546125144948736.0000, Gradient norm: 1.261226317298892e+34\n",
      "0.2\n",
      "Epoch 414, Loss: 78387996577257041400559629863223296.0000, Validation Loss: 41442417568664133348023952969039872.0000, Gradient norm: 1.543861613706697e+34\n",
      "0.2\n",
      "Epoch 415, Loss: 95954403449320992194816074338795520.0000, Validation Loss: 50729481922396316313389259468832768.0000, Gradient norm: 1.8898342427405858e+34\n",
      "0.2\n",
      "Epoch 416, Loss: 117457365200559133715050199095705600.0000, Validation Loss: 62097736741608956553650343759577088.0000, Gradient norm: 2.3133378233687935e+34\n",
      "0.2\n",
      "Epoch 417, Loss: 143779046546249471435694503427571712.0000, Validation Loss: 76013567698741795028921200416915456.0000, Gradient norm: 2.831746702434611e+34\n",
      "0.2\n",
      "Epoch 418, Loss: 175999301452491352104209878358163456.0000, Validation Loss: 93047875453721267671694994038587392.0000, Gradient norm: 3.466328741848845e+34\n",
      "0.2\n",
      "Epoch 419, Loss: 215439974431885990679298407930003456.0000, Validation Loss: 113899497005118699552647898957086720.0000, Gradient norm: 4.243117838271715e+34\n",
      "0.2\n",
      "Epoch 420, Loss: 263719129565639934231100093871685632.0000, Validation Loss: 139423875663570659364840909232406528.0000, Gradient norm: 5.193981970635809e+34\n",
      "0.2\n",
      "Epoch 421, Loss: 322817432012122463616698148548771840.0000, Validation Loss: 170668155840733967461050894484766720.0000, Gradient norm: 6.357930592443355e+34\n",
      "0.2\n",
      "Epoch 422, Loss: 395159405320891200517682678980411392.0000, Validation Loss: 208914142426810022591357821088956416.0000, Gradient norm: 7.78271500495386e+34\n",
      "0.2\n",
      "Epoch 423, Loss: 483712898155067893701949807686320128.0000, Validation Loss: 255730887176508220796246114500083712.0000, Gradient norm: 9.52678736699714e+34\n",
      "0.2\n",
      "Epoch 424, Loss: 592110841070762253772963972481286144.0000, Validation Loss: 313039059473895122032555006934122496.0000, Gradient norm: 1.1661698710309416e+35\n",
      "0.2\n",
      "Epoch 425, Loss: 724800288457746131672463979537498112.0000, Validation Loss: 383189742303848991962089615045689344.0000, Gradient norm: 1.4275034339608465e+35\n",
      "0.2\n",
      "Epoch 426, Loss: 887224860126568125383638378944135168.0000, Validation Loss: 469060886055770177889349395225247744.0000, Gradient norm: 1.7474007042975166e+35\n",
      "0.2\n",
      "Epoch 427, Loss: 1086048067256665086077382239994249216.0000, Validation Loss: 574175377202455363159248670780555264.0000, Gradient norm: 2.1389855524951428e+35\n",
      "0.2\n",
      "Epoch 428, Loss: 1329426684711782047494922239970639872.0000, Validation Loss: 702845565653035789576867634753830912.0000, Gradient norm: 2.6183228509240417e+35\n",
      "0.2\n",
      "Epoch 429, Loss: 1627345384894531460108659580018360320.0000, Validation Loss: 860350180053007321207575086788247552.0000, Gradient norm: 3.2050775395251607e+35\n",
      "0.2\n",
      "Epoch 430, Loss: 1992026361582826388943818085355225088.0000, Validation Loss: 1053150889028512012331374061966852096.0000, Gradient norm: 3.923321385192569e+35\n",
      "0.2\n",
      "Epoch 431, Loss: 2438430748674836946829372243023233024.0000, Validation Loss: 1289157392857417638187719820885098496.0000, Gradient norm: 4.802520532401767e+35\n",
      "0.2\n",
      "Epoch 432, Loss: 2984872404679620373036437986217033728.0000, Validation Loss: 1578051921023391267702759052472745984.0000, Gradient norm: 5.87874435961063e+35\n",
      "0.2\n",
      "Epoch 433, Loss: 3653769243625122226170882556398927872.0000, Validation Loss: 1931686448251270893286773419904335872.0000, Gradient norm: 7.196145235087686e+35\n",
      "0.2\n",
      "Epoch 434, Loss: 4472562935933542534193405074069258240.0000, Validation Loss: 2364568924917078604078393779543867392.0000, Gradient norm: 8.808769879543652e+35\n",
      "0.2\n",
      "Epoch 435, Loss: 5474844710236681187609577272228446208.0000, Validation Loss: 2894458469564319355538145040807231488.0000, Gradient norm: 1.078277664719895e+36\n",
      "0.2\n",
      "Epoch 436, Loss: 6701733442449638164121543712230604800.0000, Validation Loss: 3543093941457603666668720733026254848.0000, Gradient norm: 1.3199149689831874e+36\n",
      "0.2\n",
      "Epoch 437, Loss: 8203562568573067863490875741433757696.0000, Validation Loss: 4337085783056051082745480509975953408.0000, Gradient norm: 1.615702135310812e+36\n",
      "0.2\n",
      "Epoch 438, Loss: 10041945027269537810150732536446189568.0000, Validation Loss: 5309007720480727695430965355937267712.0000, Gradient norm: 1.9777739107383103e+36\n",
      "0.2\n",
      "Epoch 439, Loss: 12292300947031567712135299676004941824.0000, Validation Loss: 6498733109277704361594503641461424128.0000, Gradient norm: 2.4209843859893417e+36\n",
      "0.2\n",
      "Epoch 440, Loss: 15046951776978430876986520878845001728.0000, Validation Loss: 7955070749416435404738637749494480896.0000, Gradient norm: 2.96351638849164e+36\n",
      "0.2\n",
      "Epoch 441, Loss: 18418907798819364580740524543905366016.0000, Validation Loss: 9737767279268142186107543652155785216.0000, Gradient norm: 3.627627437700132e+36\n",
      "0.2\n",
      "Epoch 442, Loss: 22546504403666985441762348822316449792.0000, Validation Loss: 11919958297308839585568208065021345792.0000, Gradient norm: 4.440562865742329e+36\n",
      "0.2\n",
      "Epoch 443, Loss: 27599077338188259724123659060146864128.0000, Validation Loss: 14591168769465649645528802916940382208.0000, Gradient norm: 5.435673564403053e+36\n",
      "0.2\n",
      "Epoch 444, Loss: 33783909748573343624476738037882028032.0000, Validation Loss: 17860985814614513750725484806215303168.0000, Gradient norm: 6.6537842143151e+36\n",
      "0.2\n",
      "Epoch 445, Loss: 41354736026645476644420400894063935488.0000, Validation Loss: 21863554545229469882603494826970185728.0000, Gradient norm: 8.144868128321993e+36\n",
      "0.2\n",
      "Epoch 446, Loss: 50622151330656753960062966011902558208.0000, Validation Loss: 26763081406239886585993778915300081664.0000, Gradient norm: 9.970097419906168e+36\n",
      "0.2\n",
      "Epoch 447, Loss: 61966353834124111360162466574148567040.0000, Validation Loss: 32760570788033584885490030531603070976.0000, Gradient norm: 1.2204352605386958e+37\n",
      "0.2\n",
      "Epoch 448, Loss: 75852742456847499550642082574042660864.0000, Validation Loss: 40102071284942787089599490933248753664.0000, Gradient norm: 1.49392945969847e+37\n",
      "0.2\n",
      "Epoch 449, Loss: 92851009979166768679969298283673681920.0000, Validation Loss: 49088769904157162813320847686170050560.0000, Gradient norm: 1.8287125116082312e+37\n",
      "0.2\n",
      "Epoch 450, Loss: 113658514839538936067268802469643157504.0000, Validation Loss: 60089348342664392654452321134755971072.0000, Gradient norm: 2.238518979863656e+37\n",
      "0.2\n",
      "Epoch 451, Loss: 139128890449637468451929881817536004096.0000, Validation Loss: 73555108251760911764592828592525672448.0000, Gradient norm: 2.7401612836361087e+37\n",
      "0.2\n",
      "Epoch 452, Loss: 170307065731721785597428552274112675840.0000, Validation Loss: 90038486007125291289513001066518544384.0000, Gradient norm: 3.354219431633151e+37\n",
      "0.2\n",
      "Epoch 453, Loss: 208472133605120483864627324027171504128.0000, Validation Loss: 110215716557812556857590735869250109440.0000, Gradient norm: 4.1058853224201353e+37\n",
      "0.2\n",
      "Epoch 454, Loss: 255189826112870054265682401925806424064.0000, Validation Loss: 134914576144591865021244887287864492032.0000, Gradient norm: 5.025996248747777e+37\n",
      "0.2\n",
      "Epoch 455, Loss: 312376748994510834315439709866361356288.0000, Validation Loss: 165148342040014158531489921146327924736.0000, Gradient norm: 6.152300005675087e+37\n",
      "0.2\n",
      "Epoch 456, Loss: 382379010945446125443291935559542374400.0000, Validation Loss: 202157362517562106313942669307773190144.0000, Gradient norm: 7.531003503884484e+37\n",
      "0.2\n",
      "Epoch 457, Loss: 468068473349105987633005582968762138624.0000, Validation Loss: 247459942468905513216512165898732175360.0000, Gradient norm: 9.218668420461222e+37\n",
      "0.2\n",
      "Epoch 458, Loss: 572960569152735350436941573574063292416.0000, Validation Loss: 302914632265219749836010091515830337536.0000, Gradient norm: 1.128453165671405e+38\n",
      "0.2\n",
      "Epoch 459, Loss: 701358524437465993193643795023870820352.0000, Validation Loss: 370796475279642555168574848821675163648.0000, Gradient norm: 1.3813345800435102e+38\n",
      "0.2\n",
      "Epoch 460, Loss: 858529899410882173724370904898038923264.0000, Validation Loss: 453890342145723344681780888078578089984.0000, Gradient norm: 1.6908856123317364e+38\n",
      "0.2\n",
      "Epoch 461, Loss: 1050922691463169886857213153310641487872.0000, Validation Loss: 555605180814599135221986599324245557248.0000, Gradient norm: 2.069805675827223e+38\n",
      "0.2\n",
      "Epoch 462, Loss: 1286429865972113787087050338792781119488.0000, Validation Loss: 680113869549828233975897306381408010240.0000, Gradient norm: 2.5336400667451456e+38\n",
      "0.2\n",
      "Epoch 463, Loss: 1574713167303445621011223452758384312320.0000, Validation Loss: 832524410366129127868786548006774112256.0000, Gradient norm: 3.1014177141295086e+38\n",
      "0.2\n",
      "Epoch 464, Loss: 1927599494438824121650465142218411737088.0000, Validation Loss: 1019089486168303484098639047186301583360.0000, Gradient norm: 3.796431846719703e+38\n",
      "0.2\n",
      "Epoch 465, Loss: 2359566102646812755021199030734796357632.0000, Validation Loss: 1247462978727607918578862231004062416896.0000, Gradient norm: 4.647195603844327e+38\n",
      "0.2\n",
      "Epoch 466, Loss: 2888334536724253598565483099224063082496.0000, Validation Loss: 1527013971213666470707306456144414769152.0000, Gradient norm: 5.6886117945329094e+38\n",
      "0.2\n",
      "Epoch 467, Loss: 3535597662076960219735892632711787970560.0000, Validation Loss: 1869211117319171428966217953481026699264.0000, Gradient norm: 6.96340479452366e+38\n",
      "0.2\n",
      "Epoch 468, Loss: 4327909620282834561457761438371973955584.0000, Validation Loss: 2288093145822760673791555927786571956224.0000, Gradient norm: 8.523873325122307e+38\n",
      "0.2\n",
      "Epoch 469, Loss: 5297775219800725561737705022410079600640.0000, Validation Loss: 2800844803164705715842085588505836126208.0000, Gradient norm: 1.0434036022129845e+39\n",
      "0.2\n",
      "Epoch 470, Loss: 6484983454368089902294831774230166634496.0000, Validation Loss: 3428501862232495829867526030054257590272.0000, Gradient norm: 1.2772257817374483e+39\n",
      "0.2\n",
      "Epoch 471, Loss: 7938239857033746179356877382624695287808.0000, Validation Loss: 4196814120528922219294465513543497154560.0000, Gradient norm: 1.563446488084719e+39\n",
      "0.2\n",
      "Epoch 472, Loss: 9717164657583468630758944985265366630400.0000, Validation Loss: 5137301792451687001831860324443740962816.0000, Gradient norm: 1.913808001729573e+39\n",
      "0.2\n",
      "Epoch 473, Loss: 11894738718297193725107743463952181362688.0000, Validation Loss: 6288548634458265772759399598990393606144.0000, Gradient norm: 2.3426839967967493e+39\n",
      "0.2\n",
      "Epoch 474, Loss: 14560297593201815127402710552980228145152.0000, Validation Loss: 7697784853919270705267302984973639745536.0000, Gradient norm: 2.867669224858364e+39\n",
      "0.2\n",
      "Epoch 475, Loss: 17823196542895397380404787308359550238720.0000, Validation Loss: 9422824740916327403972398042704974446592.0000, Gradient norm: 3.5103013442889244e+39\n",
      "0.2\n",
      "Epoch 476, Loss: 21817296863149039866269747680455501545472.0000, Validation Loss: 11534438514843428519803017664934048694272.0000, Gradient norm: 4.296944508418763e+39\n",
      "0.2\n",
      "Epoch 477, Loss: 26706457580108521523737885196521010364416.0000, Validation Loss: 14119255691448383287353205957936751312896.0000, Gradient norm: 5.2598709619245885e+39\n",
      "0.2\n",
      "Epoch 478, Loss: 32691257810349560882261833051428775526400.0000, Validation Loss: 17283319081718097902150528061266521489408.0000, Gradient norm: 6.438585018236226e+39\n",
      "0.2\n",
      "Epoch 479, Loss: 40017225572392766365871921096174057029632.0000, Validation Loss: 21156435226355636365182332603694955102208.0000, Gradient norm: 7.881443734484211e+39\n",
      "0.2\n",
      "Epoch 480, Loss: 48984910638855675652139093851766742056960.0000, Validation Loss: 25897499743578605456755822764197704368128.0000, Gradient norm: 9.647640772608246e+39\n",
      "0.2\n",
      "Epoch 481, Loss: 59962214670675869081583180353955805790208.0000, Validation Loss: 31701016064046255468859228247950729674752.0000, Gradient norm: 1.1809634835055306e+40\n",
      "0.2\n",
      "Epoch 482, Loss: 73399484480435735552545298161788549857280.0000, Validation Loss: 38805074985746507810342568804087515578368.0000, Gradient norm: 1.4456122302286607e+40\n",
      "0.2\n",
      "Epoch 483, Loss: 89847987629923831325422957784729699483648.0000, Validation Loss: 47501122412200914494594522826304236027904.0000, Gradient norm: 1.7695676025336623e+40\n",
      "0.2\n",
      "Epoch 484, Loss: 109982528328229271991399776680008700919808.0000, Validation Loss: 58145915998040944499718486266328016486400.0000, Gradient norm: 2.1661199555854783e+40\n",
      "0.2\n",
      "Epoch 485, Loss: 134629131453592411402242288560405485715456.0000, Validation Loss: 71176161226514962188968613995365902843904.0000, Gradient norm: 2.6515379549600344e+40\n",
      "0.2\n",
      "Epoch 486, Loss: 164798930443359297057138953796028878290944.0000, Validation Loss: 87126427367891744605931552079700419411968.0000, Gradient norm: 3.245736002969111e+40\n",
      "0.2\n",
      "Epoch 487, Loss: 201729649311723975813534443512013936132096.0000, Validation Loss: 106651078325711466422768739479870341382144.0000, Gradient norm: 3.973091232302831e+40\n",
      "0.2\n",
      "Epoch 488, Loss: 246936380606048812459685172682154877911040.0000, Validation Loss: 130551118089674068317022942406350259355648.0000, Gradient norm: 4.863443584370862e+40\n",
      "0.2\n",
      "Epoch 489, Loss: 302273742480905457949860530089050526187520.0000, Validation Loss: 159807052136997937191281808193601126006784.0000, Gradient norm: 5.953320000821779e+40\n",
      "0.2\n",
      "Epoch 490, Loss: 370011964900301071583366867039836717449216.0000, Validation Loss: 195619112929965201863234463926782223450112.0000, Gradient norm: 7.287432951022788e+40\n",
      "0.2\n",
      "Epoch 491, Loss: 452930026424740245975301224526397254402048.0000, Validation Loss: 239456499771370802751107998514864069804032.0000, Gradient norm: 8.920514772987517e+40\n",
      "0.2\n",
      "Epoch 492, Loss: 554429662544539616026751733955225037307904.0000, Validation Loss: 293117653096018979038334199563609071157248.0000, Gradient norm: 1.0919563082075447e+41\n",
      "0.2\n",
      "Epoch 493, Loss: 678674922781541211293031886223327222562816.0000, Validation Loss: 358804035967080348172677261429160223440896.0000, Gradient norm: 1.3366589365951144e+41\n",
      "0.2\n",
      "Epoch 494, Loss: 830763001926378744326109934082339194798080.0000, Validation Loss: 439210449682787857983187339940430295859200.0000, Gradient norm: 1.636198352764126e+41\n",
      "0.2\n",
      "Epoch 495, Loss: 1016933353808162302339224067740314330202112.0000, Validation Loss: 537635588715215970807477216455960821760000.0000, Gradient norm: 2.0028632407961607e+41\n",
      "0.2\n",
      "Epoch 496, Loss: 1244823666544508398204561327346705309368320.0000, Validation Loss: 658117370526861585562699800967980827803648.0000, Gradient norm: 2.4516961250790297e+41\n",
      "0.2\n",
      "Epoch 497, Loss: 1523783200724511516349721160274695222722560.0000, Validation Loss: 805598592206685564424540138385990339264512.0000, Gradient norm: 3.0011104938638574e+41\n",
      "0.2\n",
      "Epoch 498, Loss: 1865256345306812781433798787937726894178304.0000, Validation Loss: 986129710033089648066828684404485003411456.0000, Gradient norm: 3.673646217509696e+41\n",
      "0.2\n",
      "Epoch 499, Loss: 2283252126715326274133494924150740826980352.0000, Validation Loss: 1207117061049247486992993452164782269399040.0000, Gradient norm: 4.496894252649778e+41\n",
      "0.2\n",
      "Epoch 500, Loss: 2794918932867934289908099899632631750328320.0000, Validation Loss: 1477626710006818835155483185720374950100992.0000, Gradient norm: 5.504628568513261e+41\n",
      "0.2\n",
      "Epoch 501, Loss: 3421248030344032159956443954260695618420736.0000, Validation Loss: 1808756387079595135438887452850860154945536.0000, Gradient norm: 6.738191732980533e+41\n",
      "0.2\n",
      "Epoch 502, Loss: 4187934736669518088350033974857361809997824.0000, Validation Loss: 2214090775190529652600400325704711938244608.0000, Gradient norm: 8.248191002407649e+41\n",
      "0.2\n",
      "Epoch 503, Loss: 5126432577540869363675959161006891219288064.0000, Validation Loss: 2710258825235638196486427571421239348035584.0000, Gradient norm: 1.0096574497755543e+42\n",
      "0.2\n",
      "Epoch 504, Loss: 6275243676068339653701185602847096614944768.0000, Validation Loss: 3317615963209799987127618208515870718689280.0000, Gradient norm: 1.2359172642700835e+42\n",
      "0.2\n",
      "Epoch 505, Loss: 7681498312599578889373685653684230215958528.0000, Validation Loss: 4061079176962939485935982621773818243317760.0000, Gradient norm: 1.5128809126901457e+42\n",
      "0.2\n",
      "Epoch 506, Loss: 9402888456984852207293344296355285868478464.0000, Validation Loss: 4971149242242490196474612781916516410982400.0000, Gradient norm: 1.851910902251137e+42\n",
      "0.2\n",
      "Epoch 507, Loss: 11510034596958432668335565767502779377516544.0000, Validation Loss: 6085162025116950823835049009322223479029760.0000, Gradient norm: 2.2669160282935228e+42\n",
      "0.2\n",
      "Epoch 508, Loss: 14089382962398940699460776996035774965088256.0000, Validation Loss: 7448820195794713233177736151868246727852032.0000, Gradient norm: 2.774921986304709e+42\n",
      "0.2\n",
      "Epoch 509, Loss: 17246752004863196817367740684998148389601280.0000, Validation Loss: 9118068192804253371468668250862896338173952.0000, Gradient norm: 3.396769855597072e+42\n",
      "0.2\n",
      "Epoch 510, Loss: 21111673627658073703802208469775219700006912.0000, Validation Loss: 11161387358439048981026308812406450552832000.0000, Gradient norm: 4.15797111012042e+42\n",
      "0.2\n",
      "Epoch 511, Loss: 25842707266566788100671914046661243365752832.0000, Validation Loss: 13662605404008239763646418469611670255697920.0000, Gradient norm: 5.0897542334545713e+42\n",
      "0.2\n",
      "Epoch 512, Loss: 31633944832802346254828449795900147192823808.0000, Validation Loss: 16724335463950878109558259008653782100738048.0000, Gradient norm: 6.23034587563991e+42\n",
      "0.2\n",
      "Epoch 513, Loss: 38722973385200063950090947028111415496933376.0000, Validation Loss: 20472185826921962857371637267317951970672640.0000, Gradient norm: 7.62653911164525e+42\n",
      "0.2\n",
      "Epoch 514, Loss: 47400622202390055423535671810092935667515392.0000, Validation Loss: 25059913049185872197315310687527803302182912.0000, Gradient norm: 9.335613139692786e+42\n",
      "0.2\n",
      "Epoch 515, Loss: 58022894131173520350023874671611367152156672.0000, Validation Loss: 30675729858162246493220618755564926253662208.0000, Gradient norm: 1.1427683175573884e+43\n",
      "0.2\n",
      "Epoch 516, Loss: 71025570697838085697975410202808558209204224.0000, Validation Loss: 37550026629542416617599202217747740073394176.0000, Gradient norm: 1.3988576947993793e+43\n",
      "0.2\n",
      "Epoch 517, Loss: 86942090160981952277445028296934387221528576.0000, Validation Loss: 45964823213624987298775834567150662624215040.0000, Gradient norm: 1.7123355803930636e+43\n",
      "0.2\n",
      "Epoch 518, Loss: 106425431957710360727412849922996879793061888.0000, Validation Loss: 56265338874555765630484266950558394955595776.0000, Gradient norm: 2.0960624878290845e+43\n",
      "0.2\n",
      "Epoch 519, Loss: 130274905358421170069130584405416778049519616.0000, Validation Loss: 68874155002301614052269562147629387030200320.0000, Gradient norm: 2.565780915371587e+43\n",
      "0.2\n",
      "Epoch 520, Loss: 159468941341853934936653783555735051787304960.0000, Validation Loss: 84308551626376728503748775104013717003567104.0000, Gradient norm: 3.140761186229418e+43\n",
      "0.2\n",
      "Epoch 521, Loss: 195205232985784731317106666196415277613187072.0000, Validation Loss: 103201728966401140527459400178955811314204672.0000, Gradient norm: 3.844592018682394e+43\n",
      "0.2\n",
      "Epoch 522, Loss: 238949871143550896435492534199020645112610816.0000, Validation Loss: 126328784639236681695378043741263912727740416.0000, Gradient norm: 4.706148259511988e+43\n",
      "0.2\n",
      "Epoch 523, Loss: 292497491210584252352000593663797578703044608.0000, Validation Loss: 154638512244521858353031869337650271367462912.0000, Gradient norm: 5.760775482257327e+43\n",
      "0.2\n",
      "Epoch 524, Loss: 358044898518016589451944023226297577442902016.0000, Validation Loss: 189292325874018831378134828119003282001625088.0000, Gradient norm: 7.051740048754527e+43\n",
      "0.2\n",
      "Epoch 525, Loss: 438281192854681865352651455725464346869891072.0000, Validation Loss: 231711907433105073831506607202787336325693440.0000, Gradient norm: 8.632004123119066e+43\n",
      "0.2\n",
      "Epoch 526, Loss: 536498089499959867626689820002538851756146688.0000, Validation Loss: 283637531518424310590707975885856725817884672.0000, Gradient norm: 1.0566398458591041e+44\n",
      "0.2\n",
      "Epoch 527, Loss: 656724962717122757947978887576418633341992960.0000, Validation Loss: 347199460645288769716387870001378548711948288.0000, Gradient norm: 1.2934282096400601e+44\n",
      "0.2\n",
      "Epoch 528, Loss: 803894151902358853907368245277943915859673088.0000, Validation Loss: 425005339832993660059608143250181880562057216.0000, Gradient norm: 1.5832798091505727e+44\n",
      "0.2\n",
      "Epoch 529, Loss: 984043312118130554315446589269845624108351488.0000, Validation Loss: 520247175934112532026731131876637262882013184.0000, Gradient norm: 1.938085883221511e+44\n",
      "0.2\n",
      "Epoch 530, Loss: 1204563110495216621512108892424883376580722688.0000, Validation Loss: 636832290563159208933227171920727080416837632.0000, Gradient norm: 2.3724024452491994e+44\n",
      "0.2\n",
      "Epoch 531, Loss: 1474500430314116653830001139014981505073020928.0000, Validation Loss: 779543619003291407078780116949708550910771200.0000, Gradient norm: 2.9040474475098885e+44\n",
      "0.2\n",
      "Epoch 532, Loss: 1804929521793743559579032320971248474446102528.0000, Validation Loss: 954235931396258436730833506924234600899149824.0000, Gradient norm: 3.5548317673828932e+44\n",
      "0.2\n",
      "Epoch 533, Loss: 2209406326147073252375386695369380885906325504.0000, Validation Loss: 1168076026242015578883446510316044080927211520.0000, Gradient norm: 4.351454004386249e+44\n",
      "0.2\n",
      "Epoch 534, Loss: 2704524611668761659312591850937479535112749056.0000, Validation Loss: 1429836750210104464984262402004395142932332544.0000, Gradient norm: 5.326595797310938e+44\n",
      "0.2\n",
      "Epoch 535, Loss: 3310596737485381580746706430800608794073104384.0000, Validation Loss: 1750256906503620953505469673438705263331770368.0000, Gradient norm: 6.5202625971298395e+44\n",
      "0.2\n",
      "Epoch 536, Loss: 4052486973481901144008718806913348554421436416.0000, Validation Loss: 2142481817111974227621638473940967927110959104.0000, Gradient norm: 7.981424901246104e+44\n",
      "0.2\n",
      "Epoch 537, Loss: 4960631563575634873364326460124555259083227136.0000, Validation Loss: 2622602613135828567386456306816287730776932352.0000, Gradient norm: 9.77002728115168e+44\n",
      "0.2\n",
      "Epoch 538, Loss: 6072287380704333171399435725903381274057244672.0000, Validation Loss: 3210316377712998949312628661639288774790742016.0000, Gradient norm: 1.1959447624389139e+45\n",
      "0.2\n",
      "Epoch 539, Loss: 7433060399930846999290525539967209265277435904.0000, Validation Loss: 3929734224084118916181947909403834049338802176.0000, Gradient norm: 1.463950748187134e+45\n",
      "0.2\n",
      "Epoch 540, Loss: 9098776695679306018403529074602552014273511424.0000, Validation Loss: 4810370460415285556386356554768220778324295680.0000, Gradient norm: 1.7920157020856853e+45\n",
      "0.2\n",
      "Epoch 541, Loss: 11137772721261223792816245431848467819078352896.0000, Validation Loss: 5888353422127168767823960276892156177317625856.0000, Gradient norm: 2.193598575975558e+45\n",
      "0.2\n",
      "Epoch 542, Loss: 13633698830017194992237735871760555934444683264.0000, Validation Loss: 7207907646448379030543338229155178142914052096.0000, Gradient norm: 2.6851744138857537e+45\n",
      "0.2\n",
      "Epoch 543, Loss: 16688951053273399063030100396920428003078438912.0000, Validation Loss: 8823168195797701075825789957073361791107465216.0000, Gradient norm: 3.286910245088999e+45\n",
      "0.2\n",
      "Epoch 544, Loss: 20428871924714796372617563822067877520372400128.0000, Validation Loss: 10800401563093694890823632929317573615469723648.0000, Gradient norm: 4.0234924418323864e+45\n",
      "0.2\n",
      "Epoch 545, Loss: 25006892691110321278502638421683197050452180992.0000, Validation Loss: 13220724272221643256291973839494185536263815168.0000, Gradient norm: 4.925139484313476e+45\n",
      "0.2\n",
      "Epoch 546, Loss: 30610827869950398501893822366078777352570011648.0000, Validation Loss: 16183430704963890639428160487239769678866808832.0000, Gradient norm: 6.028841681853994e+45\n",
      "0.2\n",
      "Epoch 547, Loss: 37470580389895198797060363954508564998830161920.0000, Validation Loss: 19810066679376949727105786454662615126878715904.0000, Gradient norm: 7.379878710161368e+45\n",
      "0.2\n",
      "Epoch 548, Loss: 45867573419466394761581852962913012008070676480.0000, Validation Loss: 24249415899249930267398531491853254714611204096.0000, Gradient norm: 9.033677222047173e+45\n",
      "0.2\n",
      "Epoch 549, Loss: 56146295827258882593549888657261156616015708160.0000, Validation Loss: 29683603845057309720624773548199387801967394816.0000, Gradient norm: 1.1058084740575555e+46\n",
      "0.2\n",
      "Epoch 550, Loss: 68728434929242899308295065823919801902259240960.0000, Validation Loss: 36335569520153084756668973162442417626276691968.0000, Gradient norm: 1.353615312171175e+46\n",
      "0.2\n",
      "Epoch 551, Loss: 84130176322867583153047717426122455212575686656.0000, Validation Loss: 44478211582577750074519961997549513364761214976.0000, Gradient norm: 1.6569545778764745e+46\n",
      "0.2\n",
      "Epoch 552, Loss: 102983380538253183100558891226792117876698382336.0000, Validation Loss: 54445584084964123256540395467492397980699328512.0000, Gradient norm: 2.02827084509119e+46\n",
      "0.2\n",
      "Epoch 553, Loss: 126061505284209594750061389793317767457426898944.0000, Validation Loss: 66646601130743993910484028167677511489254588416.0000, Gradient norm: 2.482797462269133e+46\n",
      "0.2\n",
      "Epoch 554, Loss: 154311336756108116256610935943790119826059427840.0000, Validation Loss: 81581812683815827189444008580722352117803646976.0000, Gradient norm: 3.039181504565237e+46\n",
      "0.2\n",
      "Epoch 555, Loss: 188891831790935061268319408697765363913880240128.0000, Validation Loss: 99863939763718860395664283184383018878533369856.0000, Gradient norm: 3.720248775044935e+46\n",
      "0.2\n",
      "Epoch 556, Loss: 231221664379254168395170080778741684445510631424.0000, Validation Loss: 122243011488148364168253025787245210567666827264.0000, Gradient norm: 4.553940239315596e+46\n",
      "0.2\n",
      "Epoch 557, Loss: 283037427142353511901033889603150215229544071168.0000, Validation Loss: 149637135216655831853053924053442687019530584064.0000, Gradient norm: 5.574458311059392e+46\n",
      "0.2\n",
      "Epoch 558, Loss: 346464875505630940542998175393077339428889821184.0000, Validation Loss: 183170162148848930174735723791004456383393300480.0000, Gradient norm: 6.823670015136008e+46\n",
      "0.2\n",
      "Epoch 559, Loss: 424106137379348498569079940824782452069287067648.0000, Validation Loss: 224217793618258788761998889603078196177385029632.0000, Gradient norm: 8.352824593393973e+46\n",
      "0.2\n",
      "Epoch 560, Loss: 519146466147064086340694676901003197087362318336.0000, Validation Loss: 274464019604821830417085079837333704683059937280.0000, Gradient norm: 1.022465601842508e+47\n",
      "0.2\n",
      "Epoch 561, Loss: 635484916531435446513179430260651819836475703296.0000, Validation Loss: 335970204870937821994012632035630643692752076800.0000, Gradient norm: 1.251595667144704e+47\n",
      "0.2\n",
      "Epoch 562, Loss: 777894304349487963757335659108053946184379662336.0000, Validation Loss: 411259656998176803696241879766386445041140760576.0000, Gradient norm: 1.5320727770132721e+47\n",
      "0.2\n",
      "Epoch 563, Loss: 952217012548779588605460969270089214266991181824.0000, Validation Loss: 503421145750798660373687857945294581716800765952.0000, Gradient norm: 1.8754035793524174e+47\n",
      "0.2\n",
      "Epoch 564, Loss: 1165604676519083716090815084581423044322628993024.0000, Validation Loss: 616235620675456539344537834668783816639674056704.0000, Gradient norm: 2.295673311488778e+47\n",
      "0.2\n",
      "Epoch 565, Loss: 1426811581833147029027496147457353484190905008128.0000, Validation Loss: 754331325560260710168295625899137003428222337024.0000, Gradient norm: 2.8101236507726187e+47\n",
      "0.2\n",
      "Epoch 566, Loss: 1746553811136735651707742896651355607615590629376.0000, Validation Loss: 923373673365069799446996529659097538658922659840.0000, Gradient norm: 3.439860058969114e+47\n",
      "0.2\n",
      "Epoch 567, Loss: 2137948874284493856894088706955661850427619540992.0000, Validation Loss: 1130297671292440371366844744480818883454996316160.0000, Gradient norm: 4.210717639431187e+47\n",
      "0.2\n",
      "Epoch 568, Loss: 2617053857664676712630094002333780553979559673856.0000, Validation Loss: 1383592431299485440724810288955985284827470364672.0000, Gradient norm: 5.154321029074204e+47\n",
      "0.2\n",
      "Epoch 569, Loss: 3203524170431672817418662610631344868395654840320.0000, Validation Loss: 1693649438169929528876201723839475839389686300672.0000, Gradient norm: 6.309381807502388e+47\n",
      "0.2\n",
      "Epoch 570, Loss: 3921419912885445985278842320066357444215807410176.0000, Validation Loss: 2073188862936492767939763800173483759881584377856.0000, Gradient norm: 7.723286649840738e+47\n",
      "0.2\n",
      "Epoch 571, Loss: 4800192948474739244598449617541774815542095380480.0000, Validation Loss: 2537781411274948833411638148780475315953170644992.0000, Gradient norm: 9.454041377664001e+47\n",
      "0.2\n",
      "Epoch 572, Loss: 5875895174315069852668846459424660379285806120960.0000, Validation Loss: 3106487115838782587457794081035895756216380424192.0000, Gradient norm: 1.1572650663228491e+48\n",
      "0.2\n",
      "Epoch 573, Loss: 7192657559840338675411185017278319930842028179456.0000, Validation Loss: 3802637279159591803585443673605753125395717160960.0000, Gradient norm: 1.4166031015004346e+48\n",
      "0.2\n",
      "Epoch 574, Loss: 8804500631541443382435489375261515130461751345152.0000, Validation Loss: 4654791646528333060674797213209190240388311416832.0000, Gradient norm: 1.734057655051357e+48\n",
      "0.2\n",
      "Epoch 575, Loss: 10777550679409027854444642483706700211995921088512.0000, Validation Loss: 5697910077129029481794425641062456015639797563392.0000, Gradient norm: 2.1226523843250846e+48\n",
      "0.2\n",
      "Epoch 576, Loss: 13192752605538072048708947742676964469328419225600.0000, Validation Loss: 6974786781544278482211055154907577006989288407040.0000, Gradient norm: 2.598329491269155e+48\n",
      "0.2\n",
      "Epoch 577, Loss: 16149190710228728007751929015359328040800042876928.0000, Validation Loss: 8537805965607055810791077387260202870871878008832.0000, Gradient norm: 3.1806037554969944e+48\n",
      "0.2\n",
      "Epoch 578, Loss: 19768153651714826942498882247010927356170848960512.0000, Validation Loss: 10451090906353993215400382055938624772070659063808.0000, Gradient norm: 3.893363133303124e+48\n",
      "0.2\n",
      "Epoch 579, Loss: 24198110345572343465256183987881524590128517873664.0000, Validation Loss: 12793134626491707218427522409529015899731276070912.0000, Gradient norm: 4.765848767412815e+48\n",
      "0.2\n",
      "Epoch 580, Loss: 29620800941402058536795281974249620784372315586560.0000, Validation Loss: 15660020091494703278260205930678709072862059167744.0000, Gradient norm: 5.833854612626463e+48\n",
      "0.2\n",
      "Epoch 581, Loss: 36258692760722362068486050916642647860764311814144.0000, Validation Loss: 19169362038775765427517433080292302701353207070720.0000, Gradient norm: 7.14119589231923e+48\n",
      "0.2\n",
      "Epoch 582, Loss: 44384107077903734193957824999592670924887499472896.0000, Validation Loss: 23465132153517168396786463031018970205653477359616.0000, Gradient norm: 8.741506629613763e+48\n",
      "0.2\n",
      "Epoch 583, Loss: 54330391172756055672683821620350491340168457355264.0000, Validation Loss: 28723565545282464123348844290218323092412414558208.0000, Gradient norm: 1.070043999741961e+49\n",
      "0.2\n",
      "Epoch 584, Loss: 66505593991192718886261818614038705344503399579648.0000, Validation Loss: 35160390840179997772141864340550148903718159908864.0000, Gradient norm: 1.3098361757283997e+49\n",
      "0.2\n",
      "Epoch 585, Loss: 81409206461581250791975511615790915746486632316928.0000, Validation Loss: 43039680505028890398922212340110811413923206529024.0000, Gradient norm: 1.603364728609785e+49\n",
      "0.2\n",
      "Epoch 586, Loss: 99652653242703640009592212577917577592908034342912.0000, Validation Loss: 52684684490426449934445104137372118983463684538368.0000, Gradient norm: 1.96267174520533e+49\n",
      "0.2\n",
      "Epoch 587, Loss: 121984376582727370417003032599153980300120184324096.0000, Validation Loss: 64491091645800288316212644576254414609801164095488.0000, Gradient norm: 2.402497891273509e+49\n",
      "0.2\n",
      "Epoch 588, Loss: 149320541361161916067716546012297730229082775355392.0000, Validation Loss: 78943262959518707303949778282424856297218118778880.0000, Gradient norm: 2.9408871512387343e+49\n",
      "0.2\n",
      "Epoch 589, Loss: 182782620996298926558821227958101239853215561809920.0000, Validation Loss: 96634102597045332011585493751429053001212589244416.0000, Gradient norm: 3.599927087443367e+49\n",
      "0.2\n",
      "Epoch 590, Loss: 223743406189969852422823562790664828559467118329856.0000, Validation Loss: 118289381951754269143056656535734842028161195048960.0000, Gradient norm: 4.406654988257481e+49\n",
      "0.2\n",
      "Epoch 591, Loss: 273883324030589971127842679956541066080507316404224.0000, Validation Loss: 144797514609048942078227277635787437090063263989760.0000, Gradient norm: 5.394167080013117e+49\n",
      "0.2\n",
      "Epoch 592, Loss: 335259377960644755820045133136737132003450750500864.0000, Validation Loss: 177246003749593579473035632509036473413806929739776.0000, Gradient norm: 6.602976308477258e+49\n",
      "0.2\n",
      "Epoch 593, Loss: 410389536889090114067776009069447782109133909524480.0000, Validation Loss: 216966057256052011274123762471570843020808702394368.0000, Gradient norm: 8.082674393208804e+49\n",
      "0.2\n",
      "Epoch 594, Loss: 502356035534409849770742041932802488561297579311104.0000, Validation Loss: 265587200869934318706652611742178082588697982664704.0000, Gradient norm: 9.893966341021032e+49\n",
      "0.2\n",
      "Epoch 595, Loss: 614931823922332011154486385397940525035919392112640.0000, Validation Loss: 325104129917811395178793078766398772305838232043520.0000, Gradient norm: 1.2111160885004405e+50\n",
      "0.2\n",
      "Epoch 596, Loss: 752735353662421670722587245823046303727312508551168.0000, Validation Loss: 397958542216716074083635795926969289807775582388224.0000, Gradient norm: 1.4825219020031914e+50\n",
      "0.2\n",
      "Epoch 597, Loss: 921420051151647082168949916415743674456818506006528.0000, Validation Loss: 487139309375402511513635853695723768786852432052224.0000, Gradient norm: 1.8147485701725638e+50\n",
      "0.2\n",
      "Epoch 598, Loss: 1127906250893405591479874826825284281379502027702272.0000, Validation Loss: 596305096045696087609673727626595184828992066682880.0000, Gradient norm: 2.2214257802825158e+50\n",
      "0.2\n",
      "Epoch 599, Loss: 1380665104058001816210132674119920386509406725996544.0000, Validation Loss: 729934457611277935264266402183805933662705211670528.0000, Gradient norm: 2.7192375728581223e+50\n",
      "0.2\n",
      "Epoch 600, Loss: 1690066109708655554444181154097896395071428109533184.0000, Validation Loss: 893509574111438530006714281678508931560874191093760.0000, Gradient norm: 3.3286068088680165e+50\n",
      "0.2\n",
      "Epoch 601, Loss: 2068802526253865550231936250571339754222742323331072.0000, Validation Loss: 1093741158132810779750775685879715911898954119249920.0000, Gradient norm: 4.0745330230182875e+50\n",
      "0.2\n",
      "Epoch 602, Loss: 2532412115743909423358866102595061205818862464925696.0000, Validation Loss: 1338843763575054572755185166626186950099478815703040.0000, Gradient norm: 4.9876180363016375e+50\n",
      "0.2\n",
      "Epoch 603, Loss: 3099914584684523546407366595245537777417355102519296.0000, Validation Loss: 1638872789905704741018676382399165589921496616140800.0000, Gradient norm: 6.105321403828945e+50\n",
      "0.2\n",
      "Epoch 604, Loss: 3794591872546379879763280662312188174003877997182976.0000, Validation Loss: 2006137007593222645546795408049493783368067903913984.0000, Gradient norm: 7.473497203023897e+50\n",
      "0.2\n",
      "Epoch 605, Loss: 4644943299513658519147142762767554179534714291879936.0000, Validation Loss: 2455703528683669975286288948636475992913411211001856.0000, Gradient norm: 9.148275209324408e+50\n",
      "0.2\n",
      "Epoch 606, Loss: 5685854758661699307468291421412370190522779118338048.0000, Validation Loss: 3006015939072996464887614622916136263031876583686144.0000, Gradient norm: 1.1198363635123437e+51\n",
      "0.2\n",
      "Epoch 607, Loss: 6960029918983256888926272112992437939715635004047360.0000, Validation Loss: 3679650951515527080273509646739870548175986073010176.0000, Gradient norm: 1.3707867902425713e+51\n",
      "0.2\n",
      "Epoch 608, Loss: 8519742154747559467245789482805822820342267050459136.0000, Validation Loss: 4504244621259250929281918722512554424552604833939456.0000, Gradient norm: 1.677974109011705e+51\n",
      "0.2\n",
      "Epoch 609, Loss: 10428979074559234513651713300441811597302040851644416.0000, Validation Loss: 5513626122550253450445614247756680506568671764676608.0000, Gradient norm: 2.0540007611361526e+51\n",
      "0.2\n",
      "Epoch 610, Loss: 12766067629991206092972013485274643069069454219411456.0000, Validation Loss: 6749205599488416870594084229033554407413744708616192.0000, Gradient norm: 2.514293339861337e+51\n",
      "0.2\n",
      "Epoch 611, Loss: 15626887499570244102551903819559717326945584525869056.0000, Validation Loss: 8261673028184301597452854947289784511525225643376640.0000, Gradient norm: 3.077735470445641e+51\n",
      "0.2\n",
      "Epoch 612, Loss: 19128804578046324576632230452856379896524258156740608.0000, Validation Loss: 10113077786488182052133765287640053234626563315597312.0000, Gradient norm: 3.7674425159005684e+51\n",
      "0.2\n",
      "Epoch 613, Loss: 23415485943387568954061630342843096029070674511265792.0000, Validation Loss: 12379374246191624783978529945183452917404263176470528.0000, Gradient norm: 4.6117098908958775e+51\n",
      "0.2\n",
      "Epoch 614, Loss: 28662793836800161085007286539177351230907026694471680.0000, Validation Loss: 15153537821297517421513142226931843570682346652827648.0000, Gradient norm: 5.6451738886593106e+51\n",
      "0.2\n",
      "Epoch 615, Loss: 35086000457868471565949581462132338681018612398948352.0000, Validation Loss: 18549379309066228381770688295162240730659706103660544.0000, Gradient norm: 6.910232644102898e+51\n",
      "0.2\n",
      "Epoch 616, Loss: 42948619563701804817918791553746630597199853112000512.0000, Validation Loss: 22706214008192091793379447659942900041176474382761984.0000, Gradient norm: 8.458785528565156e+51\n",
      "0.2\n",
      "Epoch 617, Loss: 52573217190787518672708372891682672643535067724906496.0000, Validation Loss: 27794577165923115799908637007015778338327010247442432.0000, Gradient norm: 1.0354362335300548e+52\n",
      "0.2\n",
      "Epoch 618, Loss: 64354645012285175446938849808432543626548850775293952.0000, Validation Loss: 34023220231859573397756180507472500476948639050104832.0000, Gradient norm: 1.2674729606116035e+52\n",
      "0.2\n",
      "Epoch 619, Loss: 78776239232758377404490374539837569738455909207638016.0000, Validation Loss: 41647674941601255599041125581854296385166395876311040.0000, Gradient norm: 1.5515081024397187e+52\n",
      "0.2\n",
      "Epoch 620, Loss: 96429649584301493026339270911121610099062705756307456.0000, Validation Loss: 50980736574048837128068508885583280939929609485418496.0000, Gradient norm: 1.8991942761244703e+52\n",
      "0.2\n",
      "Epoch 621, Loss: 118039111913893089168384392924514336031273370364411904.0000, Validation Loss: 62405296460773645393719012805258685004216304284991488.0000, Gradient norm: 2.3247953992583767e+52\n",
      "0.2\n",
      "Epoch 622, Loss: 144491160151315890200291347834641663418497607516815360.0000, Validation Loss: 76390050204560184388538773694904615480823724388646912.0000, Gradient norm: 2.8457718709229604e+52\n",
      "0.2\n",
      "Epoch 623, Loss: 176870996599017352975492519714504422090004120859574272.0000, Validation Loss: 93508726040957613016557387140961900843714073480658944.0000, Gradient norm: 3.4834968891971394e+52\n",
      "0.2\n",
      "Epoch 624, Loss: 216507012644708915967674855293434525014015507731316736.0000, Validation Loss: 114463622191478626294625806360293520376709370022461440.0000, Gradient norm: 4.264133292283368e+52\n",
      "0.2\n",
      "Epoch 625, Loss: 265025286370759091884608165442461237541770896848453632.0000, Validation Loss: 140114418834610318378816945455380991627319036298133504.0000, Gradient norm: 5.21970689589165e+52\n",
      "0.2\n",
      "Epoch 626, Loss: 324416292839276883820611424782111195503564553711517696.0000, Validation Loss: 171513446713397206306361170744367279438203574051405824.0000, Gradient norm: 6.389420360832448e+52\n",
      "0.2\n",
      "Epoch 627, Loss: 397116563860041786105070277743539004504490263835574272.0000, Validation Loss: 209948859283588156505234889335232323484395285931622400.0000, Gradient norm: 7.821261492585486e+52\n",
      "0.2\n",
      "Epoch 628, Loss: 486108647354945118846763343736409251969966994840616960.0000, Validation Loss: 256997479551187024408588688148991653535478353219289088.0000, Gradient norm: 9.573971953761171e+52\n",
      "0.2\n",
      "Epoch 629, Loss: 595043467178406676510858007823348897117634165265661952.0000, Validation Loss: 314589489654949419806632859206220994530858871375790080.0000, Gradient norm: 1.1719457156406249e+53\n",
      "0.2\n",
      "Epoch 630, Loss: 728390103237890098901304473540715199181950954414014464.0000, Validation Loss: 385087617101124359282796585956085316995258289164910592.0000, Gradient norm: 1.4345736200625148e+53\n",
      "0.2\n",
      "Epoch 631, Loss: 891619136683729294010728300287418748366195422954258432.0000, Validation Loss: 471384066286745717524633060735153429430861389168115712.0000, Gradient norm: 1.7560552881532563e+53\n",
      "0.2\n",
      "Epoch 632, Loss: 1091427081953362638153879220264583070416957560034689024.0000, Validation Loss: 577019171952954212876158362190651135439984475139735552.0000, Gradient norm: 2.149579590705586e+53\n",
      "0.2\n",
      "Epoch 633, Loss: 1336011113054174995590701484514533319452215082680844288.0000, Validation Loss: 706326642357777156005640005552628646301757237291384832.0000, Gradient norm: 2.6312909667196846e+53\n",
      "0.2\n",
      "Epoch 634, Loss: 1635405354803654654979647855304986988944556125818191872.0000, Validation Loss: 864611350808092856407629933444751006458106296903139328.0000, Gradient norm: 3.220951753299796e+53\n",
      "0.2\n",
      "Epoch 635, Loss: 2001892535464273031845595343252506733621569409129644032.0000, Validation Loss: 1058366969495589206479000218732412838148129555916783616.0000, Gradient norm: 3.9427529407811935e+53\n",
      "0.2\n",
      "Epoch 636, Loss: 2450507888931743461593488092089262574668813305863208960.0000, Validation Loss: 1295542374122613936608725716470118945904792348034859008.0000, Gradient norm: 4.826306614531845e+53\n",
      "0.2\n",
      "Epoch 637, Loss: 2999655979197730010443672811789503484021117653805432832.0000, Validation Loss: 1585867748638440636489750863834358566782120538874576896.0000, Gradient norm: 5.907860798617189e+53\n",
      "0.2\n",
      "Epoch 638, Loss: 3671865752474352140273677523790126294129458320697720832.0000, Validation Loss: 1941253768619328605251989510193419062312982093445988352.0000, Gradient norm: 7.2317865406119275e+53\n",
      "0.2\n",
      "Epoch 639, Loss: 4494714793194392277320574244649729440377504379034402816.0000, Validation Loss: 2376280239896544329030691755089540962954757895901675520.0000, Gradient norm: 8.852398245608124e+53\n",
      "0.2\n",
      "Epoch 640, Loss: 5501960701734999615802837532263669763339098850131443712.0000, Validation Loss: 2908794238961796144788179646559806004586113432389943296.0000, Gradient norm: 1.0836181939105588e+54\n",
      "0.2\n",
      "Epoch 641, Loss: 6734926008936443867856806755480755018939770159258140672.0000, Validation Loss: 3560642294019034563018531541588085548093631592434499584.0000, Gradient norm: 1.3264522873861242e+54\n",
      "0.2\n",
      "Epoch 642, Loss: 8244193443901718726084782922756572035200989626781138944.0000, Validation Loss: 4358566644604677424006642007192700545503914873342394368.0000, Gradient norm: 1.6237044381492802e+54\n",
      "0.2\n",
      "Epoch 643, Loss: 10091681103888640463366090717855956629562271388766568448.0000, Validation Loss: 5335302349065151293264379058748108924322351564177014784.0000, Gradient norm: 1.9875694946110188e+54\n",
      "0.2\n",
      "Epoch 644, Loss: 12353182660690265176058392415768781401714422908058599424.0000, Validation Loss: 6530920249017306687771828607215341816351642611580141568.0000, Gradient norm: 2.4329751173255754e+54\n",
      "0.2\n",
      "Epoch 645, Loss: 15121476816144795006496859873910130679200718432189284352.0000, Validation Loss: 7994470886265313021201913196721467741242424769195802624.0000, Gradient norm: 2.978194190228229e+54\n",
      "0.2\n",
      "Epoch 646, Loss: 18510133573012967346103128357238498503050244339120734208.0000, Validation Loss: 9785996814301987131267474309450447140819503602278072320.0000, Gradient norm: 3.6455944705505414e+54\n",
      "0.2\n",
      "Epoch 647, Loss: 22658173474496236411968429425845757745649670135134289920.0000, Validation Loss: 11978995860008244315513731574741544946586397744994189312.0000, Gradient norm: 4.4625562319998395e+54\n",
      "0.2\n",
      "Epoch 648, Loss: 27735770958934146145905666728693661422925182569526853632.0000, Validation Loss: 14663436391515925050054292005823938871808710256913022976.0000, Gradient norm: 5.462595547758008e+54\n",
      "0.2\n",
      "Epoch 649, Loss: 33951235811321633415123951101623083249389725568307560448.0000, Validation Loss: 17949448294398662224608085601965198211933701559359111168.0000, Gradient norm: 6.68673929628293e+54\n",
      "0.2\n",
      "Epoch 650, Loss: 41559559127548594081059350182351920536294168852556677120.0000, Validation Loss: 21971841079469050917410432465068144048899764051364544512.0000, Gradient norm: 8.185208299890606e+54\n",
      "0.2\n",
      "Epoch 651, Loss: 50872874391813541675592987265203215813586631062458466304.0000, Validation Loss: 26895634478754164109106275259860311017262306306176319488.0000, Gradient norm: 1.001947764732523e+55\n",
      "0.2\n",
      "Epoch 652, Loss: 62273262835690131806893181486607042032569718143782486016.0000, Validation Loss: 32922828423817724568473372108786463258067496177571463168.0000, Gradient norm: 1.22647987255977e+55\n",
      "0.2\n",
      "Epoch 653, Loss: 76228428422102051240328374864994603034908811561179021312.0000, Validation Loss: 40300690146587242660879280835428879528017426509666975744.0000, Gradient norm: 1.5013286428118336e+55\n",
      "0.2\n",
      "Epoch 654, Loss: 93310885524585908963009649160158972747128476132666507264.0000, Validation Loss: 49331898383197882503742591441617536857653928424892268544.0000, Gradient norm: 1.8377698192657262e+55\n",
      "0.2\n",
      "Epoch 655, Loss: 114221446481478961950059780520555881482734935559655915520.0000, Validation Loss: 60386960849509092790834350304163003329460673329219239936.0000, Gradient norm: 2.249605990516819e+55\n",
      "0.2\n",
      "Epoch 656, Loss: 139817972608177747629991121150500241318851554725515493376.0000, Validation Loss: 73919414418524544781761953935208193308950818714793541632.0000, Gradient norm: 2.7537328448407897e+55\n",
      "0.2\n",
      "Epoch 657, Loss: 171150568185380436919505566242290926993945018773228486656.0000, Validation Loss: 90484431591029355638370233473509417630649430427345879040.0000, Gradient norm: 3.3708323202912735e+55\n",
      "0.2\n",
      "Epoch 658, Loss: 209504661266024378407030650544334932402243082973131833344.0000, Validation Loss: 110761596594843514098887529484093596783829802019725508608.0000, Gradient norm: 4.1262210866999246e+55\n",
      "0.2\n",
      "Epoch 659, Loss: 256453738702462924720213448991536597746698331140204265472.0000, Validation Loss: 135582785508210109202986967254336999084199994671383969792.0000, Gradient norm: 5.050889168778325e+55\n",
      "0.2\n",
      "Epoch 660, Loss: 313923898862372767944507610612488148513106181525080113152.0000, Validation Loss: 165966294196784041997411786413744907210463107289291161600.0000, Gradient norm: 6.182771320110199e+55\n",
      "0.2\n",
      "Epoch 661, Loss: 384272870325703077245657683375224280140461333902650245120.0000, Validation Loss: 203158614171896544317894125744773268263916527206120030208.0000, Gradient norm: 7.568303306489529e+55\n",
      "0.2\n",
      "Epoch 662, Loss: 470386738325687720030834746755216316794271886520042389504.0000, Validation Loss: 248685570235774427144665430268989595576513975676485763072.0000, Gradient norm: 9.264326945541874e+55\n",
      "0.2\n",
      "Epoch 663, Loss: 575798347161848197755919816192209179300433805907800883200.0000, Validation Loss: 304414917849185573212908713365042455243058265672294334464.0000, Gradient norm: 1.1340422057384926e+56\n",
      "0.2\n",
      "Epoch 664, Loss: 704832236075416471598960544458459616178783041150976524288.0000, Validation Loss: 372632968295141323914993746404802580018239435668616904704.0000, Gradient norm: 1.388176099522366e+56\n",
      "0.2\n",
      "Epoch 665, Loss: 862782054619951678361034744207841128035496644923896102912.0000, Validation Loss: 456138385206338428032254152166808554888479455355376500736.0000, Gradient norm: 1.6992602863755299e+56\n",
      "0.2\n",
      "Epoch 666, Loss: 1056127736039836224338415146380644894107404200032350502912.0000, Validation Loss: 558357000483789372799015338138833414101071430067066765312.0000, Gradient norm: 2.0800570776622314e+56\n",
      "0.2\n",
      "Epoch 667, Loss: 1292801338252169839242507319421820900606637161980813639680.0000, Validation Loss: 683482359960180907281903896723834519637743402293206712320.0000, Gradient norm: 2.5461887628535876e+56\n",
      "0.2\n",
      "Epoch 668, Loss: 1582512458628925218113164733650184868549206702899589021696.0000, Validation Loss: 836647764731125729435984817926317300601201760475329593344.0000, Gradient norm: 3.1167785181011432e+56\n",
      "0.2\n",
      "Epoch 669, Loss: 1937146572807209556452722209311102417194163487677886758912.0000, Validation Loss: 1024136866195594606539038775649074988062647793123166519296.0000, Gradient norm: 3.815234939616044e+56\n",
      "0.2\n",
      "Epoch 670, Loss: 2371252639483092883530370616668985832770214216283384184832.0000, Validation Loss: 1253641454522985444952578583384770944922143845447786037248.0000, Gradient norm: 4.67021238754401e+56\n",
      "0.2\n",
      "Epoch 671, Loss: 2902639975305129789671817531457612428627468685664881475584.0000, Validation Loss: 1534577016387136210913240708730761156655130102362892402688.0000, Gradient norm: 5.716786538698595e+56\n",
      "0.2\n",
      "Epoch 672, Loss: 3553108886818568085772924461993213398621087022972592455680.0000, Validation Loss: 1878469007807101402038889841809003642434185861778959761408.0000, Gradient norm: 6.997893375515675e+56\n",
      "0.2\n",
      "Epoch 673, Loss: 4349345033829753634831108949127260830557427459880629829632.0000, Validation Loss: 2299425689040558756236934732051994188609061649028351000576.0000, Gradient norm: 8.566090646133182e+56\n",
      "0.2\n",
      "Epoch 674, Loss: 5324014215685219402538237249131732318454492177951642091520.0000, Validation Loss: 2814716919706883269372403758155064578563272328989913382912.0000, Gradient norm: 1.0485714059963537e+57\n",
      "0.2\n",
      "Epoch 675, Loss: 6517102494363249446101724570121470924191970618683542208512.0000, Validation Loss: 3445482659363497228108748218999060730575783454178346532864.0000, Gradient norm: 1.2835516677254592e+57\n",
      "0.2\n",
      "Epoch 676, Loss: 7977556633283577607274576144795314691109974687276158943232.0000, Validation Loss: 4217600239959762880931874618096682341974328025203104284672.0000, Gradient norm: 1.5711899774296694e+57\n",
      "0.2\n",
      "Epoch 677, Loss: 9765292151272948988945037971262459447810222069088392314880.0000, Validation Loss: 5162745990251116866874623544058815959757698154110535073792.0000, Gradient norm: 1.9232867731378822e+57\n",
      "0.2\n",
      "Epoch 678, Loss: 11953651372633668108800347861018705561268385861751485235200.0000, Validation Loss: 6319694765596908882526104191445541891752996420129843576832.0000, Gradient norm: 2.3542869193822254e+57\n",
      "0.2\n",
      "Epoch 679, Loss: 14632412315471845812563544810232729431898972046536661270528.0000, Validation Loss: 7735910696696962234607390881166544253186416424792845451264.0000, Gradient norm: 2.8818723116008745e+57\n",
      "0.2\n",
      "Epoch 680, Loss: 17911471858727899245142677473002469418438610753515297964032.0000, Validation Loss: 9469494418156139190605660959852262002684542288396338331648.0000, Gradient norm: 3.5276872805932566e+57\n",
      "0.2\n",
      "Epoch 681, Loss: 21925354290814765477072928256961196048190471078600863907840.0000, Validation Loss: 11591566662445790363249271568170934693174117445919848792064.0000, Gradient norm: 4.318226556938087e+57\n",
      "0.2\n",
      "Epoch 682, Loss: 26838730204268710589792815805103104702171012855398506954752.0000, Validation Loss: 14189186006837250639216538385640572793124419314729315467264.0000, Gradient norm: 5.28592222435019e+57\n",
      "0.2\n",
      "Epoch 683, Loss: 32853172150531211334084075589588276169727254185055015141376.0000, Validation Loss: 17368920474650097678132444113441195781884226108030411866112.0000, Gradient norm: 6.470474254526214e+57\n",
      "0.2\n",
      "Epoch 684, Loss: 40215424207393054446750138356915916188157020654912428572672.0000, Validation Loss: 21261219516704557476463195595458597407932338431042187689984.0000, Gradient norm: 7.920479209024554e+57\n",
      "0.2\n",
      "Epoch 685, Loss: 49227524720300891578317161405855759483550418492881255792640.0000, Validation Loss: 26025765734678162132428250664424097286927145150248973762560.0000, Gradient norm: 9.695423926106607e+57\n",
      "0.2\n",
      "Epoch 686, Loss: 60259197505675831951095226844215091731674580440780466290688.0000, Validation Loss: 31858025902238299162599130796668851753040249810327917559808.0000, Gradient norm: 1.1868125984071256e+58\n",
      "0.2\n",
      "Epoch 687, Loss: 73763019868650716435650075634776952463291045476267431297024.0000, Validation Loss: 38997270041331876931717573646548350571089726748740414341120.0000, Gradient norm: 1.4527721061739013e+58\n",
      "0.2\n",
      "Epoch 688, Loss: 90292989707180766190697173139389031291333375612471149068288.0000, Validation Loss: 47736387538366350472077457500506893599516130837943157784576.0000, Gradient norm: 1.7783319753342813e+58\n",
      "0.2\n",
      "Epoch 689, Loss: 110527253422903861675771881108885984678829624062259067092992.0000, Validation Loss: 58433903009054620398811462520477313846877352534290303287296.0000, Gradient norm: 2.1768483859627232e+58\n",
      "0.2\n",
      "Epoch 690, Loss: 135295927057328196725496505496599164746914192446582341763072.0000, Validation Loss: 71528684865969555483512800035528441866311928141354415161344.0000, Gradient norm: 2.664670579618727e+58\n",
      "0.2\n",
      "Epoch 691, Loss: 165615152022846154293187695763547959592837321657961880223744.0000, Validation Loss: 87557950011697404541017262295634349095120764704655392374784.0000, Gradient norm: 3.2618115913228295e+58\n",
      "0.2\n",
      "Epoch 692, Loss: 202728782573982294504524226053263313399526898570692233527296.0000, Validation Loss: 107179303304907623438923498281062624153397175012454744195072.0000, Gradient norm: 3.9927692896321534e+58\n",
      "0.2\n",
      "Epoch 693, Loss: 248159415258450981299016442987887629136135929181158833651712.0000, Validation Loss: 131197715974285692705468572073574776678137756487138370650112.0000, Gradient norm: 4.8875314082026106e+58\n",
      "0.2\n",
      "Epoch 694, Loss: 303770853844804455963587110342597485757735771097874955239424.0000, Validation Loss: 160598549776924838059952721841232274860323151680227931848704.0000, Gradient norm: 5.98280580052441e+58\n",
      "0.2\n",
      "Epoch 695, Loss: 371844572366911709299420841836850791959814090148387124936704.0000, Validation Loss: 196587981726042682722115035918329469574551470690465042399232.0000, Gradient norm: 7.323526389358139e+58\n",
      "0.2\n",
      "Epoch 696, Loss: 455173313201971395041139699922040987597791764983690913906688.0000, Validation Loss: 240642487823210506969816745716540361385572859698983896875008.0000, Gradient norm: 8.964696592846759e+58\n",
      "0.2\n",
      "Epoch 697, Loss: 557175660068060871082705209458728225877493742278978022932480.0000, Validation Loss: 294569415878349203807220223573473044160816579768116452524032.0000, Gradient norm: 1.0973645854349393e+59\n",
      "0.2\n",
      "Epoch 698, Loss: 682036286328868209771304564226491671635128538425752977145856.0000, Validation Loss: 360581132433516162216091497254582380199085241904452778065920.0000, Gradient norm: 1.3432791850732296e+59\n",
      "0.2\n",
      "Epoch 699, Loss: 834877632329544887652841092209519947310922447746906263126016.0000, Validation Loss: 441385785687716711823603921963633745482813416626311636451328.0000, Gradient norm: 1.6443021699445774e+59\n",
      "0.2\n",
      "Epoch 700, Loss: 1021970054871967611180314747336978139750787820971296787791872.0000, Validation Loss: 540298407995831663660511771977773622201954124987896761942016.0000, Gradient norm: 2.0127830879304854e+59\n",
      "0.2\n",
      "Epoch 701, Loss: 1250989070267432973107242835510266509602363847122343337918464.0000, Validation Loss: 661376915951179450079071952091964686283963770115469338476544.0000, Gradient norm: 2.4638389665298183e+59\n",
      "0.2\n",
      "Epoch 702, Loss: 1531330244431316450359643672444355679435644947733818067910656.0000, Validation Loss: 809588587491207409442951069946313359836326249416064757661696.0000, Gradient norm: 3.0159744929257813e+59\n",
      "0.2\n",
      "Epoch 703, Loss: 1874494648469449573893165449430915115859955852427839332679680.0000, Validation Loss: 991013845793780721195740577868132437498681704477536154550272.0000, Gradient norm: 3.691841173690931e+59\n",
      "0.2\n",
      "Epoch 704, Loss: 2294560693173982182133116585238968087608110189477107406471168.0000, Validation Loss: 1213095710252518199181895116597884856569765059512399376154624.0000, Gradient norm: 4.519166618858756e+59\n",
      "0.2\n",
      "Epoch 705, Loss: 2808761699564208793584174761859034164499540287646987576147968.0000, Validation Loss: 1484945148323675010064879874534062281403978888283219078152192.0000, Gradient norm: 5.531892074487435e+59\n",
      "0.2\n",
      "Epoch 706, Loss: 3438192900457150042806830884626930778797875402655753113174016.0000, Validation Loss: 1817714855385166314504173730654446748406153926173206392078336.0000, Gradient norm: 6.771564871291458e+59\n",
      "0.2\n",
      "Epoch 707, Loss: 4208676877995044961403185183543087237319552512843327381438464.0000, Validation Loss: 2225056797025691001222120476358937449291162892482392845451264.0000, Gradient norm: 8.289042914915714e+59\n",
      "0.2\n",
      "Epoch 708, Loss: 5151822941934107452274558280648190503548866336537237690253312.0000, Validation Loss: 2723682284557857403177075494955696502764359349175904758661120.0000, Gradient norm: 1.0146581145018327e+60\n",
      "0.2\n",
      "Epoch 709, Loss: 6306323909970132058367274396612860547099624221461568357924864.0000, Validation Loss: 3334047561001949001576114120985384627833755643704488384004096.0000, Gradient norm: 1.2420385560699972e+60\n",
      "0.2\n",
      "Epoch 710, Loss: 7719543490858122067013927956814940659658851839876506151026688.0000, Validation Loss: 4081193023887331425852871173099630789994955858087973788581888.0000, Gradient norm: 1.5203739591851032e+60\n",
      "0.2\n",
      "Epoch 711, Loss: 9449459393139904475130840463668705486094211272200139720097792.0000, Validation Loss: 4995770514209799672318229622956015928535590891465420914556928.0000, Gradient norm: 1.8610831076631366e+60\n",
      "0.2\n",
      "Epoch 712, Loss: 11567041876031191695201505846304139944278367872752711704248320.0000, Validation Loss: 6115300816347039042366824716869216391349997251835015223836672.0000, Gradient norm: 2.2781436847849796e+60\n",
      "0.2\n",
      "Epoch 713, Loss: 14159165323149864947692983279476717163030713629244639408029696.0000, Validation Loss: 7485712958200197272992661281371632212726985697477059768483840.0000, Gradient norm: 2.7886657114643396e+60\n",
      "0.2\n",
      "Epoch 714, Loss: 17332172287170581359415386391446842814945489952425009381113856.0000, Validation Loss: 9163228461758524393020846021968478669717825273460284731686912.0000, Gradient norm: 3.4135934893987606e+60\n",
      "0.2\n",
      "Epoch 715, Loss: 21216236221284241909064503093795686937492555189984328643772416.0000, Validation Loss: 11216667845966849503910302374921138119462632821706665544908800.0000, Gradient norm: 4.178564846607864e+60\n",
      "0.2\n",
      "Epoch 716, Loss: 25970701879678555535481849656883939081979918023017527404134400.0000, Validation Loss: 13730274006788384386707482030558286075102244985420670138580992.0000, Gradient norm: 5.1149629361351785e+60\n",
      "0.2\n",
      "Epoch 717, Loss: 31790622478387558643415508962196806667123261041378687558090752.0000, Validation Loss: 16807168304379684826978618619886830615809860199528717304725504.0000, Gradient norm: 6.2612037382345415e+60\n",
      "0.2\n",
      "Epoch 718, Loss: 38914761805269673837819661863224351636886453837317602048737280.0000, Validation Loss: 20573581144271667191598380458676177081094558760034389249228800.0000, Gradient norm: 7.664312086160179e+60\n",
      "0.2\n",
      "Epoch 719, Loss: 47635389567800782437934767442580410295930703290806014287282176.0000, Validation Loss: 25184030613273085655892861310832503810989702916192419155279872.0000, Gradient norm: 9.381850872436922e+60\n",
      "0.2\n",
      "Epoch 720, Loss: 58310271835426378015105252115912513446226984876287096302600192.0000, Validation Loss: 30827661625009149547984280309579844930094619950100650542497792.0000, Gradient norm: 1.1484282581810007e+61\n",
      "0.2\n",
      "Epoch 721, Loss: 71377348487554167999123957727744470327038555342455310930411520.0000, Validation Loss: 37736005640224594708169828008806110946018909099749682781880320.0000, Gradient norm: 1.4057860033390942e+61\n",
      "0.2\n",
      "Epoch 722, Loss: 87372699813387866218282716202199249040978722762447863651762176.0000, Validation Loss: 46192479306436518132783950855914566344963715132996167357431808.0000, Gradient norm: 1.7208164925463144e+61\n",
      "0.2\n",
      "Epoch 723, Loss: 106952539348130824355977607816859400905698214284486279904100352.0000, Validation Loss: 56544011701151165852526750728282893885650331062807411076104192.0000, Gradient norm: 2.1064439352687978e+61\n",
      "0.2\n",
      "Epoch 724, Loss: 130920135207504933907470267103742323485774061412133498739752960.0000, Validation Loss: 69215277189384693709455196784545231007343380657032617571385344.0000, Gradient norm: 2.578488799735443e+61\n",
      "0.2\n",
      "Epoch 725, Loss: 160258764375480095841809481773773767087905294675853148967403520.0000, Validation Loss: 84726117802246832823714079839439226295950631547967884161449984.0000, Gradient norm: 3.156316851847623e+61\n",
      "0.2\n",
      "Epoch 726, Loss: 196172051903620384403395861131662670621916500984448930990260224.0000, Validation Loss: 103712869894294839806404936106963377762647435139490432935788544.0000, Gradient norm: 3.863633640867252e+61\n",
      "0.2\n",
      "Epoch 727, Loss: 240133349948408727177948970329973936209096863000692328476180480.0000, Validation Loss: 126954470011438269092550832387858846225181191786175784871264256.0000, Gradient norm: 4.7294570258695344e+61\n",
      "0.2\n",
      "Epoch 728, Loss: 293946182434668705961243856682725264444467855134920011375706112.0000, Validation Loss: 155404410969556859815583891063180149708091058550964136976580608.0000, Gradient norm: 5.789307641116273e+61\n",
      "0.2\n",
      "Epoch 729, Loss: 359818235103449971960257201026992765169060503811218533760630784.0000, Validation Loss: 190229859150442010581208906824125005469739624931956142825799680.0000, Gradient norm: 7.086666139507896e+61\n",
      "0.2\n",
      "Epoch 730, Loss: 440451926405735598795443236257310024886691944234569099305287680.0000, Validation Loss: 232859537812514218948780406455282063533571802226740086309912576.0000, Gradient norm: 8.674756997913537e+61\n",
      "0.2\n",
      "Epoch 731, Loss: 539155274936935549814394488970476528026418946423072652882083840.0000, Validation Loss: 285042340841851574140101530566652112666952612483483294238769152.0000, Gradient norm: 1.0618732065466726e+62\n",
      "0.2\n",
      "Epoch 732, Loss: 659977611778104023717104364536388714067669761430097146375307264.0000, Validation Loss: 348919081588230663991588512438918334190971404655964268064145408.0000, Gradient norm: 1.2998343435475132e+62\n",
      "0.2\n",
      "Epoch 733, Loss: 807875705378711009354567565475603772201001163908462088344829952.0000, Validation Loss: 427110320301225407464986707890228115054801181029499673193218048.0000, Gradient norm: 1.5911215296224087e+62\n",
      "0.2\n",
      "Epoch 734, Loss: 988917114298396107816791181939397311224019780998980258095955968.0000, Validation Loss: 522823873310254550355636468729058254450027928606905074075041792.0000, Gradient norm: 1.9476848989222097e+62\n",
      "0.2\n",
      "Epoch 735, Loss: 1210529110407926978281044560841943665453329517127554840181866496.0000, Validation Loss: 639986414541228641065390002877846361903396770445384632200331264.0000, Gradient norm: 2.3841525583465954e+62\n",
      "0.2\n",
      "Epoch 736, Loss: 1481803384689773262250717322512036129223027420277961082470924288.0000, Validation Loss: 783404568356966698821716104675156667391306441173786343287816192.0000, Gradient norm: 2.9184307095136785e+62\n",
      "0.2\n",
      "Epoch 737, Loss: 1813869036274676664883585658090504388568618223944060435787939840.0000, Validation Loss: 958962102597927382518903678833858499741365551110836426683449344.0000, Gradient norm: 3.572438255435798e+62\n",
      "0.2\n",
      "Epoch 738, Loss: 2220349146688469340778959844713485745908250164834872037694504960.0000, Validation Loss: 1173861311720112604830762123288411769728199024339124144106897408.0000, Gradient norm: 4.373006029335491e+62\n",
      "0.2\n",
      "Epoch 739, Loss: 2717919670388852501916611224603123544337020469774651641298944000.0000, Validation Loss: 1436918492837468635090428052537063749648797822798531917640630272.0000, Gradient norm: 5.352977536702522e+62\n",
      "0.2\n",
      "Epoch 740, Loss: 3326993570224795540443481344579637806229683990197470651989622784.0000, Validation Loss: 1758925636651872718194945832953255265822040966501867739039137792.0000, Gradient norm: 6.5525563688271405e+62\n",
      "0.2\n",
      "Epoch 741, Loss: 4072558264657435161013453311363021168048486452368402692951769088.0000, Validation Loss: 2153093171737154587026261650560079428371813855364763094114893824.0000, Gradient norm: 8.020955565807611e+62\n",
      "0.2\n",
      "Epoch 742, Loss: 4985200743237061275059627865300876264010206674802304656628252672.0000, Validation Loss: 2635591925878944594693975066431486831735784296447288111183953920.0000, Gradient norm: 9.818416594587138e+62\n",
      "0.2\n",
      "Epoch 743, Loss: 6102362405970832085046423867572114210827415363969945760950124544.0000, Validation Loss: 3226216538578240087026401272349946699200289441247285038031044608.0000, Gradient norm: 1.201868077113049e+63\n",
      "0.2\n",
      "Epoch 744, Loss: 7469875106699454513692952420680577723606945217430588526285553664.0000, Validation Loss: 3949197541392769366587706711365467570311689753821271090259820544.0000, Gradient norm: 1.4712014517491132e+63\n",
      "0.2\n",
      "Epoch 745, Loss: 9143841417070188312085509162636760061704267864436061259983486976.0000, Validation Loss: 4834195421927802631757190076371161391812250841820405284395286528.0000, Gradient norm: 1.800891256574337e+63\n",
      "0.2\n",
      "Epoch 746, Loss: 11192936249434956520741966594972340622612937050456755168551632896.0000, Validation Loss: 5917517453215569209177746447542701201580126280888438780759900160.0000, Gradient norm: 2.2044631033704027e+63\n",
      "0.2\n",
      "Epoch 747, Loss: 13701224263364036527413876571860354485969185148454963716296802304.0000, Validation Loss: 7243607209231651517299717623889628144550630309317462660969660416.0000, Gradient norm: 2.698473634307893e+63\n",
      "0.2\n",
      "Epoch 748, Loss: 16771608640625649696475270266219192286934942808433784807325958144.0000, Validation Loss: 8866867874317923714498794743517641406594679023702705469338419200.0000, Gradient norm: 3.303189762587446e+63\n",
      "0.2\n",
      "Epoch 749, Loss: 20530052715540702851315127391910671609243413638875739155268108288.0000, Validation Loss: 10853894148265228480721634319411876966183517016841724428267028480.0000, Gradient norm: 4.043420127935018e+63\n",
      "0.2\n",
      "Epoch 750, Loss: 25130747654218889714584909475687358717481495780567015224707645440.0000, Validation Loss: 13286204311554423100992327335183965388414521714714232899967647744.0000, Gradient norm: 4.94953287763383e+63\n",
      "0.2\n",
      "Epoch 751, Loss: 30762438188088928667570901642189644902140436096977853730990850048.0000, Validation Loss: 16263584534457705384880076435411757102719484171096369228142346240.0000, Gradient norm: 6.058701527829942e+63\n",
      "0.2\n",
      "Epoch 752, Loss: 37656165916620670690141636374859653696540044177955449754812940288.0000, Validation Loss: 19908182631169102840270425141167714174854757462009572774849282048.0000, Gradient norm: 7.4164300169024e+63\n",
      "0.2\n",
      "Epoch 753, Loss: 46094747850289108712175974262395402815811796376716928343984832512.0000, Validation Loss: 24369519206314292039062293826451487133132993979799154639197175808.0000, Gradient norm: 9.078419516617383e+63\n",
      "0.2\n",
      "Epoch 754, Loss: 56424379053522335366767827768136795445363683569866694097910104064.0000, Validation Loss: 29830621777455848442586440621936356445808073150867867939666657280.0000, Gradient norm: 1.1112853587489603e+64\n",
      "0.2\n",
      "Epoch 755, Loss: 69068835389140779097283058025083547069220965116089176725162819584.0000, Validation Loss: 36515533527598406910369840212462031405668927079483774092361859072.0000, Gradient norm: 1.360319542745641e+64\n",
      "0.2\n",
      "Epoch 756, Loss: 84546859035649827721668552794453608557793493923020898345557164032.0000, Validation Loss: 44698504736259088337156608067006821624365916320503365764238016512.0000, Gradient norm: 1.6651611971734176e+64\n",
      "0.2\n",
      "Epoch 757, Loss: 103493440022848608857076167887616122230994805385900037773593673728.0000, Validation Loss: 54715243970003124210080007474566578285651919808306754322215993344.0000, Gradient norm: 2.0383165318462757e+64\n",
      "0.2\n",
      "Epoch 758, Loss: 126685866866403988343357730292046647681864797458589210105677348864.0000, Validation Loss: 66976690615524094611510697096910968157724876107021199269796249600.0000, Gradient norm: 2.4950943434488056e+64\n",
      "0.2\n",
      "Epoch 759, Loss: 155075615035590437727364578801198608267581035110134230339201007616.0000, Validation Loss: 81985873777094962426649319564971767615207707559426928568430493696.0000, Gradient norm: 3.0542340629849404e+64\n",
      "0.2\n",
      "Epoch 760, Loss: 189827381487051119590932945171774548902688047585311059585422852096.0000, Validation Loss: 100358549179134511699199623158341505146243057230622376850316328960.0000, Gradient norm: 3.7386745459105706e+64\n",
      "0.2\n",
      "Epoch 761, Loss: 232366866666692917232513280709893631894937806222553246968164909056.0000, Validation Loss: 122848460708295861100182049643943746798453751227613482120122466304.0000, Gradient norm: 4.576495144769302e+64\n",
      "0.2\n",
      "Epoch 762, Loss: 284439264249029402309349534948166175558611511256108289364896776192.0000, Validation Loss: 150378262956549714913449826000639093275766185584454978633333735424.0000, Gradient norm: 5.602067672086156e+64\n",
      "0.2\n",
      "Epoch 763, Loss: 348180858171058944731110556435513984935662437992552867984358506496.0000, Validation Loss: 184077373370801382708403907820022353722067486689712638841438863360.0000, Gradient norm: 6.857466513102757e+64\n",
      "0.2\n",
      "Epoch 764, Loss: 426206664248002810992013097090369521732633587918421451669818572800.0000, Validation Loss: 225328306903531768851915058653901410174475324682012205104700063744.0000, Gradient norm: 8.394194738603371e+64\n",
      "0.2\n",
      "Epoch 765, Loss: 521717711891460284376923164747616473239089200379369728821302394880.0000, Validation Loss: 275823394055805480522207736091584616664686742869364897931860115456.0000, Gradient norm: 1.0275297032068897e+65\n",
      "0.2\n",
      "Epoch 766, Loss: 638632367190950237539079899331141268632178086294529131936181387264.0000, Validation Loss: 337634209185422683886379547015059822009928642278052095121376149504.0000, Gradient norm: 1.2577946114556124e+65\n",
      "0.2\n",
      "Epoch 767, Loss: 781747084923134731297402815372376227771480118716759869393018552320.0000, Validation Loss: 413296557394988617177345816278203756707588475982439877915996848128.0000, Gradient norm: 1.539660877606995e+65\n",
      "0.2\n",
      "Epoch 768, Loss: 956933184382576058014671736725399599253018056037944445131041013760.0000, Validation Loss: 505914506609551177129715141298342769529248420270647723049764257792.0000, Gradient norm: 1.884692140070598e+65\n",
      "0.2\n",
      "Epoch 769, Loss: 1171377721814741999516545652949542729710200310935656239248323903488.0000, Validation Loss: 619287732787413362446242615297042932182883113507473084016045850624.0000, Gradient norm: 2.3070433980011593e+65\n",
      "0.2\n",
      "Epoch 770, Loss: 1433878341306771129822460711515301325007322614143785636987349762048.0000, Validation Loss: 758067402635206892564803762156558621791254556374128203099191377920.0000, Gradient norm: 2.8240417238973336e+65\n",
      "0.2\n",
      "Epoch 771, Loss: 1755204200472086379286597320356748783566602504303524316857006817280.0000, Validation Loss: 927946988957002252461251600249917829073090110221780906172720611328.0000, Gradient norm: 3.456897111351627e+65\n",
      "0.2\n",
      "Epoch 772, Loss: 2148537778000894127077820878783869339935524541551900720190078320640.0000, Validation Loss: 1135895846887818587086861711242462835356828077786629981550906703872.0000, Gradient norm: 4.231572620669127e+65\n",
      "0.2\n",
      "Epoch 773, Loss: 2630015688348637319539043747592693697505295368539736562814137925632.0000, Validation Loss: 1390445133538528542039321840769803981209250512125604118607096184832.0000, Gradient norm: 5.17984952031024e+65\n",
      "0.2\n",
      "Epoch 774, Loss: 3219390690628612121677806485748298255566572637643668145252467736576.0000, Validation Loss: 1702037800981513080956120371678950116061759585421807737763446915072.0000, Gradient norm: 6.340631121867783e+65\n",
      "0.2\n",
      "Epoch 775, Loss: 3940842050799296703071465652767213540945357744626162711274398416896.0000, Validation Loss: 2083457021132227286004040724084596717166653729447694120146134106112.0000, Gradient norm: 7.76153879875458e+65\n",
      "0.2\n",
      "Epoch 776, Loss: 4823967502470352954917904413300411351399758289770007340606528946176.0000, Validation Loss: 2550350618771199944800779799630857719648440214391208200599186178048.0000, Gradient norm: 9.50086566569215e+65\n",
      "0.2\n",
      "Epoch 777, Loss: 5904997501782697864139672261444201725524933481313369030570050322432.0000, Validation Loss: 3121873027710440661662852850239630792643139753086350368583446429696.0000, Gradient norm: 1.162996806921999e+66\n",
      "0.2\n",
      "Epoch 778, Loss: 7228281591491547308025737714096312328107844646764410762507017256960.0000, Validation Loss: 3821471106526434570488774711510002502250227306351692745289150496768.0000, Gradient norm: 1.4236193000758862e+66\n",
      "0.2\n",
      "Epoch 779, Loss: 8848107852733567025956457687425536912304166349583144666246961692672.0000, Validation Loss: 4677846052158816089978702351970335901898654465547318169354454958080.0000, Gradient norm: 1.7426461530125952e+66\n",
      "0.2\n",
      "Epoch 780, Loss: 10830930087969987976321578070889303404020353605158622152055077208064.0000, Validation Loss: 5726130874135511787782397649094504608400529924092274152934140280832.0000, Gradient norm: 2.1331655270813776e+66\n",
      "0.2\n",
      "Epoch 781, Loss: 13258094105877306890705169325461987212461438840319581297253493506048.0000, Validation Loss: 7009331735617095203124488268137918215965810936581230842678568026112.0000, Gradient norm: 2.6111985832935084e+66\n",
      "0.2\n",
      "Epoch 782, Loss: 16229174954747024001495173304155602228690556301845872979529445670912.0000, Validation Loss: 8580092292659365757314579650151882357441853521450082934226421809152.0000, Gradient norm: 3.19635675470669e+66\n",
      "0.2\n",
      "Epoch 783, Loss: 19866062015280842127039762776886461150201772522941480853932427182080.0000, Validation Loss: 10502853414180916300395275327836194713907789952718094033950452219904.0000, Gradient norm: 3.912646310673453e+66\n",
      "0.2\n",
      "Epoch 784, Loss: 24317959544797847172618474305488947576768692760452807864254369628160.0000, Validation Loss: 12856496885720748296814043456488396430599295023740018935936415956992.0000, Gradient norm: 4.78945322041544e+66\n",
      "0.2\n",
      "Epoch 785, Loss: 29767507821507456742199595618986263188059196119894214411077669617664.0000, Validation Loss: 15737581555634583150339814443739980017477056180149176681972117798912.0000, Gradient norm: 5.862748720213225e+66\n",
      "0.2\n",
      "Epoch 786, Loss: 36438276010417371007181683856779358251042670443724719437121954250752.0000, Validation Loss: 19264304687486815471268695256094749536611945053634403388788723154944.0000, Gradient norm: 7.176565042925798e+66\n",
      "0.2\n",
      "Epoch 787, Loss: 44603934147689748369524006815893878770902727905184976055994842873856.0000, Validation Loss: 23581351034171796627970938515535155253355382909295129895029838970880.0000, Gradient norm: 8.784801852034929e+66\n",
      "0.2\n",
      "Epoch 788, Loss: 54599480526539178083475249952241029734417705884947840014459347140608.0000, Validation Loss: 28865828568317776196529467766687866967598103438617207011622025953280.0000, Gradient norm: 1.07534374896509e+67\n",
      "0.2\n",
      "Epoch 789, Loss: 66834985091160139331803497726524816378965695965537160462780898213888.0000, Validation Loss: 35334534383889481155040507348494519449605264642886092766911899107328.0000, Gradient norm: 1.3163235755515993e+67\n",
      "0.2\n",
      "Epoch 790, Loss: 81812412665068486238741083135555646521402240601977694075798985637888.0000, Validation Loss: 43252848854531547467355441617460826815078611065422403754554669662208.0000, Gradient norm: 1.6113059263333278e+67\n",
      "0.2\n",
      "Epoch 791, Loss: 100146216191267498024439359661675502307494627001881325527147630034944.0000, Validation Loss: 52945622933860788697445611856237891929744216622636488997586826428416.0000, Gradient norm: 1.972392530574356e+67\n",
      "0.2\n",
      "Epoch 792, Loss: 122588544827382782190435058873324506207199443928840935941406229266432.0000, Validation Loss: 64810505252092138552513563003530496525425147962811604316159012241408.0000, Gradient norm: 2.4143970620888322e+67\n",
      "0.2\n",
      "Epoch 793, Loss: 150060101064563555997579135494773099599037664364680538837671793917952.0000, Validation Loss: 79334255756676415796224218705943287668187312543452256208313556926464.0000, Gradient norm: 2.955452874142507e+67\n",
      "0.2\n",
      "Epoch 794, Loss: 183687912791645659745323304075844500438671500451453928289275654176768.0000, Validation Loss: 97112715168388073515303404645112859648395654777712498948182449848320.0000, Gradient norm: 3.617756925085183e+67\n",
      "0.2\n",
      "Epoch 795, Loss: 224851569913537626821669382592512699205509566626638663743335181582336.0000, Validation Loss: 118875249505101870176129213104622917581489476785293042513845413740544.0000, Gradient norm: 4.428480414460739e+67\n",
      "0.2\n",
      "Epoch 796, Loss: 275239822393375970132004700127246417037125979931612952955979053400064.0000, Validation Loss: 145514672516336163666433557424312411489158126332023038779433938845696.0000, Gradient norm: 5.420883488682879e+67\n",
      "0.2\n",
      "Epoch 797, Loss: 336919861668157574430082941241624136766347189345622358898309637079040.0000, Validation Loss: 178123873604385563134731910113412925422113312122487547921735488634880.0000, Gradient norm: 6.635679747372888e+67\n",
      "0.2\n",
      "Epoch 798, Loss: 412422127726319521575700957118729371844818011809381376728036047585280.0000, Validation Loss: 218040653902232236906696742071823958734854148279684003705116292022272.0000, Gradient norm: 8.122706529594348e+67\n",
      "0.2\n",
      "Epoch 799, Loss: 504844121080143828319539924162036900290852906100666241863829701001216.0000, Validation Loss: 266902609920237555599051642752490648581284556879293000641821510991872.0000, Gradient norm: 9.942969503921002e+67\n",
      "0.2\n",
      "Epoch 800, Loss: 617977478546716842525613086200219457760663627992889145505704654667776.0000, Validation Loss: 326714316377791813368482341238872065665978251944990069670985171206144.0000, Gradient norm: 1.2171145442188002e+68\n",
      "0.2\n",
      "Epoch 801, Loss: 756463526155099866020148836880957090894777308751612644520429210304512.0000, Validation Loss: 399929564413428554808403114250374328832146484884618955377234554126336.0000, Gradient norm: 1.48986458538846e+68\n",
      "0.2\n",
      "Epoch 802, Loss: 925983690779029640552620377307409268628960892615787395153254548504576.0000, Validation Loss: 489552029017809877609949571724017196334901683732130030479887625617408.0000, Gradient norm: 1.8237367167602394e+68\n",
      "0.2\n",
      "Epoch 803, Loss: 1133492582182936837335800877534868470480822285925043256831537991122944.0000, Validation Loss: 599258495597749851984973127083835748526853705164242605277681763221504.0000, Gradient norm: 2.2324281311728796e+68\n",
      "0.2\n",
      "Epoch 804, Loss: 1387503307734108894314652269269287029553466159962390000395501415956480.0000, Validation Loss: 733549701073782977078182539044201431206642645333282770821822457839616.0000, Gradient norm: 2.732705502417778e+68\n",
      "0.2\n",
      "Epoch 805, Loss: 1698436724892819744211487252809506357726356737299868168049970481463296.0000, Validation Loss: 897934977807358134614424156967067186245456502186220685198321334091776.0000, Gradient norm: 3.345092842483134e+68\n",
      "0.2\n",
      "Epoch 806, Loss: 2079048959656569174698004925008880625828415600315850696027448522309632.0000, Validation Loss: 1099158275423796558802433952976076505647860353476388138266903879614464.0000, Gradient norm: 4.0947135045952724e+68\n",
      "0.2\n",
      "Epoch 807, Loss: 2544954730016118232220953501870762332740460634745411312995856734486528.0000, Validation Loss: 1345474833136313963975215404704395823249339588893898646508928629735424.0000, Gradient norm: 5.012320875455475e+68\n",
      "0.2\n",
      "Epoch 808, Loss: 3115267943907048429642947940228088936960930210726738686434185391898624.0000, Validation Loss: 1646989853126659321352712857636168925008370052677711053796373826633728.0000, Gradient norm: 6.135560041094977e+68\n",
      "0.2\n",
      "Epoch 809, Loss: 3813385852357925798623209385385832161549290044223913003805338255753216.0000, Validation Loss: 2016073069147742894556322313810107496190917201387884320882403273867264.0000, Gradient norm: 7.51051218652488e+68\n",
      "0.2\n",
      "Epoch 810, Loss: 4667948927926144002566849463610298890338190190064724526555245643300864.0000, Validation Loss: 2467866218135238401673830683170932376725666621785297552923063555719168.0000, Gradient norm: 9.193585088586642e+68\n",
      "0.2\n",
      "Epoch 811, Loss: 5714015847689164238054098033713820449405660628118425706824022724968448.0000, Validation Loss: 3020904233985780702042791707135910254416049635089415507084791901061120.0000, Gradient norm: 1.125382725997425e+69\n",
      "0.2\n",
      "Epoch 812, Loss: 6994501784780342022893979630844713917125725220266057143281688544018432.0000, Validation Loss: 3697875648141441806627357293157050556271988064039466622911867313455104.0000, Gradient norm: 1.377576068280124e+69\n",
      "0.2\n",
      "Epoch 813, Loss: 8561939014761507510445315112694532959522054486499164926982734521303040.0000, Validation Loss: 4526553392616368687828902244253510390704188448448591781353210167427072.0000, Gradient norm: 1.6862848345358978e+69\n",
      "0.2\n",
      "Epoch 814, Loss: 10480632066176163887878354550880106997444603511702337159699959348461568.0000, Validation Loss: 5540934191906888734682131112546159388607896159697400200490750882873344.0000, Gradient norm: 2.064173883868263e+69\n",
      "0.2\n",
      "Epoch 815, Loss: 12829295830907026005046825112940450348094897800318342506266247661879296.0000, Validation Loss: 6782633287640725854058306592856474931320951723888904354992787166330880.0000, Gradient norm: 2.5267462148626075e+69\n",
      "0.2\n",
      "Epoch 816, Loss: 15704284863515771085526311419953903172017383921781768789549559270342656.0000, Validation Loss: 8302591714914397501231001504751979906519742111860135873210135315742720.0000, Gradient norm: 3.0929789802194627e+69\n",
      "0.2\n",
      "Epoch 817, Loss: 19223546352427864034064322899746123160255564596146010190794347750883328.0000, Validation Loss: 10163166171783832153320651690815343452833427143326895880115945734144000.0000, Gradient norm: 3.7861020294828565e+69\n",
      "0.2\n",
      "Epoch 818, Loss: 23531458934654808208272848703032906307987803078243334703882689977516032.0000, Validation Loss: 12440687219358978101510059625594997853912271434917168494793259827068928.0000, Gradient norm: 4.634550919785773e+69\n",
      "0.2\n",
      "Epoch 819, Loss: 28804755867712798447138958736808879912738134150994391096380262925205504.0000, Validation Loss: 15228590763340489904464511606682301248502434278513065651939716131454976.0000, Gradient norm: 5.6731334921317446e+69\n",
      "0.2\n",
      "Epoch 820, Loss: 35259775558438255674821256517342151970599561344658434862087070476664832.0000, Validation Loss: 18641251286860079226629652740720064332398061344993637304513562759135232.0000, Gradient norm: 6.944457872314115e+69\n",
      "0.2\n",
      "Epoch 821, Loss: 43161336903570128308034256598806734767635768805037897294901196017893376.0000, Validation Loss: 22818674094019517304174354361061180910399435080488187687276603951284224.0000, Gradient norm: 8.500680480589964e+69\n",
      "0.2\n",
      "Epoch 822, Loss: 52833603555302804388750670549381530864587383237380049736049679361114112.0000, Validation Loss: 27932239064665402716755130766785646989168006997965292522845367391223808.0000, Gradient norm: 1.0405645762669651e+70\n",
      "0.2\n",
      "Epoch 823, Loss: 64673382821189097631682737952367189795868648627438411623328791736090624.0000, Validation Loss: 34191731559464417160839947444039665506590576670843862724450436390060032.0000, Gradient norm: 1.2737505425053922e+70\n",
      "0.2\n",
      "Epoch 824, Loss: 79166404789291938969752398802781206603634404716918350508616520772354048.0000, Validation Loss: 41853948920026502950865865071140104293391670755678028589248464757456896.0000, Gradient norm: 1.559192462954391e+70\n",
      "0.2\n",
      "Epoch 825, Loss: 96907249534017731915320385137730391242070746702481958962021956094787584.0000, Validation Loss: 51233235648028927080363765541646058699074678481678661355429944459526144.0000, Gradient norm: 1.9086006681904854e+70\n",
      "0.2\n",
      "Epoch 826, Loss: 118623739921540676553727247723568802961811301631786022940091180784812032.0000, Validation Loss: 62714379471861783077152686124742034372709114035698700397236206818033664.0000, Gradient norm: 2.3363097226078112e+70\n",
      "0.2\n",
      "Epoch 827, Loss: 145206800736138084025410386017948046201429937334186997742531353119817728.0000, Validation Loss: 76768397365353525710734101365815080151381376011600351244035754507108352.0000, Gradient norm: 2.85986650372849e+70\n",
      "0.2\n",
      "Epoch 828, Loss: 177747009106022327748379486908262781759531942280124542900822649226657792.0000, Validation Loss: 93971859144185860687742432940925437421714489180580873882331731355238400.0000, Gradient norm: 3.500750067511995e+70\n",
      "0.2\n",
      "Epoch 829, Loss: 217579335719594035117480775891941194867920115448445910603625170722619392.0000, Validation Loss: 115030541395672163521692965400470969462148138054741004020743893030010880.0000, Gradient norm: 4.2852528323289584e+70\n",
      "0.2\n",
      "Epoch 830, Loss: 266337912352393095180813559033170209421320043651221092796991763443089408.0000, Validation Loss: 140808382150648581660455017053133219999232758823438778120530332366143488.0000, Gradient norm: 5.2455592324059775e+70\n",
      "0.2\n",
      "Epoch 831, Loss: 326023072557082502458241741744458380066180338054853594133179735484661760.0000, Validation Loss: 172362924170580798236976502387490030860913087325725137598806356683390976.0000, Gradient norm: 6.42106609278527e+70\n",
      "0.2\n",
      "Epoch 832, Loss: 399083415878571929483872386970212515670865043805001048460544971974377472.0000, Validation Loss: 210988700920149975780814006605843357878139920618998338194250263747887104.0000, Gradient norm: 7.85999889453269e+70\n",
      "0.2\n",
      "Epoch 833, Loss: 488516262300495614620355418805327978212061671909107013645103308021432320.0000, Validation Loss: 258270345146364126866330704020507961466926121772700516185618845152575488.0000, Gradient norm: 9.621390237903159e+70\n",
      "0.2\n",
      "Epoch 834, Loss: 597990618093384267074860345755695598342638351531725391783608525277626368.0000, Validation Loss: 316147598857753331018625392916158891109934670453484144474242851488661504.0000, Gradient norm: 1.1777501670440361e+71\n",
      "0.2\n",
      "Epoch 835, Loss: 731997697771105083559939638786811920906058306734796917517306621916610560.0000, Validation Loss: 386994891755306747263036305808963140570612531634626049603339858632245248.0000, Gradient norm: 1.441678823615154e+71\n",
      "0.2\n",
      "Epoch 836, Loss: 896035177358790412225532611846257441448446597284510004380711041047199744.0000, Validation Loss: 473718752841411230739011439612514126075446029403917240173828288905478144.0000, Gradient norm: 1.7647527367174303e+71\n",
      "0.2\n",
      "Epoch 837, Loss: 1096832738011503966408975685079716025515833628019157170958158846641569792.0000, Validation Loss: 579877051543910063125174996102846191606669066327481008202054613707259904.0000, Gradient norm: 2.1602260994179753e+71\n",
      "0.2\n",
      "Epoch 838, Loss: 1342628152970483591537098388667832241279842701029916019000040179319701504.0000, Validation Loss: 709824960254062205970497163061659106414883497250700069906047002445086720.0000, Gradient norm: 2.6443233114270594e+71\n",
      "0.2\n",
      "Epoch 839, Loss: 1643505244397642949660690112369116714634996874234146576656150074497171456.0000, Validation Loss: 868893626430270819561916195476327572995965020292693004750860470823419904.0000, Gradient norm: 3.236904589404107e+71\n",
      "0.2\n",
      "Epoch 840, Loss: 2011807574857203816890269554325683251836307002854872317842784011069423616.0000, Validation Loss: 1063608884338082310996853660156515976734683969749215104057479062293053440.0000, Gradient norm: 3.962280737619386e+71\n",
      "0.2\n",
      "Epoch 841, Loss: 2462644845247339488081522933500250305110073376453148110395099944883060736.0000, Validation Loss: 1301958979133661041867878779571421097283414737573585312988546953606332416.0000, Gradient norm: 4.850210505154205e+71\n",
      "0.2\n",
      "Epoch 842, Loss: 3014512774291426095196872306582548880609270315219997342733811099673559040.0000, Validation Loss: 1593722286742347859846299715512706834267314482508190939819765173495791616.0000, Gradient norm: 5.937121446483418e+71\n",
      "0.2\n",
      "Epoch 843, Loss: 3690051890309619571455953796743153539769300720847373577308555420517793792.0000, Validation Loss: 1950868474327333492682260426105954479947525897423665015317370838930423808.0000, Gradient norm: 7.267604371569978e+71\n",
      "0.2\n",
      "Epoch 844, Loss: 4516976364904676830778748829946454369586966559902446017248983526192185344.0000, Validation Loss: 2388049559063198738596988280743675906080948799235549451505778895525773312.0000, Gradient norm: 8.896242695683353e+71\n",
      "0.2\n",
      "Epoch 845, Loss: 5529210994210575659400036727433538515447400460809246760160748009294921728.0000, Validation Loss: 2923201011030883481069808882895688870914956073084216909668486511765487616.0000, Gradient norm: 1.088985173850385e+72\n",
      "0.2\n",
      "Epoch 846, Loss: 6768282972661577344921422192695224853500684180429288777352471926703915008.0000, Validation Loss: 3578277560639954024129051291789676811238946210365961200194457956387913728.0000, Gradient norm: 1.3330219840353153e+72\n",
      "0.2\n",
      "Epoch 847, Loss: 8285025557170118918336752033950154794023447703643894242234994789458116608.0000, Validation Loss: 4380153897273042297538387833881036196096947882950958173565904252055846912.0000, Gradient norm: 1.6317463750572439e+72\n",
      "0.2\n",
      "Epoch 848, Loss: 10141663514988830782268036044896934831770733894705703229998875618125545472.0000, Validation Loss: 5361727210553492052822608759539105132394373404320693309722503284088897536.0000, Gradient norm: 1.997413594374692e+72\n",
      "0.2\n",
      "Epoch 849, Loss: 12414365911308876118684546809061531371654608614422424981005678389126758400.0000, Validation Loss: 6563266806284474547658131747549260076664548994395473174803696849027858432.0000, Gradient norm: 2.4450252367515487e+72\n",
      "0.2\n",
      "Epoch 850, Loss: 15196370965383742421788844234076701703398597623512766740901851194764296192.0000, Validation Loss: 8034066165411798793943233812909088967809656813170900690299573610131488768.0000, Gradient norm: 2.9929446886654823e+72\n",
      "0.2\n",
      "Epoch 851, Loss: 18601811173230564945881733575030887269405538171764447826653549222896336896.0000, Validation Loss: 9834465222168054300014901691290078664784539462689143483100891968949977088.0000, Gradient norm: 3.663650491113999e+72\n",
      "0.2\n",
      "Epoch 852, Loss: 22770395623583490313013028490291999445538842646563522478742512298979491840.0000, Validation Loss: 12038325825895856822754601608576604920648122734269369452325211147065098240.0000, Gradient norm: 4.4846585277273116e+72\n",
      "0.2\n",
      "Epoch 853, Loss: 27873141600354412274135667663207406730978990883253560361153131381545500672.0000, Validation Loss: 14736061943028825686634978106247377771114394197749552235385325654800072704.0000, Gradient norm: 5.48965087120029e+72\n",
      "0.2\n",
      "Epoch 854, Loss: 34119390612113646607165367844013771040917178208653905485344991363347775488.0000, Validation Loss: 18038348914071085012551954862393231222418586262657391758968116402873958400.0000, Gradient norm: 6.719857599267931e+72\n",
      "0.2\n",
      "Epoch 855, Loss: 41765396683063020152585442621809934851197493620015409061442206684057436160.0000, Validation Loss: 22080663938827818066168542882436192564363958014331331534908023760589160448.0000, Gradient norm: 8.225748269591808e+72\n",
      "0.2\n",
      "Epoch 856, Loss: 51124839242419057533966811503257144280776216455831757351489459138322235392.0000, Validation Loss: 27028844064498939671157853747137207943038583457467439641165140317844799488.0000, Gradient norm: 1.0069102446763727e+73\n",
      "0.2\n",
      "Epoch 857, Loss: 62581691906284139312720928744841904789331793638848004700004474862270676992.0000, Validation Loss: 33085889694573302351308842911626444126489539425662126313927522903060905984.0000, Gradient norm: 1.2325544225346763e+73\n",
      "0.2\n",
      "Epoch 858, Loss: 76605975097199250146941617333436111336102132129408687531174180976454533120.0000, Validation Loss: 40500292734282155304351493882888832023986360909850149445529665439078023168.0000, Gradient norm: 1.5087644728434198e+73\n",
      "0.2\n",
      "Epoch 859, Loss: 93773038756777786120305854962164637951114122173239315790185218333992812544.0000, Validation Loss: 49576231036990454791557071538868947050867609152825766440959211136511639552.0000, Gradient norm: 1.8468719862553926e+73\n",
      "0.2\n",
      "Epoch 860, Loss: 114787166229826433698568245710268540133516695272831830362195860325429936128.0000, Validation Loss: 60686047381396022191246674552163943504214462023924506660853120370426773504.0000, Gradient norm: 2.260747913282106e+73\n",
      "0.2\n",
      "Epoch 861, Loss: 140510467675565787622644212879369020444066552763957974176339692328841117696.0000, Validation Loss: 74285524932889445242028553166121362612907365718143017723223062595122495488.0000, Gradient norm: 2.7673716237215342e+73\n",
      "0.2\n",
      "Epoch 862, Loss: 171998248365818863516260980330572070056223539153723860192682982106543947776.0000, Validation Loss: 90932585868933203029448816558522344814912225560698010722863445452575997952.0000, Gradient norm: 3.387527489812401e+73\n",
      "0.2\n",
      "Epoch 863, Loss: 210542302863990471027355743916323299401112671573144369832082937255125057536.0000, Validation Loss: 111310180284530509529916722962118773109848914276980126566508772932653678592.0000, Gradient norm: 4.146657570623917e+73\n",
      "0.2\n",
      "Epoch 864, Loss: 257723911240026050895860387648822226616348816781018921478689540465554882560.0000, Validation Loss: 136254304401208805790662064074661056158767370286164802875666508979051167744.0000, Gradient norm: 5.075905379284427e+73\n",
      "0.2\n",
      "Epoch 865, Loss: 315478711505140952477667079789014467069454767013461986958823012163152510976.0000, Validation Loss: 166788297533980304172076052593474696131875480891074871592407320758841245696.0000, Gradient norm: 6.213393553876683e+73\n",
      "0.2\n",
      "Epoch 866, Loss: 386176109675177187525979555035178001493330927704801333736710697548504891392.0000, Validation Loss: 204164824858455981488123280788876467479674771527507396980410283780246339584.0000, Gradient norm: 7.605787848787453e+73\n",
      "0.2\n",
      "Epoch 867, Loss: 472716485281525345172236419617625686291631144739765318408499139095367254016.0000, Validation Loss: 249917268332280552732372600735226788696026028361136503067493541010223398912.0000, Gradient norm: 9.310211609671826e+73\n",
      "0.2\n",
      "Epoch 868, Loss: 578650180211503029863676481079873315836995984588260718425037587390490738688.0000, Validation Loss: 305922634097086298317892791914015200367531960050912340309682954820336484352.0000, Gradient norm: 1.1396589273876078e+74\n",
      "0.2\n",
      "Epoch 869, Loss: 708323152426965091525578490642247328272400325729654922510910039315240189952.0000, Validation Loss: 374478557153832979575329155564001645685031417503075277987590549746046992384.0000, Gradient norm: 1.3950515039045984e+74\n",
      "0.2\n",
      "Epoch 870, Loss: 867055270043618968053897724721684622004773540293733849433341125948000436224.0000, Validation Loss: 458397562448787073823243932248347071320149133924018561824737013159914635264.0000, Gradient norm: 1.707676438781207e+74\n",
      "0.2\n",
      "Epoch 871, Loss: 1061358560332995929661587713308028965666060711283878351513927910087504953344.0000, Validation Loss: 561122449456219462203710154223935903976673527777624136159096185502346248192.0000, Gradient norm: 2.0903592529784416e+74\n",
      "0.2\n",
      "Epoch 872, Loss: 1299204367370329120462111157404641798629607816472920090348213803608759599104.0000, Validation Loss: 686867533940964458962912571238550986884059931627672530034833369432074485760.0000, Gradient norm: 2.558799610558093e+74\n",
      "0.2\n",
      "Epoch 873, Loss: 1590350378541778479401493583537100122439605143585820738594596709874721095680.0000, Validation Loss: 840791541381650393576932979102898393914376537398342903434149790471627472896.0000, Gradient norm: 3.1322154015694346e+74\n",
      "0.2\n",
      "Epoch 874, Loss: 1946740936260295587055422147712840015953848148656126086490919299490456272896.0000, Validation Loss: 1029209245053196941349311205312814859204003536913290444809264187192673042432.0000, Gradient norm: 3.834131161091189e+74\n",
      "0.2\n",
      "Epoch 875, Loss: 2382997057784553683257835201145314286092801682549249111463943540891581415424.0000, Validation Loss: 1259850531277109728803526712508663556434210461748719131792421920454127648768.0000, Gradient norm: 4.693343169529321e+74\n",
      "0.2\n",
      "Epoch 876, Loss: 2917016266334143475161841847933094853774405102791667383230568270716609757184.0000, Validation Loss: 1542177520060244079593012756358395084291703925475571734472354794085285888000.0000, Gradient norm: 5.745100827666675e+74\n",
      "0.2\n",
      "Epoch 877, Loss: 3570706841731769528901980011846668631671197041035030480671464933199070625792.0000, Validation Loss: 1887772751080456274193159046388459481083384126509360449913634282957984235520.0000, Gradient norm: 7.032552772689392e+74\n",
      "0.2\n",
      "Epoch 878, Loss: 4370886613400039262028562985944605229850679846137618920679674846026183737344.0000, Validation Loss: 2310814360452266470749195410509691020386050431480484124755147391064231378944.0000, Gradient norm: 8.608517062484313e+74\n",
      "0.2\n",
      "Epoch 879, Loss: 5350383168934147532871174877297328747157384147516994165923711629736024211456.0000, Validation Loss: 2828657742525511374005792392207231345637065578976727065682646694665947971584.0000, Gradient norm: 1.0537648050487878e+75\n",
      "0.2\n",
      "Epoch 880, Loss: 6549380614599302741966853280904254210459493603246242456642777502200488787968.0000, Validation Loss: 3462547559546726046628732958533920343818548005393866023310992162692309975040.0000, Gradient norm: 1.2899088847702835e+75\n",
      "0.2\n",
      "Epoch 881, Loss: 8017068138959876163666664850513019348554305015347202779196735508425589391360.0000, Validation Loss: 4238489309568653832544043753455620803663843070820275471734708716139339317248.0000, Gradient norm: 1.5789718189841064e+75\n",
      "0.2\n",
      "Epoch 882, Loss: 9813658012400898977557349700598113912768374296774283595535558505024475627520.0000, Validation Loss: 5188316208912810696070159063771358239129804060789241191932878128289679409152.0000, Gradient norm: 1.932812491317925e+75\n",
      "0.2\n",
      "Epoch 883, Loss: 12012855811508079130624708859682393528715039742565931947387716441413179670528.0000, Validation Loss: 6350995158321367429177123051664732801637490001394395319899091686934735486976.0000, Gradient norm: 2.3659473093054664e+75\n",
      "0.2\n",
      "Epoch 884, Loss: 14704884209917396111209312391046860575955645977518256792372015983090835914752.0000, Validation Loss: 7774225370406538099328760506162331541384563367606305688877209880463889399808.0000, Gradient norm: 2.8961457438599605e+75\n",
      "0.2\n",
      "Epoch 885, Loss: 18000184387456857353248865073985103270970904352624395335175854002901889318912.0000, Validation Loss: 9516395242513020293040924228332853579904028072387876973641900877065786228736.0000, Gradient norm: 3.5451593265364842e+75\n",
      "0.2\n",
      "Epoch 886, Loss: 22033946908873051982991522207153125066860378307340004626473226486389908963328.0000, Validation Loss: 11648977756222252547191286705910930019733885313463578703644564939765415149568.0000, Gradient norm: 4.339614011889418e+75\n",
      "0.2\n",
      "Epoch 887, Loss: 26971657952645501825618140935537115272555024337786792930603008758543435169792.0000, Validation Loss: 14259462675399180442788054375099696095102582626636718510316551399400963833856.0000, Gradient norm: 5.312102514327766e+75\n",
      "0.2\n",
      "Epoch 888, Loss: 33015888425398439123657392116057134838479348142557402567640396339282897272832.0000, Validation Loss: 17454945836984998637957154461237286537482810816824995296065509255327030181888.0000, Gradient norm: 6.502521432877721e+75\n",
      "0.2\n",
      "Epoch 889, Loss: 40414604487131336749633303107170309842146994254420332461916236430606258405376.0000, Validation Loss: 21366522786143537229212527693375392795255490258089109159268437517687475666944.0000, Gradient norm: 7.959708019750976e+75\n",
      "0.2\n",
      "Epoch 890, Loss: 49471340428772520503079857364647088889030538454024564025059333939512890884096.0000, Validation Loss: 26154667005809924095552291168301020214085876698065408197216813373332115161088.0000, Gradient norm: 9.743443741583976e+75\n",
      "0.2\n",
      "Epoch 891, Loss: 60557651247058444401834823220695932558007502298395625357289849613963757617152.0000, Validation Loss: 32015813383936702780964581187559670978532260673014298531323437540458922770432.0000, Gradient norm: 1.1926906829979684e+76\n",
      "0.2\n",
      "Epoch 892, Loss: 74128355786929497706560261851274210825255390234348024294115134595827566116864.0000, Validation Loss: 39190417006929076416433379416797371082397310631738390320101081411005632741376.0000, Gradient norm: 1.4599674437889282e+76\n",
      "0.2\n",
      "Epoch 893, Loss: 90740195805406529596977812597676419637753396016353153503960302488665699909632.0000, Validation Loss: 47972817893410054327070160452836653573508727990517813244574417710395122778112.0000, Gradient norm: 1.7871397566096403e+76\n",
      "0.2\n",
      "Epoch 894, Loss: 111074676449997769064029625849222763788330706985465392437106798236454436732928.0000, Validation Loss: 58723316371637109688324400681129696794641165988365617145483814074935729455104.0000, Gradient norm: 2.1876299524638693e+76\n",
      "0.2\n",
      "Epoch 895, Loss: 135966025188327736280395867641231422575004496918641166784762428824434751045632.0000, Validation Loss: 71882954496135373998156892088526089117384194834977289211699806691283611680768.0000, Gradient norm: 2.6778682479740774e+76\n",
      "0.2\n",
      "Epoch 896, Loss: 166435416211499016307877995800041862724623503287055921650716626084936529477632.0000, Validation Loss: 87991609915089275591274668204053191360190081387958647725414471807521781710848.0000, Gradient norm: 3.27796679938088e+76\n",
      "0.2\n",
      "Epoch 897, Loss: 203732864376423187329664796446915085620007915112447676726917108590877127737344.0000, Validation Loss: 107710144494206855904770567132577597722753645749143541494546469411403899863040.0000, Gradient norm: 4.012544809092996e+76\n",
      "0.2\n",
      "Epoch 898, Loss: 249388507397227299944782320436641615060955442380846497307703787822166451421184.0000, Validation Loss: 131847516350231393572626905220374841890662659456350153550056224036406285041664.0000, Gradient norm: 4.911738535002892e+76\n",
      "0.2\n",
      "Epoch 899, Loss: 305275380151256215209110452559251979386667226782182468993734731138496553025536.0000, Validation Loss: 161393967572474227631867314180054624765541422711196410313537839901124623073280.0000, Gradient norm: 6.01243763846855e+76\n",
      "0.2\n",
      "Epoch 900, Loss: 373686256432240653038600245310629892656820154223890971987320229347317086420992.0000, Validation Loss: 197561649167456309326643488631754445630405326498569349890557281503719406436352.0000, Gradient norm: 7.359798592465585e+76\n",
      "0.2\n",
      "Epoch 901, Loss: 457427710603958602558241188411386542801364030158039557772732405280311854759936.0000, Validation Loss: 241834349875798904470836582943658644968055283624970597550387541851305125347328.0000, Gradient norm: 9.009097237880958e+76\n",
      "0.2\n",
      "Epoch 902, Loss: 559935258058707374756967462600998362419910064621044223696917954346336382877696.0000, Validation Loss: 296028368999281417794418483995500458085405555756718658079748272021537642512384.0000, Gradient norm: 1.1027996489562042e+77\n",
      "0.2\n",
      "Epoch 903, Loss: 685414298148464372023343964054518591044974390478762014513635240545741432684544.0000, Validation Loss: 362367030561957400235569238780263072842317029203285084143714303829069965295616.0000, Gradient norm: 1.3499322225364113e+77\n",
      "0.2\n",
      "Epoch 904, Loss: 839012641809913889002390700984545436815739493533606647433201502429378913501184.0000, Validation Loss: 443571895768575131594799131452196396687866418936902241302770005006599948599296.0000, Gradient norm: 1.6524461239781061e+77\n",
      "0.2\n",
      "Epoch 905, Loss: 1027031701874963339730255433009353943200519678584184570981280644413962137370624.0000, Validation Loss: 542974415775627131674069587439829526367825329864075081709682696207294881857536.0000, Gradient norm: 2.0227520664109576e+77\n",
      "0.2\n",
      "Epoch 906, Loss: 1257185010205313399894433334752546156479830798759908313336696092855115200856064.0000, Validation Loss: 664652605359607392261087292313076950042512258154444308751252356523416560336896.0000, Gradient norm: 2.47604194944634e+77\n",
      "0.2\n",
      "Epoch 907, Loss: 1538914667385169781928352380308675525756497879801481659355770415543657305210880.0000, Validation Loss: 813598344556004684325228227038890573239392802586462663171631381039197234135040.0000, Gradient norm: 3.0309121108926167e+77\n",
      "0.2\n",
      "Epoch 908, Loss: 1883778707404762282736691515742440983420123182189196255607314369117493408038912.0000, Validation Loss: 995922171863194974563631353881751921372136597716079820458990736907321946931200.0000, Gradient norm: 3.7101262464513905e+77\n",
      "0.2\n",
      "Epoch 909, Loss: 2305925269073663805058865501510919328542623616579182645259602123053518020411392.0000, Validation Loss: 1219103970706798649801778456120112468939280024581720978405466851854601972350976.0000, Gradient norm: 4.54154929637786e+77\n",
      "0.2\n",
      "Epoch 910, Loss: 2822673027172049574685875888100629614945990424850875642076485112563682097758208.0000, Validation Loss: 1492299833643262600926061980371258819352028044761758000938682939833106705678336.0000, Gradient norm: 5.559290612053423e+77\n",
      "0.2\n",
      "Epoch 911, Loss: 3455221695681975156176242204119824315520459933535506680769551609255529161949184.0000, Validation Loss: 1826717693488101769119180791995862934918857794160583774637246993912182029156352.0000, Gradient norm: 6.805103301182785e+77\n",
      "0.2\n",
      "Epoch 912, Loss: 4229521751682414868407730744710914145348929346130357926516778852120601691160576.0000, Validation Loss: 2236077131735567153657725383810462460888183983043705939141817817870779306475520.0000, Gradient norm: 8.33009716012375e+77\n",
      "0.2\n",
      "Epoch 913, Loss: 5177339060561743583668244833493267572783865598128815236980364890829898867802112.0000, Validation Loss: 2737172228032250166498343743903021994179899050816798391928987404290384839311360.0000, Gradient norm: 1.0196835466853397e+78\n",
      "0.2\n",
      "Epoch 914, Loss: 6337558079079736782181873497968918805347163603081639167961291174589907932807168.0000, Validation Loss: 3350560541753723343010308115737827737907947921149886769361524207006847825084416.0000, Gradient norm: 1.2481901656058791e+78\n",
      "0.2\n",
      "Epoch 915, Loss: 7757777100530663232695434895126234352325455506771175401131719142293423628746752.0000, Validation Loss: 4101406491336332107860079259801636385255025212818488325952581820450977039253504.0000, Gradient norm: 1.527904117487938e+78\n",
      "0.2\n",
      "Epoch 916, Loss: 9496260987363921536755028172499699310143198145583253898837244798384056626577408.0000, Validation Loss: 5020513731225167807787874764116705034369836828835276147293914498600864627818496.0000, Gradient norm: 1.8703007414766923e+78\n",
      "0.2\n",
      "Epoch 917, Loss: 11624331502636419699313418577842744126805921185890696858019718344754895177908224.0000, Validation Loss: 6145588879976609933765291245748731323426870064012194466832560691696564900462592.0000, Gradient norm: 2.289426949983909e+78\n",
      "0.2\n",
      "Epoch 918, Loss: 14229293304279222644836099143510417443137982616525030516620741302200033704148992.0000, Validation Loss: 7522788444296417213599417211856733487588149804170499772340578403557034764009472.0000, Gradient norm: 2.8024775069993427e+78\n",
      "0.2\n",
      "Epoch 919, Loss: 17418015641870191673498263939372470512438710935397622589177042801766993898766336.0000, Validation Loss: 9208612401982716603851365285173577660358540643961577032744281097130354589827072.0000, Gradient norm: 3.430500447848945e+78\n",
      "0.2\n",
      "Epoch 920, Loss: 21321316695973654261988406175441190272661730890830054650731560115396407818452992.0000, Validation Loss: 11272222128516981950668251713110678725745177856960229407019566150558763832049664.0000, Gradient norm: 4.1992605804327736e+78\n",
      "0.2\n",
      "Epoch 921, Loss: 26099330428732701483175887156920811106103805078145442021724599399153338421346304.0000, Validation Loss: 13798277760856766531342685382465264580959534303640463451478035783813089795768320.0000, Gradient norm: 5.140296493310068e+78\n",
      "0.2\n",
      "Epoch 922, Loss: 31948076122184639500793147356187898078949678057326411081953907309394344074543104.0000, Validation Loss: 16890411402033226879203038568715034522676017479094765464195594941317117844127744.0000, Gradient norm: 6.292214434669036e+78\n",
      "0.2\n",
      "Epoch 923, Loss: 39107500121353313339031533860788826118470448991481121111167671993139776112820224.0000, Validation Loss: 20675478655694192481799180475843326185558982913361805445421443926391054856617984.0000, Gradient norm: 7.702272143909422e+78\n",
      "0.2\n",
      "Epoch 924, Loss: 47871319696763882785031686372835781596183900762358081018486204911376519921664000.0000, Validation Loss: 25308762910926346867970337737889151702074280211672824541987518179402622129143808.0000, Gradient norm: 9.428317612949162e+78\n",
      "0.2\n",
      "Epoch 925, Loss: 58599072873453477775978607352051434973413296466316133562344620336592775083458560.0000, Validation Loss: 30980345884523126742291649293106954655926094373700028341106446628998623476580352.0000, Gradient norm: 1.1541162315452553e+79\n",
      "0.2\n",
      "Epoch 926, Loss: 71730868573912346502075705342495484280522113544034069069809210815336734686969856.0000, Validation Loss: 37922905773886328709716912259163577584020417653245344412623452361942991009480704.0000, Gradient norm: 1.4127486266339081e+79\n",
      "0.2\n",
      "Epoch 927, Loss: 87805442203486028627396955048381752065464457341211096925375739853574104646942720.0000, Validation Loss: 46421262941854918024246331739361849419603633706335456326860294587654535978680320.0000, Gradient norm: 1.729339409241062e+79\n",
      "0.2\n",
      "Epoch 928, Loss: 107482257413423926390162770863677605207024619159352440295378479170046267012153344.0000, Validation Loss: 56824064747715549501179121439635742346882699870309069883414594857609927696842752.0000, Gradient norm: 2.1168768002838748e+79\n",
      "0.2\n",
      "Epoch 929, Loss: 131568560772271429075921042943530261372936707631964633437310277880085200938991616.0000, Validation Loss: 69558088897689626896438195274320982361376553558757193203703756186114000378920960.0000, Gradient norm: 2.5912596241282127e+79\n",
      "0.2\n",
      "Epoch 930, Loss: 161052499270683578570656530332094994832998470340634131483319218962363113153757184.0000, Validation Loss: 85145752113648378187773414877629821990441086021566327286821490411933873576345600.0000, Gradient norm: 3.1719495620796896e+79\n",
      "0.2\n",
      "Epoch 931, Loss: 197143659314087832310111592258381902322295043078568542069393856892569846821158912.0000, Validation Loss: 104226542417838906020827851328768605560035995460396358342558446325182842814857216.0000, Gradient norm: 3.8827695730266556e+79\n",
      "0.2\n",
      "Epoch 932, Loss: 241322690326134292895124834395862234285436093030695266023191805429369045627437056.0000, Validation Loss: 127583254298792789370512472311489856963293984397152869203100381625123550875615232.0000, Gradient norm: 4.752881236654056e+79\n",
      "0.2\n",
      "Epoch 933, Loss: 295402048784440418241948160744085268438850343848248414808447778835467776787742720.0000, Validation Loss: 156174103063064304651003960834294838904315130994295416325227530558835103734169600.0000, Gradient norm: 5.8179811149929165e+79\n",
      "0.2\n",
      "Epoch 934, Loss: 361600354728826696753892452849849560518683605023746135506027954203121581918519296.0000, Validation Loss: 191172035872606080447913666095166383127810636443515320702580294527123823605579776.0000, Gradient norm: 7.121765213355776e+79\n",
      "0.2\n",
      "Epoch 935, Loss: 442633411237533821475770350891702935320497395142425873145332605101125267382861824.0000, Validation Loss: 234012852213526973051522498103830237672402650586658544311573835104266041834864640.0000, Gradient norm: 8.717721620556709e+79\n",
      "0.2\n",
      "Epoch 936, Loss: 541825620969604442734496317655435154142333614307174179365592607622193808932864000.0000, Validation Loss: 286454107951240942630975058408336923181787865117546982040516933874670195561201664.0000, Gradient norm: 1.0671324871957039e+80\n",
      "0.2\n",
      "Epoch 937, Loss: 663246370666659725705669026112608482991960517923391068525534117981112365536509952.0000, Validation Loss: 350647219526509278966634683366472305898237471864406091084463784091381652334313472.0000, Gradient norm: 1.306272205966322e+80\n",
      "0.2\n",
      "Epoch 938, Loss: 811876978824472900265407506013100307235870617298779898306993864502460808729460736.0000, Validation Loss: 429225726386163951348703692990114948385445510128587926899734835125718590678892544.0000, Gradient norm: 1.5990020888260953e+80\n",
      "0.2\n",
      "Epoch 939, Loss: 993815055606888576363880751047167952874999170030274846271183048710978328510595072.0000, Validation Loss: 525413332638166819582390210003027812875221679901232622992630598621923554755608576.0000, Gradient norm: 1.9573314569445423e+80\n",
      "0.2\n",
      "Epoch 940, Loss: 1216524658921824383011748453622072014257997130010543541490205450472302170211352576.0000, Validation Loss: 643156160368591815562076662259218348461760150904514418728707346291539359733645312.0000, Gradient norm: 2.395960867791779e+80\n",
      "0.2\n",
      "Epoch 941, Loss: 1489142509378787164512492937112326367330210125580751382855789654314065611949342720.0000, Validation Loss: 787284640347974065910756902376558955211382460952047287790635032103595105882996736.0000, Gradient norm: 2.932885209412025e+80\n",
      "0.2\n",
      "Epoch 942, Loss: 1822852826677847129135732638580703407304111769879525604735001243505817621429747712.0000, Validation Loss: 963711681736240940408505531179198241077881089545715526894118519306210669810941952.0000, Gradient norm: 3.5901319454835796e+80\n",
      "0.2\n",
      "Epoch 943, Loss: 2231346165192448740568440345497248279915328957936998441080629642262841032391524352.0000, Validation Loss: 1179675250750982896816162959508134502507465097051495979017225882615285529912016896.0000, Gradient norm: 4.394664797864912e+80\n",
      "0.2\n",
      "Epoch 944, Loss: 2731381072597677737084920712386364417334335952170859835206804653103149333958623232.0000, Validation Loss: 1444035310153344788762639037349587523768098480440299158165134430183338210679062528.0000, Gradient norm: 5.379489940443298e+80\n",
      "0.2\n",
      "Epoch 945, Loss: 3343471613738334342815988564753253174435049321605882257510555676549665457189158912.0000, Validation Loss: 1767637301572785250270258163398095776305717479512315713150582823228835915509006336.0000, Gradient norm: 6.585010086182286e+80\n",
      "0.2\n",
      "Epoch 946, Loss: 4092728965586056556347622136146429563758511925009555537089602941512899573437169664.0000, Validation Loss: 2163757082629591420895252605110812186537765713319341232373573221350479270403637248.0000, Gradient norm: 8.060682019148664e+80\n",
      "0.2\n",
      "Epoch 947, Loss: 5009891609942052457000223668544273482256534428227155536022224803279888324780621824.0000, Validation Loss: 2648645572518734993396618274138615040707592048600569937914803295539209171952992256.0000, Gradient norm: 9.867045572210525e+80\n",
      "0.2\n",
      "Epoch 948, Loss: 6132586387814650944156575341660447173696520422697212688915685342015775710078042112.0000, Validation Loss: 3242195450284763984674219350535273086122692715283234109902158651343370838649864192.0000, Gradient norm: 1.2078207289755108e+81\n",
      "0.2\n",
      "Epoch 949, Loss: 7506872150562263819914543444742909406399450234381987272977387192808569728042795008.0000, Validation Loss: 3968757257261482389319458784764385549261154462458475643409201189995065685066121216.0000, Gradient norm: 1.4784880668348958e+81\n",
      "0.2\n",
      "Epoch 950, Loss: 9189129336499860550440186466764790642576158941756359705621447037323442815317835776.0000, Validation Loss: 4858138384495683942951901785237837617162613213597096525798747461677296402355453952.0000, Gradient norm: 1.8098107702020636e+81\n",
      "0.2\n",
      "Epoch 951, Loss: 11248372993350870805518134236254206117659325935868690699491209805069714801565892608.0000, Validation Loss: 5946825928879266303185764165098631107823794662501900598655376970547064110187544576.0000, Gradient norm: 2.2153814409549473e+81\n",
      "0.2\n",
      "Epoch 952, Loss: 13769084138904829973113569061951376588021794813960201851385682166185286726420791296.0000, Validation Loss: 7279483585987209603033050874423256404067538081779329119430406959361439375099428864.0000, Gradient norm: 2.711838723547685e+81\n",
      "0.2\n",
      "Epoch 953, Loss: 16854675617203437326114409363703539743093282797268839990183816855464929450858119168.0000, Validation Loss: 8910783990047580402508857915663845850294596746830904897286879438432674418826149888.0000, Gradient norm: 3.3195499098172214e+81\n",
      "0.2\n",
      "Epoch 954, Loss: 20631734637925393250291004964431937671821449491638681392108016991378279732843905024.0000, Validation Loss: 10907651673277332394069446726908742601354204036150937119482912592544550084092624896.0000, Gradient norm: 4.063446512538801e+81\n",
      "0.2\n",
      "Epoch 955, Loss: 25255216050274743258949296802072790734341531604228064888585503613643800368121905152.0000, Validation Loss: 13352008662586209640265708751799714919930361095282215964935279009267420577073725440.0000, Gradient norm: 4.974047087357365e+81\n",
      "0.2\n",
      "Epoch 956, Loss: 30914799406812790858806843087566511253912667001955735868438366100783542147330605056.0000, Validation Loss: 16344135352482526302133252535497335022755658203056378840532599186414376306444599296.0000, Gradient norm: 6.088709264636113e+81\n",
      "0.2\n",
      "Epoch 957, Loss: 37842670617465401302742990481927080510653658916544760167865283078455024020390674432.0000, Validation Loss: 20006784534884154646134640935025736970828526061321681290884240710464179930656669696.0000, Gradient norm: 7.453162356161282e+81\n",
      "0.2\n",
      "Epoch 958, Loss: 46323047438127312373502242222114737387539529782257150215974436787987312824207540224.0000, Validation Loss: 24490217365000109482208266748843782197447713882952994860366397132130893351981416448.0000, Gradient norm: 9.123383412300194e+81\n",
      "0.2\n",
      "Epoch 959, Loss: 56703839579562824519717489034314538462644430463085094671419434728914072190492606464.0000, Validation Loss: 29978367865120102267754359583708672454543627376070110981531752843915770574699233280.0000, Gradient norm: 1.116789369535549e+82\n",
      "0.2\n",
      "Epoch 960, Loss: 69410921795666303948705025016561990689913936439175677372253781423102145058620571648.0000, Validation Loss: 36696388866716842501161841872763940890336960974212815851644298771541496762428555264.0000, Gradient norm: 1.3670569782544703e+82\n",
      "0.2\n",
      "Epoch 961, Loss: 84965605508318316500671138022635228570862475163795346630256270091230315346034425856.0000, Validation Loss: 44919888965139463246244252764574147096947387683598129617954608456685108039109312512.0000, Gradient norm: 1.6734084624851505e+82\n",
      "0.2\n",
      "Epoch 962, Loss: 104006025746886226222995164202436422512065320862417677671955557583983235625125937152.0000, Validation Loss: 54986239435416856809408869319634226923045654510181618638460081030164172612160192512.0000, Gradient norm: 2.048411973210132e+82\n",
      "0.2\n",
      "Epoch 963, Loss: 127313320807240385004909433360183376881488203289946670001461438557555389516327419904.0000, Validation Loss: 67308414978394084703042361929399651538233906031800975463239041237570269001717645312.0000, Gradient norm: 2.5074521290272593e+82\n",
      "0.2\n",
      "Epoch 964, Loss: 155843678657749023321218991951406117740442243108320970867781907929319243688204828672.0000, Validation Loss: 82391936117486910535020152578011784210670841663768165219846328508109587958105899008.0000, Gradient norm: 3.069361174212568e+82\n",
      "0.2\n",
      "Epoch 965, Loss: 190767564804566064964972784640374601988738671214070770006755594332008865863022149632.0000, Validation Loss: 100855608312380008313931706683792670899312239307946045139582201774991680705098940416.0000, Gradient norm: 3.7571915765420146e+82\n",
      "0.2\n",
      "Epoch 966, Loss: 233517740949801161880243109317544239096347402932708293184727467894138989308285026304.0000, Validation Loss: 123456908617314726710492837467883174303900999364275666351440505143020462985227272192.0000, Gradient norm: 4.599161760902832e+82\n",
      "0.2\n",
      "Epoch 967, Loss: 285848044420773900958717268568097645161572796323789639254405303319982646573848854528.0000, Validation Loss: 151123061378363528198955256657387674735776301770962960241341813644345062109418094592.0000, Gradient norm: 5.629813777667055e+82\n",
      "0.2\n",
      "Epoch 968, Loss: 349905339812042796928790767132653462118631680874285919889272748823651293101004161024.0000, Validation Loss: 184989077858422954397756249676743577003255147106053305243559005224347260909856489472.0000, Gradient norm: 6.891430399479585e+82\n",
      "0.2\n",
      "Epoch 969, Loss: 428317594675429060618518828487084196492917117828756853632917705128615488349215391744.0000, Validation Loss: 226444320375640035940384848180078757033977257166362734326824777271971263680736133120.0000, Gradient norm: 8.43576978323278e+82\n",
      "0.2\n",
      "Epoch 970, Loss: 524301692586604981214274578729212692182403199001171162413091310390190166576440803328.0000, Validation Loss: 277189501261415952557015162564739193756722286317198648174560548552128030821735989248.0000, Gradient norm: 1.0326188862195739e+83\n",
      "0.2\n",
      "Epoch 971, Loss: 641795406647926568386019682739443028328043768345058342521331413296926568436560035840.0000, Validation Loss: 339306455035372214750550251979267542884243906562974762552167386568342450885745442816.0000, Gradient norm: 1.264024258102408e+83\n",
      "0.2\n",
      "Epoch 972, Loss: 785618947675510010230030836121682639612625997808239526164587191834669404176506683392.0000, Validation Loss: 415343546219283380597006501344669731749917130413215024039828202737274274968074452992.0000, Gradient norm: 1.547286560795674e+83\n",
      "0.2\n",
      "Epoch 973, Loss: 961672714627818248896774201793472620683585934918924860724840726507033651303833141248.0000, Validation Loss: 508420216668221330896882667739697654267037123124956163918621810638981780991566151680.0000, Gradient norm: 1.8940267054787336e+83\n",
      "0.2\n",
      "Epoch 974, Loss: 1177179360039594707634889612250831184678306715053558537802093821008503136182654205952.0000, Validation Loss: 622354961500928140634084527291773756779367530762995901109065377265229645566087004160.0000, Gradient norm: 2.3184697986531194e+83\n",
      "0.2\n",
      "Epoch 975, Loss: 1440980101259851373313423621057679115630124619695795988174991866666596810438308003840.0000, Validation Loss: 761821983875944149441006075109740401923866055833745775983720280885879342659583082496.0000, Gradient norm: 2.838028730913792e+83\n",
      "0.2\n",
      "Epoch 976, Loss: 1763897433741116594937445024143468397643434962993684661735790260647845322344921825280.0000, Validation Loss: 932542955417274078803274289954950673961208952080134757708340951378137762992077406208.0000, Gradient norm: 3.474018545409235e+83\n",
      "0.2\n",
      "Epoch 977, Loss: 2159179126788949514876573311709663804627944356870962920302442102349435158469019697152.0000, Validation Loss: 1141521749311970686030769844953000033418848971172262230114270992656335751491065217024.0000, Gradient norm: 4.2525308931461546e+83\n",
      "0.2\n",
      "Epoch 978, Loss: 2643041716815224788862191864051263048676747322107956086249867077220441346547673726976.0000, Validation Loss: 1397331776067293389494901595685815877036328216885898220052344631586867432935194099712.0000, Gradient norm: 5.20550444989987e+83\n",
      "0.2\n",
      "Epoch 979, Loss: 3235335795050223828745428373372641758760283052455198722844416870554397312916922564608.0000, Validation Loss: 1710467709953164160631678039910194484004481179258790583638872341795093475373107642368.0000, Gradient norm: 6.372035208868282e+83\n",
      "0.2\n",
      "Epoch 980, Loss: 3960360383318549705656585392061775506149012158573928428678033226133194673311023366144.0000, Validation Loss: 2093776035800622830321263355755837018921788550869177420270649255352280748939267801088.0000, Gradient norm: 7.799980404173508e+83\n",
      "0.2\n",
      "Epoch 981, Loss: 4847859807861324260191573505471868321514283735280701459996987097962907501053993811968.0000, Validation Loss: 2562982079452999749646380400680339149369092755654487734031821853609040040713403760640.0000, Gradient norm: 9.547921866598777e+83\n",
      "0.2\n",
      "Epoch 982, Loss: 5934243968217901555053082873018618187261290595352799171064103491870281777267754401792.0000, Validation Loss: 3137335143434001889648469932894387963683633648215160587078823406653196997981909286912.0000, Gradient norm: 1.1687569358750816e+84\n",
      "0.2\n",
      "Epoch 983, Loss: 7264082063021965668359629482050998421922731849228947632576197486232514068521607495680.0000, Validation Loss: 3840398214694793854338029355495563592898773488444033278225690857044265219013430214656.0000, Gradient norm: 1.4306702487111063e+84\n",
      "0.2\n",
      "Epoch 984, Loss: 8891931053209422407965038734334801977354596866790718651344618261516763266177841496064.0000, Validation Loss: 4701014642410075697779506767768717910768011548924380537424233201675890485472847200256.0000, Gradient norm: 1.751277188369873e+84\n",
      "0.2\n",
      "Epoch 985, Loss: 10884573875826670227854492751816279109631835717894118187389870727977939115131445182464.0000, Validation Loss: 5754491444036419576560626095792475057314669598326990369723313774792303136127695454208.0000, Gradient norm: 2.1437307396779417e+84\n",
      "0.2\n",
      "Epoch 986, Loss: 13323759231755049194488945742671977700155714754122748557833615801334870973652431536128.0000, Validation Loss: 7044047785078091200301999409109116050863930713087643496248395005876976363918969536512.0000, Gradient norm: 2.624131413781394e+84\n",
      "0.2\n",
      "Epoch 987, Loss: 16309555347870266326960173937219052198915723660957217767605458813795827440228965023744.0000, Validation Loss: 8622588056827338693316315245135755771620580216193168667381514342374392385440837533696.0000, Gradient norm: 3.2121877758905693e+84\n",
      "0.2\n",
      "Epoch 988, Loss: 19964455302619960141739141931542981950465807071132565050955802801709991673835791843328.0000, Validation Loss: 10554872293064268930450323479553718932057576858322862077677845704805737844041974808576.0000, Gradient norm: 3.932024994400828e+84\n",
      "0.2\n",
      "Epoch 989, Loss: 24438402337091142696495078627647828729855041614851736016139711158784026942500975411200.0000, Validation Loss: 12920172967637644619642621915665808157333172842611461146017066687660922732949689860096.0000, Gradient norm: 4.813174582331609e+84\n",
      "0.2\n",
      "Epoch 990, Loss: 29914941316288554300567354967531149441538389462095275052620882078921117988487054753792.0000, Validation Loss: 15815527168752840226358951480648078262285779375816645263842573240364950372217471893504.0000, Gradient norm: 5.891785935489275e+84\n",
      "0.2\n",
      "Epoch 991, Loss: 36618748705955986679464970752801283060866041819567098311738058031706374448388761452544.0000, Validation Loss: 19359717571280610790472041654049968123696817863503118157547168423062420096179983351808.0000, Gradient norm: 7.212109371028338e+84\n",
      "0.2\n",
      "Epoch 992, Loss: 44824849984239179455856653251839483810425528415426021634461847747646086265814101524480.0000, Validation Loss: 23698145527532637128349199527975724050089527756496605610155497910713432141333780234240.0000, Gradient norm: 8.828311508462034e+84\n",
      "0.2\n",
      "Epoch 993, Loss: 54869902634951100007131316459761834186237291408945271525180409277801973379239128334336.0000, Validation Loss: 29008796196346903264003733183145256445586887456701244855626481536731923125328181985280.0000, Gradient norm: 1.0806697469610112e+85\n",
      "0.2\n",
      "Epoch 994, Loss: 67166007610234175950157029273830982199945583637332092288135708712849771142682345734144.0000, Validation Loss: 35509540431487313939099855689332155837042761793595970606909739198988861810720437698560.0000, Gradient norm: 1.3228431063826658e+85\n",
      "0.2\n",
      "Epoch 995, Loss: 82217615881542332867950907754986447896343488661961430808621090895416653070647846502400.0000, Validation Loss: 43467072991268135703549390271641332748003816651149762420652205107769359825437959651328.0000, Gradient norm: 1.6192864554829396e+85\n",
      "0.2\n",
      "Epoch 996, Loss: 100642223674685811231717122635503071205038259639733054933977588848781326180099137994752.0000, Validation Loss: 53207853761826211852698967009454516838368888748763561633163281817071394535839249727488.0000, Gradient norm: 1.982161461369854e+85\n",
      "0.2\n",
      "Epoch 997, Loss: 123195705416452020243313763710286026208264081511109232990837602260019221148629888663552.0000, Validation Loss: 65131500860630803123088067112748771497710863772328985114156420421280952735440257941504.0000, Gradient norm: 2.426355167509934e+85\n",
      "0.2\n",
      "Epoch 998, Loss: 150803323683662625400431094043285048016551387874214945110134934382367746574324443643904.0000, Validation Loss: 79727185075858901817754872164201294939751305115529793354814375190019578983686185418752.0000, Gradient norm: 2.9700907386392035e+85\n",
      "0.2\n",
      "Epoch 999, Loss: 184597688346062467213981822425332670787201134989839570760885126546128697883129402097664.0000, Validation Loss: 97593698227863821245286422300902700364495314321832522864287386444166554319072719273984.0000, Gradient norm: 3.635675070935081e+85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pietr\\AppData\\Local\\Temp\\ipykernel_17788\\3523237173.py:19: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  plt.plot(np.arange(-1, 1, 0.001), float(w_star)*(np.arange(-1, 1, 0.001)), color = 'k')\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAGsCAYAAADg5swfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1z0lEQVR4nO3dB3hUZd7+8TuhhB46SJMiCKgUKYoVEEVfpSyuritKsS0IrhQVWAsiKviqf1mRBRbrqqysBbCtDRX0FQsggkgRQelFkYQioYT/9TvHcHISAikzc6Z8P9c1F5yHYebJc0Lm5qlJhw8fPiwAAIAAJAfxpgAAAIYgAgAAAkMQAQAAgSGIAACAwBBEAABAYAgiAAAgMAQRAAAQGIIIAAAIDEEEAAAEhiACAAACEzNBZN68eerWrZtq1aqlpKQkzZo1q9CvtXr1apUvX14VK1b0lb/22mtq27atU162bFm1atVKzz//fAhqDwAAYjqI7NmzRy1bttSkSZOK9DoHDhzQn//8Z5177rm5/qxy5cq68847NX/+fC1ZskT9+/d3Hu+++26R3hMAABxdUiweemc9IjNnzlTPnj2PlGVkZDgh4t///rd27typU089VQ899JA6duzo+7sjRozQpk2bdMEFF2jIkCHOc4/l9NNP16WXXqqxY8eG7esBACBRxUyPyPEMHjzY6cl46aWXnN6MK664QhdffLG+//77I8/58MMP9fLLL+erV8Xy2Zw5c7Ry5Uqdd955Ya49AACJqbjiwLp16/TMM884v9ocEnPbbbfpnXfeccoffPBB/fLLL+rXr59eeOEFVahQIc/XSktLU+3atZ0elmLFiukf//iHLrzwwgh+NQAAJI64CCJLly7VoUOH1KRJE1+5hYkqVao4v7/xxht19dVXH7d3wyaxLl68WLt373Z6RIYNG6aGDRvmGuIBAABFFxdzRGbMmKHevXtr2bJlTi9GduXKlVPNmjWdlTAWLrLYl52Zmek8/5///Keuu+66o77XDTfcoPXr1zNhFQCAMIiLHpHWrVs7PSLbtm076moYY/NH7DlZZs+e7Uxm/eyzz5yhmLxYWLGeFQAAkMBBxHozbP+PLGvXrnWGUGzJrQ3JWI9Inz599OijjzrBZPv27c7QSosWLZxVL82aNfO93oIFC5ScnOysrskybtw4Zx+RRo0aOeHj7bffdvYRmTx5ckS/VgAAEkXMBBELDp06dTpybXM3TN++ffXss886k1Lvv/9+DR8+XBs3blTVqlV15pln6rLLLivQXiU333yzNmzYoNKlS6tp06bO5NY//elPYfmaAABIdDE5RwQAAMSHuNlHBAAAxB6CCAAACExUzxGxFSu2Hbvt7WFLdgEAQPSzWR+7du1yNhm1hSExG0QshNStWzfoagAAgEKwfbjq1KkTu0HEekKyvpBjbcsOAACiR3p6utORkPU5HrNBJGs4xkIIQQQAgNiSn2kVTFYFAACBIYgAAIDAEEQAAEBgonqOCAAgfpd3Hjx40HcYKWJLiRIlcp14XxgEEQBARO3fv1+bN2/W3r17afkYn4hqS3PLlStXpNchiAAAIrpRpZ2ebv+Tts2uSpYsyYaVMdqjZafc2yGxjRs3LlLPCEEEABDR3hALI7bHRJkyZWj5GFatWjX9+OOPOnDgQJGCCJNVAQARd7xtvxH9QnX0Ct8JAAAgMBELIuPHj3fS05AhQyL1lgAAIMpFJIh89dVXmjp1qlq0aBGJtwMAADEi7EFk9+7d6t27t6ZNm6ZKlSqF++0AAAgp680/1uPee++lxaM5iAwaNEiXXnqpunTpctznZmRkOCf2ZX+Exb590sknS/ffH57XBwCE1aHMw5r/wy+avXij86tdh4vteZL1mDBhgnMIa/ay2267LddGbYiSIPLSSy9p0aJFGjduXL6eb89LTU098rDlXWExc6a0apV0990WdS0Bhed9AAAh9863m3XOQx/qz9M+160vLXZ+tWsrD4eaNWseedhnk/WCZF2vWLHCOer+v//9r9q0aaOUlBR9+umn6tevn3r27Ol7HZsj2bFjxyPXtox53LhxatCggUqXLq2WLVvqlVdeUaIJWxBZv369br31Vr344osqVapUvv7OqFGjlJaWduRhrxEWV13lv7b6LV4cnvcCAISMhY2BLyzS5rR9vvItafuc8nCFkeMZOXKksyhj+fLl+Z4PaSHkX//6l6ZMmaJly5Zp6NChuuaaazR37lwlkrBtaLZw4UJt27ZNp59++pEyO1Ng3rx5euKJJ5xhmJwboFiStEfYWS/I4cNSt27Sm2+6Za1bS6NHS4z1AUBUsuGXMW98p6MNwliZ7Wphf35h85oqlhyaPS7y67777tOFF16Y7+fbZ+CDDz6oDz74QB06dHDKGjZs6PSm2OKO888/X4kibEHkggsu0NKlS31l/fv3V9OmTTVixIiQHJRTZG+8Ic2aJf3hD+71mDHSI49IO3dKxdl0FgCiyZdrd+TqCckZRuzP7XkdGlWJaN3atm1boOevXr3aOWvnwhzhxXaebW3/MU4gYfu0tTGzU0891VdWtmxZValSJVd5oGwMb9s2qXp193rPHjtSUFq5UmrSJOjaAQB+t21X3iGkMM8LJft8y7lzrE1czc62Qs++otS89dZbql27tu95ERkZiCLsrGqqVbNZQ9LZZ3stY6tqHnssuDsDAPCpXr5USJ8X7nNYbEVNdouzzUVs3ry5EzjWrVunk046yfcI20KNKBXRIPLxxx87S5+iks0b+fRT6V//8sqGDZPq13dDCgAgUO0bVNYJqaWcuSBHY+X25/a8oHXu3FkLFixwJqN+//33Gj16tL799lvfqIEt+x06dKiee+45/fDDD84q04kTJzrXiYQekZyuvVbasMG7/uknyeazrFsX2TsDAPCxCaijuzV3fp8zjGRd259HeqLq0XTt2lV333237rjjDrVr1067du1Snz59fM8ZO3as8xxbPdOsWTNdfPHFzlCNLedNJEmHcw5iRRHb0MzWbNtSXttAJqKsWZo1c+eKZHnqKem66yJbDwCII/v27dPatWudD9v8bu2Qky3RtdUx2SeuWk+IhZCLTz0hhLVFYe9lQT6/WRpyrKGaFSukSZOkwYPdsuuvd68XLHD/HAAQcRY2bImurY6xiak2J8SGY6KhJwQFRxA5nkGDpIsvlk46yb1etMimQ0tbtkg1ahSiyQEARWWhI9JLdBEezBHJj0aNJDs7oEq2b/qaNaUE3IoXAIBQIojkl01Y/fln/0F5V1xhM5JCekMAAEgkBJGCuvNOKfuOse+9584X+fXX0N4ZAAASAEGkMGxn2P37/WWVK0vvvBOauwIAQIIgiBSWbQNvS3xvu80ru+QS6eqrQ3NnAABIAASRonr4YemLL7zrf//bHar5/RwBAACQN4JIKLRvL+3d6y8rX97dMh4AAOSJIBIqpUu7QzU33OCVnXuuuw8JAAD51K9fP/W0k+F/17FjRw0ZMiTi7WfnwyUlJWnnzp1hfR+CSKhNmyZ9+KF3/Y9/uEM1GRkhfysAQGQDgn0w26NkyZLOSbn33XefDto+U2H02muvOefSRFN4CCWCSDh06iSlpfnLbB9+25UVABCz7GC6zZs3OyfqDh8+XPfee68etrmCOezPubKyCCpXruyc1huvCCLhYof82FBNr15eWZs20l13he0tASDm2M/JPXuCeRTizNeUlBTVrFlTJ554ogYOHKguXbro9ddfPzKc8sADD6hWrVo6+eSTneevX79eV155pSpWrOgEih49eujHH3888nqHDh3SsGHDnD+vUqWKc1pvzrNocw7NZGRkaMSIEapbt65TH+uZeeqpp5zX7WT/EZZUqVIlp2fE6mUyMzOdU37tgLrSpUurZcuWeiXH7uBvv/22mjRp4vy5vU72eoYTZ82E26uvSm+8IXXv7l4/8IC70sb+ERSn+QEkOJvoX65cMO9tqxvLli3SS9iH9i+//OL8fs6cOc5Js++//75zfeDAAXXt2lUdOnTQJ598ouLFi+v+++93elWWLFniDO88+uijevbZZ/X000+rWbNmzvXMmTPVuXPnPN+zT58+mj9/vh5//HEnUNgJuD///LMTTF599VVdfvnlWrlypVMXq5+xEPLCCy9oypQpaty4sebNm6drrrlG1apV0/nnn+8Epl69emnQoEG66aabtGDBAqfHJxL4JIyEbt3c7eGrVnWvrcvO9iH57jupWbOIVAEAEDrWa2HB491339Utt9yi7du3q2zZsnryySedgGHsg996IqzMeifMM8884/R+2FyOiy66SBMmTNCoUaOcEGAsKNhr5mXVqlX6z3/+44Qd640xDRs2PPLn1utiqlev7rxPVg/Kgw8+qA8++MAJRVl/59NPP9XUqVOdIDJ58mQ1atTICULGenSWLl2qhx56KOzfNgSRSLED86y77fzzpXnz3LLmzd3ekeybogFAIilTJrh9l+y9C+jNN99UuXLlnN4OCxlXX321M0/EehJOO+20IyHEfPPNN1q9enWu+R379u3TDz/8oLS0NGe+yRlnnHHkz6zXpG3btrmGZ7IsXrxYxYoVc8JDflkd9u7dqwsvvDDXPJbWrVs7v1++fLmvHiYrtIQbQSTS5s6Vpk+Xevd2r2+/XXrsMRtIlJKZsgMgwVhPQRGHRyLJ5k5Y74EFDpsLYsEhi/WIZLd79261adNGL774Yq7XsSGRwij9+1BLQVg9zFtvvaXatWv7/szmmASNT74g2DbwGzd615s2uaf7RmhiEACgcCxs2OTQevXq+ULI0Zx++unO6hobJrG/k/2RmprqPE444QR9kW13blsKvHDhwjxf03pdrCdmrv2n9iiyemRsEmyW5s2bO4Fj3bp1ueph80qMzU/58ssvfa/1+eefKxIIIkGpVcumMUunnOKVNWjg7kMCAIh5vXv3VtWqVZ2VMjZZ1SaV2tyQv/71r9qwYYPznFtvvVXjx4/XrFmztGLFCt18883H3AOkfv366tu3r6677jrn72S9ps0bMbaax+aj2BCSzVux3hAbGrrttts0dOhQPffcc86w0KJFizRx4kTn2gwYMMAJTbfffrsz0XX69OnOJNpIIIgE3SX57bfS5Mle2U03Sa1aFWpZGQAgepQpU8ZZnWK9JzYZ1Xodrr/+emeOiK1oMcOHD9e1117rhAubk2Gh4Q9/+MMxX9eGhv74xz86oaVp06a68cYbtcdWYkrO0MuYMWM0cuRI1ahRQ4MHD3bKbUO0u+++21k9Y/WwlTs2VGPLeY3V0VbcWLixlTg2adYmuEZC0uG8ZsREgfT0dKfryib0ZN20uLVmjdSokb9s82apZs2gagQAIWcfwva/ePsALGUbPSIu72VBPr/pEYkWtvzKxvSyB48TTpBmzAiyVgAAhBVBJJrYqhnrBcm+bvuqq6Tf14oDABBvCCLR6I47pGXLvOs5c9z5JDt2BFkrAABCjiASrWyzM9uBNfvyMNsU7e23g6wVAAAhRRCJZrYN/IED0qhRXtmll0p/+lOQtQKAIovidRKI8D0kiMQCW0L11Vfeta0Xt6GaoLZFBoBCKmH/wXLOuttLG8a4/dZrL9uPs1iRXoct3mNF27bSb7/Z/r5emZ1fYLvrnXdekDUDgHyzDy07jG3btm1H9trIOhAOscN2d7UN0+z+HW+H2eMhiMQSW6dtXWEDB9oRjW6ZHXw0YIB/UzQAiGI1f9+mICuMIDYlJyc7G6EVNUiyoVmssp6Qjh39ZdZjwgZBAGKEnYdip9giNtm5NhZGjqYgG5rRIxKrrCdk1y53eCaLDdvYXBIbxgGAGBimKer8AsQ+JqvGsnLl3KGaK6/0ytq186+yAQAgihFE4oFtA//mm971+PHu/iN0eQIAohxBJF7Y/iK//OJd27k1JUtK330XZK0AADgmgkg8qVzZHarp3NkrO+UU/9k1AABEEYJIPLKzaV56ybseOdI91TczM8haAQCQC0EkXtk28HaSb5atW22KurR2bZC1AgDAhyASz7J6QVq18soaNvQ2QwMAIGAEkXhnO959/bU0bZpXZjuznnqqO58EAIAAEUQSxQ03+Idlli2z/XmlTZuCrBUAIMERRBJJ/frust46dbyy2rWl6dODrBUAIIERRBKN9YKsXy898ohX1rt37nNrAACIAIJIoho+XFq+3H+Ins0nyb4pGgAAYUYQSWRNm7rbwGc/sbdqVemNN4KsFQAggRBEEp2dSfPbb9Jdd3ll3btLvXoFWSsAQIIgiMA1dqy0aJHXGjNnukM16em0EAAgbAgi8LRuLe3b52+R1FTpo49oJQBAWBBE4JeS4m50NmiQV2aH6N14Iy0FAAg5ggiO7oknpE8+8a6ffNIdqrH5JAAAhAhBBHk75xxp1y5/WZky0pdf0moAgJAgiODYypVzh2r+/Gev7IwzpDvuoOUAAEVGEEH+2Dbw//2vd/3ww+5Qje1DAgBAIRFEkH8XXyzt2OEvK1lS+vZbWhEAEH1BZPLkyWrRooUqVKjgPDp06KD/Zv9fNWJPpUruUM1FF3llp50mPfhgkLUCAMSosAaROnXqaPz48Vq4cKEWLFigzp07q0ePHlpmR9Ajtr37rvTyy971nXe628Pb6b4AAORT0uHD9t/byKlcubIefvhhXX/99cd9bnp6ulJTU5WWlub0qCAKbd0q1azpL/v+e+mkk4KqEQAgYAX5/I7YHJFDhw7ppZde0p49e5whmqPJyMhwKp/9gShXo4aUmSm1aeOVNW4sTZoUZK0AADEi7EFk6dKlKleunFJSUjRgwADNnDlTzZs3P+pzx40b5ySorEfdunXDXT2Egq2eWbBAeuopr2zwYOnkk935JAAABDU0s3//fq1bt87pnnnllVf05JNPau7cuUcNI9YjYo8s1iNiYYShmRiybp104on+svXrbcJQUDUCAETx0EzE54h06dJFjRo10tSpU4/7XOaIxCgbqmnYUPrpJ6/sX/+Srr02yFoBABJ5jkiWzMxMX68H4lBysvTjj9L/+39eWZ8+0tlnM1QDAPAprjAaNWqULrnkEtWrV0+7du3S9OnT9fHHH+tdW/qJ+Dd0qPQ//yM1bepef/aZG1K2bZOqVQu6dgCAeA8i27ZtU58+fbR582ani8Y2N7MQcuGFF4bzbRFNbMKqbQNfsaK0Z49bVr26NGuW1KNH0LUDAAQs4nNECoI5InFm9Gjpvvu8627dpNdfD7JGAIBEmyOCBDZmjPT11971G2+4S3/T0oKsFQAgQAQRRFarVtK+ff4yG7aZM4c7AQAJiCCCyEtJcVfP/PWvXlmXLlL//twNAEgwBBEE5+9/l/7v/7zrZ591h2r27uWuAECCIIggWGedJe3e7S8rW1aaPz+oGgEAIoggguBZ8LChmuw7r1pAGTYsyFoBACKAIILoYdvAZ9/s7rHH3KGa/fuDrBUAIIwIIoguF10k/fpr7smtS5YEVSMAQBgRRBB9bDmvDdXY9vBZWraUxo4NslYAgDAgiCB6vfWW9Oqr3vU990ipqdKhQ0HWCgAQQgQRRLdevaStW73r9HSpeHHp+++DrBUAIEQIIoh+dkheZqZ0xhleWZMm0sSJQdYKABACBBHEBls98/nn7qZnWWxn1pNOcueTAABiEkEEsaVvX2ndOu/6hx+k5GRp/fogawUAKCSCCGJP3bruUI31hmSpV0967rkgawUAKASCCGJ3qMYmrD7+uFfWr5905pkM1QBADCGIILbdcou0apV3/cUX7lDN9u1B1goAkE8EEcS+xo2lgwfdjdCyr7R57bUgawUAyAeCCOJDsWLu1vD33eeVXX65dNllQdYKAHAcBBHEl7vvlr75xr87q80nSUsLslYAgDwQRBB/WrSQMjL8ZTZs8/77QdUIAJAHggjiU8mS7uqZYcP8J/v26RNkrQAAORBEEN8efVSaP9+7fv55d6hmz54gawUA+B1BBPHP9hbJGTzKlZM++yyoGgEAfkcQQWIoU8Ydqunf3ys7+2zp1luDrBUAJDyCCBLL009LH3zgXdvOrDZUk3NyKwAgIggiSDwXXCDt3OkvK1VKWrw4qBoBQMIiiCAxpaa6QzXdu3tlrVtL994bZK0AIOEQRJDYZs+WZs3yrseMcSey2pbxAICwI4gAPXr4D8mzFTYlSvgP0wMAhAVBBDBVq7pDNeec47XHySdLjz1G+wBAGBFEgOw++cTd9CyL7cxav76UmUk7AUAYEESAnK65Rtqwwbv+6Sf3dN9162grAAgxgghwNLVru70gTZt6ZSee6O5DAgAIGYIIkBfb6Gz5cmnSJK/s+uulNm3c+SQAgCIjiADHc/PN0urV3vWiRVJysrR1K20HAEVEEAHyo1Ejd2+RatW8spo1pVdeof0AoAgIIkB+2YTVbdukBx/0yq64QuralTYEgEIiiAAFNWqUtHSpd/3ee+58kl9/pS0BoIAIIkBhnHqqtH+/G0CyVK4svfMO7QkABUAQAQrLtoG3Jb533OGVXXKJdPXVtCkA5BNBBCiqhx6SvvjCu/73v92ekt27aVsAOA6CCBAK7dtLe/f6y8qXlz79lPYFgGMgiAChUrq0u9HZDTd4ZeeeKw0aRBsDQB4IIkCoTZsmffihd/2Pf7hDNRkZtDUA5EAQAcKhUycpPd1fVqqUuysrAOAIgggQLjZHxIZqevXyyuycmrvuos0B4HcEESDcXn1Vev117/qBB6SUFHfLeABIcAQRIBK6dZN+/tm7ts3QbB8SO90XABIYQQSIlCpV3KGa88/3ypo3lx55hHsAIGERRIBI+/hj6cUXvevbb5dq13Z3aQWABEMQAYJg28Bv3Ohdb9rknu7744/cDwAJhSACBKVWLbcXxA7Qy9KggbsPCQAkCIIIECTb6GzpUmnyZK/sppukli3d+SQAEOfCGkTGjRundu3aqXz58qpevbp69uyplStXhvMtgdg0YIC0Zo13vWSJlJwsbd4cZK0AILaDyNy5czVo0CB9/vnnev/993XgwAFddNFF2rNnTzjfFohNNixz6JBUs6Z/+GbGjCBrBQBhlXT4cOT6f7dv3+70jFhAOe+88477/PT0dKWmpiotLU0VKlSISB2BqPC//yuNGOFdd+4szZkTZI0AIN8K8vkd0TkiViFTuXLlo/55RkaGU/nsDyAh3XGHtGyZd22H6Nl8kh07gqwVAIRcxIJIZmamhgwZorPPPlunZl8lkGNOiSWorEfdunUjVT0g+thmZ7YDa/Hi/k3R3noryFoBQGwGEZsr8u233+qll17K8zmjRo1yek2yHuvXr49U9YDoZNvAHzhg/zi8sssuk668MshaAUBszREZPHiwZs+erXnz5qmBTcjLJ+aIANksWCC1a5fzH4l7yi8ARJGomSNiGcdCyMyZM/Xhhx8WKIQAyKFtW+m33/xl9g987lyaCkDMSg73cMwLL7yg6dOnO3uJbNmyxXn8lvOHKYD8KVXK3ejM9h3J0rGj/xoAYkhYh2aSbJb/UTzzzDPq16/fcf8+QzPAMVhPiIWQ7CzkW1gBgAAV5PM723T80IvgFiVA4jn/fGnXLv8ckdKlpa++codxACAGcNYMEMvKlXOHarKvorEJrdlX2QBAFCOIAPHAtoF/803vevx4d/8RW/oLAFGMIALEi0svlX75xbu2c2tKlpS++y7IWgHAMRFEgHhixyfYUI2dTZPllFOkhx4KslYAkCeCCBCP7IC87LsYjxzpnuqbmRlkrQAgF4IIEK/+9Cdp82bveutWqVgxae3aIGsFAD4EESCeZfWCtGrllTVsKE2ZEmStAOAIgggQ72xjwa+/lqZN88oGDpTsFGz2+gEQMIIIkChuuME/LLNsmZScLG3aFGStACQ4ggiQSOrXd5f11qnjldWuLU2fHmStACQwggiQaKwXZP166ZFHvLLevXOfWwMAEUAQARLV8OHS8uX+Q/RsPkn2TdEAIMwIIkAia9rU3QY++4m9VatKb7wRZK0AJBCCCJDo7Eya336T7rrLK+veXerVK8haAUgQBBEArrFjpUWLvNaYOdMdqklPp4UAhA1BBICndWtp3z5/i6SmSh99RCsBCAuCCAC/lBR3o7NBg7wyO0TvxhtpKQAhRxABcHRPPCF98ol3/eST7lCNzScBgBAhiADI2znnSLt3+8vKlJG+/JJWAxASBBEAx1a2rDtU8+c/e2VnnCHdcQctB6DICCIA8se2gX/nHe/64YfdoRrbhwQACokgAiD/unaVduzwl5UsKX37La0IoFAIIgAKplIld6jGQkmW006THnyQlgRQYAQRAIVjwzQvv+xd33mnuz28ne4LAPlEEAFQeH/8o7Rli3dtB+bZlvGrV9OqAPKFIAKgaGrUkDIzpbZtvbLGjaVJk2hZAMdFEAFQdLZ65quvpKef9soGD5ZOPtmdTwIAeSCIAAid/v2ln37yrletkpKTpQ0baGUAR0UQARBa9eq5E1YbNPDK6taVnn+elgaQC0EEQOhZL8iaNdJjj3llffpIZ5/NUA0AH4IIgPAZMkRaudK7/uwzN6Rs306rA3AQRACEV5Mm0sGDUrlyXln16tLs2bQ8AIIIgAgoVkzatUsaPdor69lT6t6d5gcSHD0iACLn3nulr7/2rt94w136m5bGXQASFEEEQGS1aiXt2+cvq1hRmjOHOwEkIIIIgMhLSXFXz9x6q1fWpYu7DwmAhEIQARCcCROk//s/7/rZZ92hmr17uStAgiCIAAjWWWdJu3f7y8qWlebPD6pGACKIIAIgeBY8bKjGNj3LHlCGDQuyVgAigCACIHo895z03nvete3MakM1+/cHWSsAYUQQARBdLrxQ2rkz9+TWb74JqkYAwoggAiD6pKa6QzWXXupf9jt2bJC1AhAGBBEA0evNN6VXX/Wu77nHDSl2ui+AuEAQARDdevWStm3zrtPTpeLFpe+/D7JWAEKEIAIg+lWrJmVmSmee6T9M7/HHg6wVgBAgiACIDbZ6xvYWsU3PstjOrI0aufNJAMQkggiA2NK3r7R+vXe9Zo2UnOwvAxAzCCIAYk+dOu5QzUkneWX16vl7SwDEBIIIgNgdqrEJq9nnidihee3bM1QDxBCCCIDYdsst0qpV3vVXX7lDNdlX2gCIWgQRALGvcWPp4EGpYkWvrEYN6bXXgqwVgHwgiACID8WKSb/+6t999fLL/buzAog6BBEA8eWuu/zn0rz9tjufJOf5NQCiAkEEQPxp0ULKyPCXVarkP9kXQFQgiACITyVLuqtnhg/3yrp2lfr0CbJWACIZRObNm6du3bqpVq1aSkpK0qxZs8L5dgCQ2yOPuDuyZnn+eXeoZs8eWguI9yCyZ88etWzZUpMmTQrn2wDAsdkZNXv3+svKlZM++4yWA+I5iFxyySW6//779Yc//CGcbwMAx1e6tDtUY5ueZTn7bPe8GgCBiao5IhkZGUpPT/c9ACCknn5amjPHu7adWW2oJufkVgCJF0TGjRun1NTUI4+6desGXSUA8ahz59zLeUuVkhYvDqpGQMKKqiAyatQopaWlHXms5zRNAOGSmuoO1XTv7pW1bi3dey9tDiRqEElJSVGFChV8DwAIq9mzpewr+saMcSey2pbxABIriABAIHr0kLZv965taW+JEv7D9ADEXhDZvXu3Fi9e7DzM2rVrnd+vW7cunG8LAAVXtao7VHPOOV7ZySdLjz1GawJhlHT4sP3LC4+PP/5YnTp1ylXet29fPfvss8f9+7Zqxiat2nwRhmkARMwLL0jXXutdn3iitGaNlEwnMpAfBfn8DmsQKSqCCIDAbNwo1anjL/vpJ6levaBqBMSMgnx+E+8B4Ghq15YyM6WmTf09I+eeS3sBIUQQAYC82EZny5dL2Y+p+PRTtzx6O5OBmEIQAYDjuflm6ZNPcvz0TJaWLKHtgCIiiABAfthqmv37/WUtW0pXXUX7AUVAEAGA/LK9RWxIJvvkuxkz3KEaAIVCEAGAgkpLcwNIdhZG1q6lLYECIogAQGFceaW7A2t2DRtKQ4fSnkABEEQAoLDKlMm9embCBIZqgAIgiABAUVkYyb7EN2uoZutW2hY4DoIIAIRqie+OHf6ymjWl8eNpX+AYCCIAECqVKuUeqhk1iqEa4BgIIgAQahZG7r0391BNejptDeRAEAGAcBg92j04L7vUVOmpp2hvIBuCCACES61auYdqbriBoRogG4IIAISbhZEBA3IP1ezbR9sj4RFEACASJk+WVq3yl5UuLc2cSfsjoRFEACBSGjfOPVTTq5d0wgncAyQsgggARJqFkR49vOstW9yhmkOHuBdIOAQRAAjCrFnSwoX+suLFpY8/5n4goRBEACAop58uZWb6yzp1ktq3D6pGQMQRRAAgSDYkY0M1bdp4ZV995ZUDcY4gAgDRYMEC6cMP/WXJydLXXwdVIyAiCCIAEC1sWObAgdzDN7ayBohTBBEAiCY2YdWGZKpW9cpsrxEbqgHiEEEEAKLR9u3SK6/4yyyMrF4dVI2AsCCIAEC0uvxyae/e3Jui3XxzUDUCQo4gAgDRzLaBz7l6xraLZ6gGcYIgAgCxwMLI1Kn+MgsjmzcHVSMgJAgiABArbrpJ2rnTX1arlnTffUHVCCgygggAxJLU1NxDNaNHM1SDmEUQAYBYZGFk7NjcQzU5e0yAKEcQAYBYddddueeIVKrkTmYFYgRBBABiWc2auYdqbHkvq2oQIwgiABAPLIwMHuwvszDy229B1QjIF4IIAMSLiRNz77xapoz08stB1Qg4LoIIAMSTRo1yD9VceaVUuXJQNQKOiSACAPHIwohtEZ/l11/doZqDB4OsFZALQQQA4pUdmrd4sb+sRAlpzpygagTkQhABgHjWsqWUmekv69LFLQeiAEEEAOKdDcnYUM2ZZ3plS5Z45UCACCIAkCjmz5fmzvWXJSdLCxYEVSOAIAIACeW883JPWG3XTrrssqBqhARHjwgAJJpixdwhmdq1vbK33mI3VgSCIAIAiWrDBmnWLH+ZzRtZtSqoGiEBEUQAIJH16CHt2+cvO/lk6aabgqoREgxBBAASXUpK7tUz06YxVIOIIIgAAFwWRp56KvdQzcaNtBDChiACAPBcd52UluZvkTp1pNGjaSWEBUEEAOBXoULuoZr77mOoBmFBEAEAHJ2FkfHjcw/V2AF6QIgQRAAAeRsxQtq61V9WubI0aRKthpAgiAAAjq169dxDNYMHM1SDkCCIAADyx8LIsGG5h2r27qUFUWgEEQBA/j36qLR2rb+sbFlpxgxaEYWSdPhw9J4BnZ6ertTUVKWlpamCzeIOkUOZh/Xl2h3atmufqpcvpfYNKqtYclLIXh9AfMnrZ0bC/yyx3pCcgWT37kDvSRDyU5ejPcd8WYivIT+v1ebESlr406+BtU9BPr+LR6JCkyZN0sMPP6wtW7aoZcuWmjhxotq3b68gvPPtZo154zttTvO2ND4htZRGd2uui089IZA6AYheef3M6N7yBL3+zebE/lli/4/t3VuaPt293rPHHarZv18qUSIhfo7npy5He07FMm777Nx7oEBfQ35fyzJHZrZuhmj+3gx7j8iMGTPUp08fTZkyRWeccYYmTJigl19+WStXrlR1mwAVwR4Ru4EDX1iknF9wVkacfM3pUXmTAAQjr58ZeUnYnyXffiuddpq/7J13pK5dQ/5W0fRzPD91Mfn9Hko6ztdQ0O/Hgrx2qBXk8zvsQcTCR7t27fTEE08415mZmapbt65uueUWjRw5MmJBxLqyznnoQ1+KzHmTaqaW0qcjOjNMA+C4PzPykrA/S+yjJDnHtMPmzaVly0L2FtH0czw/dalRIcX53Zb0/H8PJeXxNRT2+zE/rx3XQzP79+/XwoULNWrUqCNlycnJ6tKli+bPn5/r+RkZGc4j+xcSKjZ2dqwbaGnM/tye16FRlZC9L4DCGTp0qObOnRtY8+3JOKgffyncapBN9hn8QhmVTYnI6Hf0aN1a+v57b57Id9+5QzVWHqF7Eqm2z29dCmPTUb6Gonw/Hu+1O3To4EyhCEpY79TPP/+sQ4cOqUaNGr5yu16xYkWu548bN05jxowJS11swk4onwcgvNasWaOvv/46Zpt5VY49wBJahO9jPLT9qq2Re+3jTZMIt6iK69ZzMizbGnXrEbFhnFCwWcOhfB6A8Bo9erQGDhwYWDMv35Su8e/k/g9Tfo28uKma1Qrdar+Yk5kpXXqpv+z006UHHgj7PYlE2xf1+6OgX8PyEL5fzteuWrWq4jaI2BdXrFgxbc2xPbBd16xZM9fzU1JSnEc42NIlmzW8JW3fUSf6ZI2dZS2DAhCs0+1DK0AXZh7Wf7Z+mOfPjLxk/Sz5a78EmyOS17yRhg29fUcWLZIuucQNKTmX/obgnkSy7fNTl6w5IlvT8/89lJTH11DY78f8vHZcb2hWsmRJtWnTRnPmzDlSZpNV7drGpCLJGt2WLpmczZ91bX8eTTcHQHCO9TMjL/wsOYo1a6Q33/SX2aTW5ctDek8i3fb5qcu93U/Rvd3z/z2UdIyvoTDfj/l97bjfWdWGWqZNm6bnnntOy5cvd7pa9+zZo/79+yvSbMmSLV2yRJidXSfccjsAhf6ZYb2rfzmvgfNrdvwsyYMN0WRbiHBkRc1118X0z/H81CWv51QqU+LI/h/5/RoK8lo5s0Y0f29GZGdVW7qbtaFZq1at9PjjjzvLeo+HnVUBRAN2Vg2hYsXcoZnsCvExxM6qO+JmZ9WE3OIdABCg55+X+vTxl61bJ4VocQJi6/ObQ+8AAJF17bXSrl3+snr1pL/9jTuRgAgiAIDIK1cu95DMuHGFWk2D2EYQAQAEx8LIo4/6yyyM/PJLUDVChBFEAADBso0st2/3l9kmW489FlSNEEEEEQBA8Cx45ByqsYDCUE3cI4gAAKKHhZERI/xlFkayDtJD3CGIAACiy/jx0k8/+cvKl3eX/SLuEEQAANHHlvPmHKqxvUdKlgyqRggTgggAIHpZGMm++dmBA+5Qzf79QdYKIUQQAQBEt+eek5Yt85fZSe1vvx1UjRBCBBEAQPSzQ/JynlFjh+k1bhxUjRAiBBEAQGywIRkbqrngAq9s9Wq3/NChIGuGIiCIAABiywcfSPPn+8uKF5dmzAiqRigCgggAIPaceaZ08KC/7Kqr2AAtBhFEAACxqVix3Et8sw/hICYQRAAAsc1Cx8SJ/rLkZOmjj4KqEQqAIAIAiH2DB0u//eYv69xZKlUqqBohnwgiAID4YKEj55BMRgbzRqIcQQQAEF8sjIwc6S+zeSPffBNUjXAMBBEAQPwZN0769Vd/WatWUosWQdUIeSCIAADiU8WKuYdqli5lqCbKEEQAAPHNwsjVV+ceqvnxx6BqhGwIIgCA+Pfii9KGDf6yBg2knj2DqhF+RxABACSG2rVzD9XMns1QTcAIIgCAxGJhpEOH3EM1v/wSVI0SGkEEAJB4PvtM+u47f1nVqtKQIUHVKGERRAAAialZs9xDNX//O0M1EUYQAQAkNgsj1arlHqrZuzeoGiUUgggAANu2SZ9+6m+HsmWlRx6hbcKMIAIAgDn77NxDNbffzlBNmBFEAADILmcYyRqqOXiQdgoDgggAAEcLI7Nm+ctKlHA3RkNIEUQAADiaHj2kQ4f8Zddcw1BNiBFEAADI81MyOe+hmqOVo8AIIgAAHI+FjqlTc3yCJkvvv0/bFRFBBACA/LjpJikjw1920UVuIEGh0XoAAORXyZK5h2Ts2oZqUCgEEQAACsrCxz33+MssjCxaRFsWEEEEAIDCGDNGSkvzl7VpI3XrRnsWAEEEAIDCqlAh91DNm28yVFMABBEAAIrKwsidd+YeqtmwgbY9DoIIAAChcP/90vbt/rK6daWbb6Z9j4EgAgBAqFStmnuoZvJkhmqOgSACAECoWRjp3z/3UM2OHbR1DgQRAADC4emnpbVr/WVVqrhDODiCIAIAQLjUr597qObuuxmqyYYgAgBAuFkY6dIl91DN3r0J3/YEEQAAIsEOyPvmG39Z2bLStGkJ3f4EEQAAIqVFi9xDNTfdJJ1ySsLeA4IIAACRZmHkpJO86+++c4dqDh1KuHtBEAEAIAjffy/Nn+8vK15cWrw4oe4HQQQAgKCceaaUmekva91aGjhQiYIgAgBAkJKS3KEamyuSZcoUrzzOEUQAAIgGU6dKixb5y5KT3SGcOEYQAQAgWrRuLR086C9r0kS65x7Fq7AFkQceeEBnnXWWypQpo4oVK4brbQAAiC/FirlDMj17emVjx8btbqxhCyL79+/XFVdcoYEJNOEGAICQmTlTmjfPX2ZhZOPGuGrksAWRMWPGaOjQoTrttNPC9RYAAMS3c8+VMjL8ZXXqSBMmKF5E1RyRjIwMpaen+x4AACS0kiXdoRpb6ptl6NC4GaqJqiAybtw4paamHnnUrVs36CoBABAd5s+X3njDX2ZhZNcuJUwQGTlypJKSko75WLFiRaErM2rUKKWlpR15rF+/vtCvBQBA3LnsMmn3bn9ZhQrS3LmKVcUL8uThw4erX79+x3xOw4YNC12ZlJQU5wEAAPJgJ/baUM2AAe7eI6ZjR+kvf3E3QovnIFKtWjXnAQAAAjZlitS7t3Teee61hRJ7/PabVKqUlOhzRNatW6fFixc7vx46dMj5vT125+xSAgAAhV9Vk3OOSOnS0oIFMdOiYQsi99xzj1q3bq3Ro0c74cN+b48FMdQ4AABEvXLl3KGaq67yytq1s4mXigVJhw9H74k6tnzXVs/YxNUKNhkHAADk7b//lf7nf7zr5s2lZcsUzZ/fUbV8FwAAFMEll0g7dnjX331nW50rbiarAgCAKFepkjtU8/TTUuXK7oZoUYwgAgBAPLruOsUChmYAAEBgCCIAACAwBBEAABAYgggAAAgMQQQAAASGIAIAAAJDEAEAAIEhiAAAgMAQRAAAQGAIIgAAIDAEEQAAEBiCCAAACAxBBAAABCaqT989bMcYS0pPTw+6KgAAIJ+yPrezPsdjNojs2rXL+bVu3bpBVwUAABTiczw1NfWYz0k6nJ+4EpDMzExt2rRJ5cuXV1JSkqIt7VlAWr9+vSpUqBB0dZAP3LPYwv2KPdyz2JMeps8yixYWQmrVqqXk5OTY7RGxytepU0fRzG4cQSS2cM9iC/cr9nDPYk+FMHyWHa8nJAuTVQEAQGAIIgAAIDAEkUJKSUnR6NGjnV8RG7hnsYX7FXu4Z7EnJQo+y6J6sioAAIhv9IgAAIDAEEQAAEBgCCIAACAwBBEAABAYgkgIdO/eXfXq1VOpUqV0wgkn6Nprr3V2hEV0+vHHH3X99derQYMGKl26tBo1auTMGt+/f3/QVcMxPPDAAzrrrLNUpkwZVaxYkbaKQpMmTVL9+vWdn4VnnHGGvvzyy6CrhDzMmzdP3bp1c3Y+tZ3LZ82apaAQREKgU6dO+s9//qOVK1fq1Vdf1Q8//KA//vGPoXhphMGKFSuc4wOmTp2qZcuW6bHHHtOUKVP0t7/9jfaOYhYUr7jiCg0cODDoquAoZsyYoWHDhjmhftGiRWrZsqW6du2qbdu20V5RaM+ePc49svAYNJbvhsHrr7+unj17KiMjQyVKlAjHWyDEHn74YU2ePFlr1qyhbaPcs88+qyFDhmjnzp1BVwXZWA9Iu3bt9MQTTzjXFvbtDJNbbrlFI0eOpK2iWFJSkmbOnOl8bgWBHpEQ27Fjh1588UWnC5kQEjvS0tJUuXLloKsBxGxv1cKFC9WlSxffWWF2PX/+/EDrhuhHEAmRESNGqGzZsqpSpYrWrVun2bNnh+qlEWarV6/WxIkT9Ze//IW2Bgrh559/1qFDh1SjRg1fuV1v2bKFNsUxEUTyYF2J1l11rIfNNchy++236+uvv9Z7772nYsWKqU+fPs4xyIjee2Y2btyoiy++2Jl7cOONN3K7YuCeAYgvxYOuQLQaPny4+vXrd8znNGzY8Mjvq1at6jyaNGmiZs2aOWOjn3/+uTp06BCB2qIw98xWNtlEYxtG++c//0kjxsA9Q3Syn332H7CtW7f6yu26Zs2agdULsYEgkodq1ao5j8KwSVrGJqsiOu+Z9YRYCGnTpo2eeeYZZzwbsfXvDNGjZMmSzr+lOXPmHJnwaD8H7Xrw4MFBVw9RjiBSRF988YW++uornXPOOapUqZKzdPfuu+929qagNyQ6WQjp2LGjTjzxRD3yyCPavn37kT/jf2/Ry+Ze2WRw+9XmIyxevNgpP+mkk1SuXLmgq5fwbOlu37591bZtW7Vv314TJkxwloj2798/4dsmGu3evduZH5dl7dq1zr8pm7Rv+2JFlJ2+i8JbsmTJ4U6dOh2uXLny4ZSUlMP169c/PGDAgMMbNmygWaPUM888Y5N3jvpA9Orbt+9R79lHH30UdNXwu4kTJx6uV6/e4ZIlSx5u37794c8//5y2iVIfffTRUf892b+zSGMfEQAAEBgGxgEAQGAIIgAAIDAEEQAAEBiCCAAACAxBBAAABIYgAgAAAkMQAQAAgSGIAACAwBBEAABAYAgiAAAgMAQRAAAQGIIIAABQUP4/G21sRr0SwT8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = .2\n",
    "nn = NeuralNetwork([1,1], lr=lr)\n",
    "\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(1000):\n",
    "    loss, val_loss, gradients_weights, gradients_biases = nn.step(X, y, Xtest, ytest)\n",
    "    print(f\"Epoch {epoch}, Loss: {loss:.4f}, Validation Loss: {val_loss:.4f}, Gradient norm: {np.sum([gw**2 for gw in gradients_weights])+ np.sum([gb**2 for gb in gradients_biases])}\")\n",
    "\n",
    "# Predict\n",
    "y_pred = nn.predict(X)\n",
    "\n",
    "# Plot the results (requires matplotlib)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X, y, label=\"True\")\n",
    "plt.plot(X, y_pred, color=\"red\", label=\"Predicted\")\n",
    "plt.plot(np.arange(-1, 1, 0.001), float(w_star)*(np.arange(-1, 1, 0.001)), color = 'k')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea858963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-1.25342943e+43]])]\n",
      "[array([[4.12824338e+41]])]\n",
      "-0.07135505490624879\n"
     ]
    }
   ],
   "source": [
    "print(nn.weights)\n",
    "print(nn.biases)\n",
    "print(np.mean(y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
